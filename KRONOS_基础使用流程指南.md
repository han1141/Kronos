# Kronos åŸºç¡€ä½¿ç”¨æµç¨‹æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¼€å§‹

æœ¬æŒ‡å—å°†å¸¦æ‚¨å®ŒæˆKronosçš„åŸºç¡€é¢„æµ‹åŠŸèƒ½ï¼Œä»æ•°æ®å‡†å¤‡åˆ°è·å¾—é¢„æµ‹ç»“æœã€‚

## ğŸ“Š æ•°æ®å‡†å¤‡

### 1. æ•°æ®æ ¼å¼è¦æ±‚

Kronosæ”¯æŒCSVå’ŒFeatheræ ¼å¼çš„é‡‘èæ•°æ®ï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š

**å¿…éœ€åˆ—**:
- `open`: å¼€ç›˜ä»·
- `high`: æœ€é«˜ä»·  
- `low`: æœ€ä½ä»·
- `close`: æ”¶ç›˜ä»·

**å¯é€‰åˆ—**:
- `volume`: æˆäº¤é‡
- `amount`: æˆäº¤é¢ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼Œä¸å‚ä¸é¢„æµ‹ï¼‰
- `timestamps`/`timestamp`/`date`: æ—¶é—´æˆ³

### 2. æ•°æ®ç¤ºä¾‹

```csv
timestamps,open,high,low,close,volume,amount
2024-01-01 09:30:00,100.0,102.5,99.8,101.2,1000000,101200000
2024-01-01 09:35:00,101.2,103.0,100.5,102.8,1200000,122400000
2024-01-01 09:40:00,102.8,104.2,102.0,103.5,1100000,113850000
...
```

### 3. æ•°æ®è´¨é‡æ£€æŸ¥

```python
import pandas as pd

# åŠ è½½æ•°æ®
df = pd.read_csv("your_data.csv")

# åŸºç¡€æ£€æŸ¥
print(f"æ•°æ®è¡Œæ•°: {len(df)}")
print(f"æ•°æ®åˆ—: {list(df.columns)}")
print(f"ç¼ºå¤±å€¼: {df.isnull().sum()}")

# æ£€æŸ¥å¿…éœ€åˆ—
required_cols = ['open', 'high', 'low', 'close']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print(f"âŒ ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
else:
    print("âœ… æ•°æ®æ ¼å¼æ­£ç¡®")
```

## ğŸš€ åŸºç¡€é¢„æµ‹æµç¨‹

### æ­¥éª¤1: å¯¼å…¥æ¨¡å—

```python
import pandas as pd
import matplotlib.pyplot as plt
from model import Kronos, KronosTokenizer, KronosPredictor
```

### æ­¥éª¤2: åŠ è½½æ¨¡å‹

```python
# ä»Hugging FaceåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
model = Kronos.from_pretrained("NeoQuasar/Kronos-small")

# åˆ›å»ºé¢„æµ‹å™¨
predictor = KronosPredictor(
    model=model, 
    tokenizer=tokenizer, 
    device="cuda:0",  # æˆ– "cpu", "mps"
    max_context=512
)
```

### æ­¥éª¤3: å‡†å¤‡æ•°æ®

```python
# åŠ è½½æ•°æ®
df = pd.read_csv("./data/your_data.csv")
df['timestamps'] = pd.to_datetime(df['timestamps'])

# è®¾ç½®å‚æ•°
lookback = 400    # å†å²æ•°æ®é•¿åº¦
pred_len = 120    # é¢„æµ‹é•¿åº¦

# å‡†å¤‡è¾“å…¥æ•°æ®
x_df = df.iloc[:lookback][['open', 'high', 'low', 'close', 'volume']]
x_timestamp = df.iloc[:lookback]['timestamps']
y_timestamp = df.iloc[lookback:lookback+pred_len]['timestamps']
```

### æ­¥éª¤4: æ‰§è¡Œé¢„æµ‹

```python
# è¿›è¡Œé¢„æµ‹
pred_df = predictor.predict(
    df=x_df,
    x_timestamp=x_timestamp,
    y_timestamp=y_timestamp,
    pred_len=pred_len,
    T=1.0,          # æ¸©åº¦å‚æ•°
    top_p=0.9,      # æ ¸é‡‡æ ·æ¦‚ç‡
    sample_count=1, # é‡‡æ ·æ¬¡æ•°
    verbose=True    # æ˜¾ç¤ºè¿›åº¦
)

print("é¢„æµ‹ç»“æœ:")
print(pred_df.head())
```

### æ­¥éª¤5: ç»“æœå¯è§†åŒ–

```python
def plot_prediction(historical_df, pred_df, actual_df=None):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœ"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)
    
    # ç»˜åˆ¶ä»·æ ¼
    ax1.plot(historical_df['timestamps'], historical_df['close'], 
             label='å†å²æ•°æ®', color='blue', linewidth=1.5)
    
    # é¢„æµ‹æ•°æ®æ—¶é—´æˆ³
    pred_timestamps = pd.date_range(
        start=historical_df['timestamps'].iloc[-1], 
        periods=len(pred_df)+1, 
        freq='5T'
    )[1:]  # æ’é™¤ç¬¬ä¸€ä¸ªç‚¹é¿å…é‡å¤
    
    ax1.plot(pred_timestamps, pred_df['close'], 
             label='é¢„æµ‹æ•°æ®', color='red', linewidth=1.5)
    
    if actual_df is not None:
        ax1.plot(pred_timestamps, actual_df['close'], 
                 label='å®é™…æ•°æ®', color='green', linewidth=1.5)
    
    ax1.set_ylabel('æ”¶ç›˜ä»·')
    ax1.legend()
    ax1.grid(True)
    ax1.set_title('Kronos ä»·æ ¼é¢„æµ‹ç»“æœ')
    
    # ç»˜åˆ¶æˆäº¤é‡
    ax2.plot(historical_df['timestamps'], historical_df['volume'], 
             label='å†å²æˆäº¤é‡', color='blue', alpha=0.7)
    ax2.plot(pred_timestamps, pred_df['volume'], 
             label='é¢„æµ‹æˆäº¤é‡', color='red', alpha=0.7)
    
    ax2.set_ylabel('æˆäº¤é‡')
    ax2.set_xlabel('æ—¶é—´')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()

# ç»˜åˆ¶ç»“æœ
plot_prediction(x_df, pred_df)
```

## ğŸ”§ å‚æ•°è°ƒä¼˜

### é¢„æµ‹è´¨é‡å‚æ•°

#### 1. Temperature (T)
- **èŒƒå›´**: 0.1 - 2.0
- **ä½œç”¨**: æ§åˆ¶é¢„æµ‹çš„éšæœºæ€§
- **å»ºè®®**: 
  - `T=0.8-1.2`: å¹³è¡¡çš„é¢„æµ‹
  - `T<0.8`: æ›´ä¿å®ˆçš„é¢„æµ‹
  - `T>1.2`: æ›´å¤šæ ·åŒ–çš„é¢„æµ‹

#### 2. Nucleus Sampling (top_p)
- **èŒƒå›´**: 0.1 - 1.0
- **ä½œç”¨**: æ§åˆ¶é¢„æµ‹çš„å¤šæ ·æ€§
- **å»ºè®®**:
  - `top_p=0.9-1.0`: è€ƒè™‘æ›´å¤šå¯èƒ½æ€§
  - `top_p=0.7-0.9`: å¹³è¡¡è´¨é‡å’Œå¤šæ ·æ€§
  - `top_p<0.7`: æ›´é›†ä¸­çš„é¢„æµ‹

#### 3. Sample Count
- **èŒƒå›´**: 1 - 5
- **ä½œç”¨**: ç”Ÿæˆå¤šä¸ªæ ·æœ¬å¹¶å¹³å‡
- **å»ºè®®**:
  - `sample_count=1`: å¿«é€Ÿé¢„æµ‹
  - `sample_count=3-5`: æ›´ç¨³å®šçš„ç»“æœ

### ç¤ºä¾‹å‚æ•°ç»„åˆ

```python
# ä¿å®ˆé¢„æµ‹ï¼ˆé€‚åˆé£é™©åŒæ¶ï¼‰
pred_df_conservative = predictor.predict(
    df=x_df, x_timestamp=x_timestamp, y_timestamp=y_timestamp,
    pred_len=pred_len, T=0.8, top_p=0.7, sample_count=3
)

# å¹³è¡¡é¢„æµ‹ï¼ˆæ¨èè®¾ç½®ï¼‰
pred_df_balanced = predictor.predict(
    df=x_df, x_timestamp=x_timestamp, y_timestamp=y_timestamp,
    pred_len=pred_len, T=1.0, top_p=0.9, sample_count=2
)

# æ¢ç´¢æ€§é¢„æµ‹ï¼ˆé€‚åˆç ”ç©¶åˆ†æï¼‰
pred_df_exploratory = predictor.predict(
    df=x_df, x_timestamp=x_timestamp, y_timestamp=y_timestamp,
    pred_len=pred_len, T=1.5, top_p=1.0, sample_count=5
)
```

## ğŸ“ˆ æ‰¹é‡é¢„æµ‹

å¯¹äºå¤šä¸ªæ—¶é—´åºåˆ—æˆ–å¤šä¸ªæ—¶é—´æ®µçš„é¢„æµ‹ï¼š

```python
# å‡†å¤‡å¤šä¸ªæ•°æ®é›†
df_list = []
x_timestamp_list = []
y_timestamp_list = []

for i in range(3):  # 3ä¸ªä¸åŒçš„æ—¶é—´æ®µ
    start_idx = i * 200
    x_df_i = df.iloc[start_idx:start_idx+lookback][['open', 'high', 'low', 'close', 'volume']]
    x_ts_i = df.iloc[start_idx:start_idx+lookback]['timestamps']
    y_ts_i = df.iloc[start_idx+lookback:start_idx+lookback+pred_len]['timestamps']
    
    df_list.append(x_df_i)
    x_timestamp_list.append(x_ts_i)
    y_timestamp_list.append(y_ts_i)

# æ‰¹é‡é¢„æµ‹
pred_df_list = predictor.predict_batch(
    df_list=df_list,
    x_timestamp_list=x_timestamp_list,
    y_timestamp_list=y_timestamp_list,
    pred_len=pred_len,
    T=1.0,
    top_p=0.9,
    sample_count=1,
    verbose=True
)

# å¤„ç†ç»“æœ
for i, pred_df in enumerate(pred_df_list):
    print(f"é¢„æµ‹ç»“æœ {i+1}:")
    print(pred_df.head())
```

## ğŸ¯ æ— æˆäº¤é‡é¢„æµ‹

å¦‚æœæ•°æ®ä¸­æ²¡æœ‰æˆäº¤é‡ä¿¡æ¯ï¼š

```python
# åªä½¿ç”¨OHLCæ•°æ®
x_df_no_vol = df.iloc[:lookback][['open', 'high', 'low', 'close']]

pred_df_no_vol = predictor.predict(
    df=x_df_no_vol,
    x_timestamp=x_timestamp,
    y_timestamp=y_timestamp,
    pred_len=pred_len,
    T=1.0,
    top_p=0.9,
    sample_count=1
)
```

## ğŸ“Š ç»“æœåˆ†æ

### 1. åŸºç¡€ç»Ÿè®¡

```python
# é¢„æµ‹ç»Ÿè®¡
print("é¢„æµ‹ç»“æœç»Ÿè®¡:")
print(f"é¢„æµ‹ç‚¹æ•°: {len(pred_df)}")
print(f"ä»·æ ¼èŒƒå›´: {pred_df['close'].min():.2f} - {pred_df['close'].max():.2f}")
print(f"å¹³å‡ä»·æ ¼: {pred_df['close'].mean():.2f}")
print(f"ä»·æ ¼å˜åŒ–: {((pred_df['close'].iloc[-1] / pred_df['close'].iloc[0]) - 1) * 100:.2f}%")
```

### 2. è¶‹åŠ¿åˆ†æ

```python
# è¶‹åŠ¿åˆ¤æ–­
price_change = pred_df['close'].iloc[-1] - pred_df['close'].iloc[0]
if price_change > 0:
    trend = "ä¸Šæ¶¨"
elif price_change < 0:
    trend = "ä¸‹è·Œ"
else:
    trend = "æ¨ªç›˜"

print(f"é¢„æµ‹è¶‹åŠ¿: {trend}")
print(f"é¢„æµ‹æ¶¨è·Œå¹…: {(price_change / pred_df['close'].iloc[0]) * 100:.2f}%")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®è´¨é‡**: ç¡®ä¿è¾“å…¥æ•°æ®æ— ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
2. **æ—¶é—´è¿ç»­æ€§**: æ—¶é—´æˆ³åº”è¯¥è¿ç»­ï¼Œæ— å¤§çš„é—´éš”
3. **æ•°æ®é•¿åº¦**: è‡³å°‘éœ€è¦400ä¸ªå†å²æ•°æ®ç‚¹
4. **è®¾å¤‡é€‰æ‹©**: GPUå¯æ˜¾è‘—æå‡é¢„æµ‹é€Ÿåº¦
5. **å†…å­˜ç®¡ç†**: å¤§æ‰¹é‡é¢„æµ‹æ—¶æ³¨æ„å†…å­˜ä½¿ç”¨

## ğŸ”— ä¸‹ä¸€æ­¥

- å­¦ä¹ ä½¿ç”¨ [Web UIç•Œé¢] è¿›è¡Œå¯è§†åŒ–é¢„æµ‹
- äº†è§£ [å¾®è°ƒè®­ç»ƒ] é€‚åº”ç‰¹å®šå¸‚åœº
- æŸ¥çœ‹ [æ•…éšœæ’é™¤æŒ‡å—] è§£å†³å¸¸è§é—®é¢˜

---

**æç¤º**: è¿™åªæ˜¯åŸºç¡€ä½¿ç”¨æµç¨‹ï¼Œå®é™…åº”ç”¨ä¸­å»ºè®®ç»“åˆé¢†åŸŸçŸ¥è¯†å’Œé£é™©ç®¡ç†ç­–ç•¥ã€‚