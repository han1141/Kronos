# -*- coding: utf-8 -*-
# V49.2-Fetch-Fix

# --- 1. å¯¼å…¥åº“ä¸é…ç½® ---
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import logging
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
import matplotlib.font_manager
import joblib
import os
import warnings

try:
    import lightgbm as lgb
except ImportError:
    lgb = None

warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")
warnings.filterwarnings("ignore", category=FutureWarning)

from backtesting import Backtest, Strategy
from backtesting.lib import crossover
import ta

# --- æ—¥å¿—é…ç½® (æ— å˜åŒ–) ---
logger = logging.getLogger(__name__)
# ... (æ—¥å¿—é…ç½®ä¿æŒä¸å˜)
logger.setLevel(logging.DEBUG)
log_filename = f"trading_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
file_handler = logging.FileHandler(log_filename, encoding="utf-8")
file_handler.setLevel(logging.DEBUG)
stream_handler = logging.StreamHandler()
stream_handler.setLevel(logging.INFO)
formatter = logging.Formatter(
    "%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
)
file_handler.setFormatter(formatter)
stream_handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(file_handler)
    logger.addHandler(stream_handler)


def set_chinese_font():  # (æ— å˜åŒ–)
    try:
        font_names = [
            "PingFang SC",
            "Microsoft YaHei",
            "SimHei",
            "Heiti TC",
            "sans-serif",
        ]
        for font in font_names:
            if font in [f.name for f in matplotlib.font_manager.fontManager.ttflist]:
                plt.rcParams["font.sans-serif"] = [font]
                plt.rcParams["axes.unicode_minus"] = False
                logger.info(f"æˆåŠŸè®¾ç½®ä¸­æ–‡å­—ä½“: {font}")
                return
        logger.warning("æœªæ‰¾åˆ°æŒ‡å®šçš„ä¸­æ–‡å­—ä½“")
    except Exception as e:
        logger.error(f"è®¾ç½®ä¸­æ–‡å­—ä½“æ—¶å‡ºé”™: {e}")


set_chinese_font()


# --- æ ¸å¿ƒé…ç½® (æ— å˜åŒ–) ---
CONFIG = {
    "symbols_to_test": ["ETHUSDT"],
    "interval": "15m",
    "backtest_start_date": "2025-01-01",
    "backtest_end_date": "2025-11-06",
    "initial_cash": 500_000,
    "commission": 0.00075,
    "spread": 0.0002,
    "show_plots": False,
    "data_lookback_days": 250,
}

# --- æ¨¡å‹æ–‡ä»¶è·¯å¾„é…ç½® (æ— å˜åŒ–) ---
LGBM_4H_MODEL_PATH = "models/eth_trend_model_lgb_4h.joblib"
LGBM_4H_SCALER_PATH = "models/eth_trend_scaler_lgb_4h.joblib"
LGBM_4H_FEATURE_COLUMNS_PATH = "models/feature_columns_lgb_4h.joblib"
LGBM_4H_THRESHOLD = 0.3159
LGBM_SEQUENCE_LENGTH = 60

# --- ç­–ç•¥å‚æ•° (æ— å˜åŒ–) ---
STRATEGY_PARAMS = {
    "tactical_ema_period": 50,
    "tactical_adx_period": 14,
    "long_entry_threshold": 0.3,
    "short_entry_threshold": -0.3,
    "score_weights": {
        "ema_direction": 0.5,
        "ml_signal": 0.4,
        "adx_score": 0.1,
    },
    "tsl_enabled": True,
    "tsl_activation_atr_mult": 1.5,
    "tsl_trailing_atr_mult": 2.0,
    "kelly_trade_history": 20,
    "default_risk_pct": 0.015,
    "max_risk_pct": 0.04,
    "tf_atr_period": 14,
    "tf_stop_loss_atr_multiplier": 2.5,
}


# --- å‡½æ•°å®šä¹‰ ---
def fetch_binance_klines(s, i, st, en=None, l=1000):
    url, cols = "https://api.binance.com/api/v3/klines", [
        "timestamp",
        "Open",
        "High",
        "Low",
        "Close",
        "Volume",
        "close_time",
        "quote_asset_volume",
        "number_of_trades",
        "taker_buy_base_volume",
        "taker_buy_quote_volume",
        "ignore",
    ]
    sts, ets = int(pd.to_datetime(st).timestamp() * 1000), (
        int(pd.to_datetime(en).timestamp() * 1000) if en else int(time.time() * 1000)
    )
    all_d, retries, last_e = [], 5, None
    while sts < ets:
        p = {
            "symbol": s.upper(),
            "interval": i,
            "startTime": sts,
            "endTime": ets,
            "limit": l,
        }
        for attempt in range(retries):
            try:
                r = requests.get(url, params=p, timeout=15)
                r.raise_for_status()
                d = r.json()
                if not d:
                    sts = ets
                    break
                all_d.extend(d)

                # ### <<< æ ¸å¿ƒä¿®æ­£ï¼šä»åˆ—è¡¨ä¸­è·å–æ—¶é—´æˆ³ >>> ###
                sts = d[-1][0] + 1

                break
            except requests.exceptions.RequestException as e:
                last_e = e
                time.sleep(2**attempt)
        else:
            logger.error(f"è·å– {s} å¤±è´¥: {last_e}")
            return pd.DataFrame()
    if not all_d:
        return pd.DataFrame()
    df = pd.DataFrame(all_d, columns=cols)[
        ["timestamp", "Open", "High", "Low", "Close", "Volume"]
    ].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
    for col in df.columns[1:]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    logger.info(f"âœ… è·å– {s} æ•°æ®æˆåŠŸ: {len(df)} æ¡")
    return df.set_index("timestamp").sort_index()


def add_features_for_lgbm_model(df: pd.DataFrame) -> pd.DataFrame:  # (æ— å˜åŒ–)
    high, low, close, volume = df["High"], df["Low"], df["Close"], df["Volume"]
    df["volatility"] = (
        np.log(df["Close"] / df["Close"].shift(1)).rolling(window=20).std()
    )
    df["EMA_8"] = ta.trend.EMAIndicator(close=close, window=8).ema_indicator()
    df["RSI_14"] = ta.momentum.RSIIndicator(close=close, window=14).rsi()
    adx_indicator = ta.trend.ADXIndicator(high=high, low=low, close=close, window=14)
    df["ADX_14"], df["DMP_14"], df["DMN_14"] = (
        adx_indicator.adx(),
        adx_indicator.adx_pos(),
        adx_indicator.adx_neg(),
    )
    atr_raw = ta.volatility.AverageTrueRange(
        high=high, low=low, close=close, window=14
    ).average_true_range()
    df["ATRr_14"] = (atr_raw / close) * 100
    bb_indicator = ta.volatility.BollingerBands(close=close, window=20, window_dev=2.0)
    (
        df["BBU_20_2.0"],
        df["BBM_20_2.0"],
        df["BBL_20_2.0"],
        df["BBB_20_2.0"],
        df["BBP_20_2.0"],
    ) = (
        bb_indicator.bollinger_hband(),
        bb_indicator.bollinger_mavg(),
        bb_indicator.bollinger_lband(),
        bb_indicator.bollinger_wband(),
        bb_indicator.bollinger_pband(),
    )
    macd_indicator = ta.trend.MACD(
        close=close, window_fast=12, window_slow=26, window_sign=9
    )
    df["MACD_12_26_9"], df["MACDs_12_26_9"], df["MACDh_12_26_9"] = (
        macd_indicator.macd(),
        macd_indicator.macd_signal(),
        macd_indicator.macd_diff(),
    )
    df["OBV"] = ta.volume.OnBalanceVolumeIndicator(
        close=close, volume=volume
    ).on_balance_volume()
    df["volume_change_rate"] = volume.pct_change()
    return df


def create_flattened_sequences(data, look_back=60):  # (æ— å˜åŒ–)
    X = []
    for i in range(len(data) - look_back + 1):
        X.append(data[i : (i + look_back), :].flatten())
    return np.array(X, dtype=np.float32) if X else np.array([])


def generate_lgbm_signals(symbol: str, interval: str) -> pd.Series:  # (æ— å˜åŒ–)
    logger.info(f"--- æ­£åœ¨ä¸º [{symbol}] ç”Ÿæˆ [{interval}] çº§åˆ«çš„LGBMä¿¡å· ---")
    if lgb is None:
        logger.warning("lightgbmåº“æœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆLGBMä¿¡å·ã€‚")
        return pd.Series(dtype="float64")
    if not all(
        os.path.exists(p)
        for p in [LGBM_4H_MODEL_PATH, LGBM_4H_SCALER_PATH, LGBM_4H_FEATURE_COLUMNS_PATH]
    ):
        logger.warning(f"ç¼ºå°‘ {interval} æ¨¡å‹çš„å¿…è¦æ–‡ä»¶ï¼Œå°†è¿”å›ç©ºä¿¡å·ã€‚")
        return pd.Series(dtype="float64")
    try:
        model, scaler, feature_columns = (
            joblib.load(LGBM_4H_MODEL_PATH),
            joblib.load(LGBM_4H_SCALER_PATH),
            joblib.load(LGBM_4H_FEATURE_COLUMNS_PATH),
        )
        start_date = (
            datetime.now() - timedelta(days=CONFIG["data_lookback_days"] + 200)
        ).strftime("%Y-%m-%d")
        end_date = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
        df_lgbm = fetch_binance_klines(symbol, interval, start_date, end_date)
        if df_lgbm.empty:
            return pd.Series(dtype="float64")

        df_featured = add_features_for_lgbm_model(df_lgbm.copy())
        for col in feature_columns:
            if col not in df_featured.columns:
                df_featured[col] = 0
        df_aligned = df_featured[feature_columns].dropna()
        if df_aligned.empty:
            return pd.Series(dtype="float64")

        scaled_features = scaler.transform(df_aligned)
        X_sequences = create_flattened_sequences(
            scaled_features, look_back=LGBM_SEQUENCE_LENGTH
        )
        if X_sequences.shape[0] == 0:
            return pd.Series(dtype="float64")

        probs = model.predict_proba(X_sequences)[:, 1]
        signals = np.where(probs > LGBM_4H_THRESHOLD, 1, -1)
        signal_index = df_aligned.index[LGBM_SEQUENCE_LENGTH - 1 :]
        signal_series = pd.Series(signals, index=signal_index)

        logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(signal_series)} æ¡ [{interval}] LGBMä¿¡å·ã€‚")
        return signal_series
    except Exception as e:
        logger.error(f"ç”Ÿæˆ {interval} LGBMä¿¡å·æ—¶å‡ºé”™: {e}", exc_info=True)
        return pd.Series(dtype="float64")


def preprocess_data_for_strategy(
    data_in: pd.DataFrame, symbol: str
) -> pd.DataFrame:  # (æ— å˜åŒ–)
    df_15m = data_in.copy()
    logger.info(f"[{symbol}] å¼€å§‹ 4h å‘¨æœŸç­–ç•¥çš„æ•°æ®é¢„å¤„ç†...")
    p = STRATEGY_PARAMS
    start_date = (
        df_15m.index.min() - timedelta(days=CONFIG["data_lookback_days"] + 50)
    ).strftime("%Y-%m-%d")
    end_date = (df_15m.index.max() + timedelta(days=1)).strftime("%Y-%m-%d")
    df_4h = fetch_binance_klines(symbol, "4h", start_date, end_date)
    if df_4h.empty:
        logger.error(f"æ— æ³•è·å– {symbol} çš„ 4h æ•°æ®ï¼Œç­–ç•¥æ— æ³•è¿è¡Œã€‚")
        for col in ["trend_direction", "adx_score", "entry_signal"]:
            df_15m[col] = 0
        return df_15m
    logger.info(f"[{symbol}] åœ¨ 4h æ•°æ®ä¸Šè®¡ç®— EMA, ADX, å’Œ LGBM ä¿¡å·...")
    ema_4h = ta.trend.EMAIndicator(
        df_4h["Close"], window=p["tactical_ema_period"]
    ).ema_indicator()
    df_4h["trend_direction"] = np.where(df_4h["Close"] > ema_4h, 1, -1)
    adx_indicator = ta.trend.ADXIndicator(
        df_4h["High"], df_4h["Low"], df_4h["Close"], window=p["tactical_adx_period"]
    )
    adx_values = adx_indicator.adx()
    df_4h["adx_score"] = (adx_values / 60).clip(0, 1)
    lgbm_signal_4h = generate_lgbm_signals(symbol, "4h")
    df_4h["entry_signal"] = lgbm_signal_4h.reindex(df_4h.index).fillna(0)
    logger.info(f"[{symbol}] å°† 4h ä¿¡å·å¹¿æ’­åˆ° 15m æ•°æ®...")
    for signal_col in ["trend_direction", "adx_score", "entry_signal"]:
        df_15m[signal_col] = (
            df_4h[signal_col].reindex(df_15m.index, method="ffill").fillna(0)
        )
    df_15m["atr_15m"] = ta.volatility.AverageTrueRange(
        df_15m["High"], df_15m["Low"], df_15m["Close"], p["tf_atr_period"]
    ).average_true_range()
    df_15m.dropna(inplace=True)
    logger.info(f"[{symbol}] æ•°æ®é¢„å¤„ç†å®Œæˆã€‚")
    return df_15m


# --- ç­–ç•¥ç±»å®šä¹‰ ---
class UltimateStrategy(Strategy):  # (æ— å˜åŒ–)
    symbol, vol_weight = (None, 1.0)

    def init(self):
        for key, value in STRATEGY_PARAMS.items():
            setattr(self, key, value)
        self.recent_trade_returns = deque(maxlen=self.kelly_trade_history)
        self.reset_trade_state()
        self.trend_direction = self.I(lambda: self.data.trend_direction)
        self.adx_score = self.I(lambda: self.data.adx_score)
        self.entry_signal = self.I(lambda: self.data.entry_signal)
        self.final_score = self.I(self._calculate_score)
        self.atr = self.I(lambda: self.data.atr_15m)

    def _calculate_score(self):
        w = self.score_weights
        direction_scores = w["ema_direction"] * self.trend_direction
        ml_scores = w["ml_signal"] * self.entry_signal
        adx_scores = w["adx_score"] * self.adx_score
        return direction_scores + ml_scores + adx_scores

    def next(self):
        if self.position:
            self.manage_open_position(self.data.Close[-1])
            return

        long_signal = crossover(self.final_score, self.long_entry_threshold)
        short_signal = crossover(self.short_entry_threshold, self.final_score)

        if long_signal:
            self.open_position(self.data.Close[-1], is_long=True)
        elif short_signal:
            self.open_position(self.data.Close[-1], is_long=False)

    def reset_trade_state(self):
        self.stop_loss_price = 0.0
        self.trailing_stop_active = False

    def manage_open_position(self, p):
        if (self.position.is_long and p < self.stop_loss_price) or (
            self.position.is_short and p > self.stop_loss_price
        ):
            self.position.close()
        elif self.tsl_enabled:
            self._manage_trailing_stop_loss()

    def _manage_trailing_stop_loss(self):
        if not self.position:
            return
        is_active, entry_price, current_price = (
            self.trailing_stop_active,
            self.trades[-1].entry_price,
            self.data.Close[-1],
        )
        if not is_active:
            activation_dist = self.atr[-1] * self.tsl_activation_atr_mult
            if (
                self.position.is_long and current_price >= entry_price + activation_dist
            ) or (
                self.position.is_short
                and current_price <= entry_price - activation_dist
            ):
                self.trailing_stop_active = True
        if self.trailing_stop_active:
            trail_dist = self.atr[-1] * self.tsl_trailing_atr_mult
            if self.position.is_long:
                self.stop_loss_price = max(
                    self.stop_loss_price, current_price - trail_dist
                )
            else:
                self.stop_loss_price = min(
                    self.stop_loss_price, current_price + trail_dist
                )

    def open_position(self, p, is_long):
        risk_ps = self.atr[-1] * self.tf_stop_loss_atr_multiplier
        if risk_ps <= 0:
            return
        size = self._calculate_position_size(p, risk_ps, self._calculate_dynamic_risk())
        if size <= 0:
            return
        self.reset_trade_state()
        if is_long:
            self.buy(size=size)
            self.stop_loss_price = p - risk_ps
        else:
            self.sell(size=size)
            self.stop_loss_price = p + risk_ps

    def _calculate_position_size(self, p, rps, risk_pct):
        if rps <= 0 or p <= 0:
            return 0
        return int(min((self.equity * risk_pct) / rps, (self.equity * 0.95) / p))

    def _calculate_dynamic_risk(self):
        if len(self.recent_trade_returns) < self.kelly_trade_history:
            return self.default_risk_pct * self.vol_weight
        wins, losses = [r for r in self.recent_trade_returns if r > 0], [
            r for r in self.recent_trade_returns if r < 0
        ]
        if not wins or not losses:
            return self.default_risk_pct * self.vol_weight
        win_rate, avg_win, avg_loss = (
            len(wins) / len(self.recent_trade_returns),
            sum(wins) / len(wins),
            abs(sum(losses) / len(losses)),
        )
        if avg_loss == 0 or (reward_ratio := avg_win / avg_loss) == 0:
            return self.default_risk_pct * self.vol_weight
        return min(
            max(0.005, (win_rate - (1 - win_rate) / reward_ratio) * 0.5)
            * self.vol_weight,
            self.max_risk_pct,
        )


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    logger.info(f"ğŸš€ (V49.2-Fetch-Fix & Crossover) å¼€å§‹è¿è¡Œ...")

    import sys

    if len(sys.argv) == 3:
        CONFIG["backtest_start_date"] = sys.argv[1]
        CONFIG["backtest_end_date"] = sys.argv[2]

    backtest_start_dt = pd.to_datetime(CONFIG["backtest_start_date"])
    data_fetch_start_date = (
        backtest_start_dt - timedelta(days=CONFIG["data_lookback_days"])
    ).strftime("%Y-%m-%d")

    logger.info(
        f"å›æµ‹æ—¶é—´æ®µ: {CONFIG['backtest_start_date']} to {CONFIG['backtest_end_date']}"
    )
    logger.info(f"æ•°æ®è·å–èµ·å§‹æ—¥æœŸ: {data_fetch_start_date}")

    raw_data = {
        s: fetch_binance_klines(
            s, CONFIG["interval"], data_fetch_start_date, CONFIG["backtest_end_date"]
        )
        for s in CONFIG["symbols_to_test"]
    }
    raw_data = {s: d for s, d in raw_data.items() if not d.empty}
    if not raw_data:
        logger.error("æ‰€æœ‰å“ç§æ•°æ®è·å–å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        exit()

    processed_backtest_data = {}
    for symbol, data in raw_data.items():
        logger.info(f"ä¸º {symbol} é¢„å¤„ç†å®Œæ•´æ—¶æ®µæ•°æ®...")
        full_processed_data = preprocess_data_for_strategy(data, symbol)
        backtest_period_slice = full_processed_data.loc[
            CONFIG["backtest_start_date"] : CONFIG["backtest_end_date"]
        ].copy()
        if not backtest_period_slice.empty:
            processed_backtest_data[symbol] = backtest_period_slice

    if not processed_backtest_data:
        logger.error("æ— å›æµ‹æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        exit()

    logger.info(f"### è¿›å…¥å›æµ‹æ¨¡å¼ ###")
    all_stats = {}
    for symbol, data in processed_backtest_data.items():
        print(f"\n{'='*80}\næ­£åœ¨å›æµ‹å“ç§: {symbol}\n{'='*80}")
        bt = Backtest(
            data,
            UltimateStrategy,
            cash=CONFIG["initial_cash"],
            commission=CONFIG["commission"],
            margin=CONFIG["spread"] / 2,
            finalize_trades=True,
        )
        stats = bt.run(symbol=symbol)
        all_stats[symbol] = stats
        print(f"\n{'-'*40}\n          {symbol} å›æµ‹ç»“æœæ‘˜è¦\n{'-'*40}")
        print(stats)
        if CONFIG["show_plots"]:
            bt.plot()

    if all_stats:
        initial_total = CONFIG["initial_cash"] * len(all_stats)
        total_equity = sum(stats["Equity Final [$]"] for stats in all_stats.values())
        ret = ((total_equity - initial_total) / initial_total) * 100
        print(f"\n{'#'*80}\n                 ç»„åˆç­–ç•¥è¡¨ç°æ€»è§ˆ\n{'#'*80}")
        for symbol, stats in all_stats.items():
            print(
                f"  - {symbol}:\n    - æœ€ç»ˆæƒç›Š: ${stats['Equity Final [$]']:,.2f} (å›æŠ¥ç‡: {stats['Return [%]']:.2f}%)\n    - æœ€å¤§å›æ’¤: {stats['Max. Drawdown [%]']:.2f}%\n    - å¤æ™®æ¯”ç‡: {stats.get('Sharpe Ratio', 'N/A')}"
            )
        print(
            f"\n--- æŠ•èµ„ç»„åˆæ•´ä½“è¡¨ç° ---\næ€»åˆå§‹èµ„é‡‘: ${initial_total:,.2f}\næ€»æœ€ç»ˆæƒç›Š: ${total_equity:,.2f}\nç»„åˆæ€»å›æŠ¥ç‡: {ret:.2f}%"
        )
