# -*- coding: utf-8 -*-
"""
Kronos V51.0 — XGBoost 核心版 (The Final Cut)
功能摘要：
- 终极简化: 完全移除 LSTM 模型和所有相关的 TensorFlow/Keras 依赖，使代码更轻量、更专注。
- 核心聚焦: 策略现在完全由表现更优的 XGBoost 模型驱动，消除了模型融合的复杂性。
- 代码清理: 删除了所有不再使用的函数、参数和逻辑，提高了代码的可读性和维护性。
- 这是我们共同调试和优化之旅的最终、最精炼的版本。
"""
import os
import sys
import time
import logging
import warnings
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import joblib
import requests
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

# ML libs - V51.0: Removed TensorFlow/Keras
try:
    import xgboost as xgb
    from sklearn.preprocessing import RobustScaler
    from sklearn.metrics import accuracy_score

    ML_LIBS = True
except Exception as e:
    ML_LIBS = False
    print("警告: 核心 ML 库 xgboost/scikit-learn 不可用。ML模块将被跳过。", e)

# Backtest libs
try:
    from backtesting import Backtest, Strategy
    from backtesting.lib import crossover
    import ta
except Exception as e:
    print("错误: 需要安装 backtesting 和 ta 库: pip install backtesting ta", e)
    raise

# Logging
warnings.filterwarnings("ignore")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# --- CONFIG ---
CONFIG = {
    "symbols_to_test": ["ETHUSDT"],
    "btc_symbol": "BTCUSDT",
    "interval": "5m",
    "backtest_start_date": "2025-07-01",
    "backtest_end_date": "2025-10-01",
    "initial_cash": 500_000,
    "commission": 0.001,
    "spread": 0.0005,
    "show_plots": True,
    "training_window_days": 180,
    "ml_training_gap_days": 90,
    "model_dir": "models",
    "data_cache": "data_cache",
    "enabled_modules": {
        "trend_following": True,
        "mean_reversion": True,
        "ml_filter": True,
    },
}

# --- STRATEGY_PARAMS ---
STRATEGY_PARAMS = {
    "regime_adx_period": 14,
    "regime_atr_period": 14,
    "regime_atr_slope_period": 5,
    "regime_rsi_period": 14,
    "regime_rsi_vol_period": 14,
    "regime_norm_period": 50,
    "regime_hurst_period": 20,
    "regime_score_weight_adx": 0.7,
    "regime_score_weight_atr": 0.2,
    "regime_score_weight_rsi": 0.05,
    "regime_score_weight_hurst": 0.05,
    "regime_score_threshold": 0.55,
    "tf_ema_fast_period": 12,
    "tf_atr_period": 14,
    "tf_chandelier_atr_multiplier": 3.0,
    "tf_stop_loss_atr_multiplier": 1.6,
    "mr_bb_period": 20,
    "mr_bb_std": 2.5,
    "mr_rsi_period": 14,
    "mr_rsi_oversold": 25,
    "mr_rsi_overbought": 75,
    "mr_stop_loss_atr_multiplier": 2.0,
    "mr_risk_multiplier": 0.8,
    "mr_take_profit_rr": 1.5,
    "ml_filter_enabled": True,
    "xgb_nrounds": 80,
    "xgb_gamma": 2.5,
    "xgb_lambda": 25.0,
    "xgb_alpha": 8.0,
    "ml_confidence_threshold": 0.75,
    "label_look_forward": 180,
    "label_risk_reward_ratio": 1.8,
    "label_sl_atr_multiplier_base": 1.5,
    "label_vol_window": 30,
    "label_vol_norm_window": 288,
    "kelly_trade_history": 20,
    "default_risk_pct": 0.015,
    "max_risk_pct": 0.04,
}
SELECTED_FEATURES = [
    "feature_taker_imbalance_10",
    "feature_rsi_14",
    "feature_atr_14_pct",
    "feature_bb_width",
    "feature_close_ma_200_ratio",
]


# --- (Utilities and Feature Engineering functions are unchanged) ---
def set_chinese_font():
    try:
        import matplotlib.font_manager as fm

        font_names = [
            "PingFang SC",
            "Microsoft YaHei",
            "SimHei",
            "Heiti TC",
            "Arial Unicode MS",
            "sans-serif",
        ]
        available = [f.name for f in fm.fontManager.ttflist]
        for font in font_names:
            if font in available:
                plt.rcParams["font.sans-serif"] = [font]
                plt.rcParams["axes.unicode_minus"] = False
                logger.info(f"设置中文字体: {font}")
                return
        logger.warning("未找到常见中文字体，绘图可能乱码。")
    except Exception:
        pass


def ensure_dirs():
    os.makedirs(CONFIG["data_cache"], exist_ok=True)
    os.makedirs(CONFIG["model_dir"], exist_ok=True)


def fetch_binance_klines(
    symbol, interval, start_str, end_str=None, limit=1000, cache_dir=None
):
    cache_dir = cache_dir or CONFIG["data_cache"]
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"{symbol}_{interval}.csv")
    start_dt, end_dt = pd.to_datetime(start_str, utc=True), (
        pd.to_datetime(end_str, utc=True)
        if end_str
        else datetime.utcnow().astimezone(pd.Timestamp.utcnow().tz)
    )
    if os.path.exists(cache_file):
        try:
            df = pd.read_csv(cache_file, index_col="timestamp", parse_dates=True)
            if (
                not df.empty
                and df.index[0] <= start_dt
                and df.index[-1] >= end_dt
                and "taker_buy_base_asset_volume" in df.columns
            ):
                logger.info(f"✅ 从有效缓存加载 {symbol} 数据: {cache_file}")
                return df.loc[start_dt:end_dt]
        except Exception as e:
            logger.warning(f"读取缓存文件失败: {e}, 将重新获取数据。")
    url = "https://api.binance.com/api/v3/klines"
    all_data, current_start_ts, end_ts = (
        [],
        int(start_dt.timestamp() * 1000),
        int(end_dt.timestamp() * 1000),
    )
    while current_start_ts < end_ts:
        params = {
            "symbol": symbol.upper(),
            "interval": interval,
            "startTime": current_start_ts,
            "endTime": end_ts,
            "limit": limit,
        }
        try:
            resp = requests.get(url, params=params, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            if not data:
                break
            all_data.extend(data)
            current_start_ts = data[-1][0] + 1
        except Exception as e:
            logger.warning(f"获取 {symbol} 数据失败: {e}. 等待 3s 重试...")
            time.sleep(3)
    if not all_data:
        logger.error(f"未能获取 {symbol} 的任何数据。")
        return pd.DataFrame()
    df = pd.DataFrame(
        all_data,
        columns=[
            "timestamp",
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "close_time",
            "quote_asset_volume",
            "number_of_trades",
            "taker_buy_base_asset_volume",
            "taker_buy_quote_asset_volume",
            "ignore",
        ],
    )
    df = df[
        [
            "timestamp",
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "taker_buy_base_asset_volume",
        ]
    ]
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
    for col in [
        "Open",
        "High",
        "Low",
        "Close",
        "Volume",
        "taker_buy_base_asset_volume",
    ]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df.drop_duplicates(subset=["timestamp"], inplace=True)
    df = df.set_index("timestamp").sort_index()
    df.to_csv(cache_file)
    logger.info(f"✅ {symbol} 数据已获取并缓存到: {cache_file}")
    return df.loc[start_dt:end_dt]


def safe_atr(high, low, close, window):
    try:
        if len(close) < int(window):
            return pd.Series([np.nan] * len(close), index=close.index)
        return ta.volatility.AverageTrueRange(
            high, low, close, window
        ).average_true_range()
    except Exception:
        return pd.Series([np.nan] * len(close), index=close.index)


def compute_hurst(ts, max_lag=100):
    if len(ts) < 10:
        return 0.5
    lags, tau = range(2, min(max_lag, len(ts) // 2 + 1)), []
    for lag in lags:
        std = np.std(np.subtract(ts[lag:], ts[:-lag]))
        if std > 0:
            tau.append(std)
    if len(tau) < 2:
        return 0.5
    try:
        return max(
            0.0, min(1.0, np.polyfit(np.log(lags[: len(tau)]), np.log(tau), 1)[0])
        )
    except Exception:
        return 0.5


def calculate_mtf_signal(raw_data: pd.DataFrame) -> pd.Series:
    logger.info("独立计算 MTF 信号...")
    df_1d = raw_data.resample("1D").agg({"Close": "last"}).dropna()
    if df_1d.empty:
        return pd.Series(0, index=raw_data.index)
    sma_daily = ta.trend.SMAIndicator(df_1d["Close"], window=50).sma_indicator()
    daily_signal = pd.Series(
        np.where(df_1d["Close"] > sma_daily, 1, -1), index=df_1d.index
    )
    return daily_signal.reindex(raw_data.index, method="ffill").fillna(0)


def add_all_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    p = STRATEGY_PARAMS
    adx = ta.trend.ADXIndicator(df.High, df.Low, df.Close, p["regime_adx_period"]).adx()
    atr = safe_atr(df.High, df.Low, df.Close, p["regime_atr_period"])
    rsi = ta.momentum.RSIIndicator(df.Close, p["regime_rsi_period"]).rsi()
    norm = lambda s: (
        (s - s.rolling(p["regime_norm_period"]).min())
        / (
            s.rolling(p["regime_norm_period"]).max()
            - s.rolling(p["regime_norm_period"]).min()
        )
    ).fillna(0.5)
    df["regime_adx_norm"] = norm(adx)
    df["regime_atr_slope_norm"] = norm(
        (atr - atr.shift(p["regime_atr_slope_period"]))
        / (atr.shift(p["regime_atr_slope_period"]) + 1e-9)
    )
    df["regime_rsi_vol_norm"] = 1 - norm(rsi.rolling(p["regime_rsi_vol_period"]).std())
    df["regime_hurst"] = (
        df.Close.rolling(p["regime_hurst_period"])
        .apply(lambda x: compute_hurst(np.log(x + 1e-9)), raw=False)
        .fillna(0.5)
    )
    df["regime_score"] = (
        df["regime_adx_norm"] * p["regime_score_weight_adx"]
        + df["regime_atr_slope_norm"] * p["regime_score_weight_atr"]
        + df["regime_rsi_vol_norm"] * p["regime_score_weight_rsi"]
        + np.clip((df["regime_hurst"] - 0.3) / 0.7, 0, 1)
        * p["regime_score_weight_hurst"]
    )
    df["market_regime"] = np.where(
        df["regime_score"] > p["regime_score_threshold"], 1, -1
    )
    if "mtf_signal" not in df.columns:
        raise ValueError("致命错误: 'mtf_signal' 未在传入的 DataFrame 中找到。")
    df["feature_rsi_14"] = ta.momentum.RSIIndicator(df.Close, 14).rsi()
    df["feature_atr_14_pct"] = safe_atr(df.High, df.Low, df.Close, 14) / (
        df.Close + 1e-9
    )
    bb = ta.volatility.BollingerBands(df.Close, 20)
    df["feature_bb_width"] = (bb.bollinger_hband() - bb.bollinger_lband()) / (
        df.Close + 1e-9
    )
    df["feature_close_ma_200_ratio"] = df.Close / (
        ta.trend.EMAIndicator(df.Close, 200).ema_indicator() + 1e-9
    )
    if "taker_buy_base_asset_volume" not in df.columns:
        raise ValueError(
            "致命错误: 数据中缺少 'taker_buy_base_asset_volume' 列。请删除 'data_cache' 文件夹并重新运行。"
        )
    taker_sell_volume = df["Volume"] - df["taker_buy_base_asset_volume"]
    imbalance = (
        df["taker_buy_base_asset_volume"].rolling(10).sum()
        - taker_sell_volume.rolling(10).sum()
    )
    total_volume = df["Volume"].rolling(10).sum()
    df["feature_taker_imbalance_10"] = (imbalance / (total_volume + 1e-9)).fillna(0)
    df.dropna(inplace=True)
    return df


def make_asymmetric_labels(df: pd.DataFrame) -> pd.Series:
    p = STRATEGY_PARAMS
    if df.empty:
        return pd.Series(dtype=float)
    atr = safe_atr(df.High, df.Low, df.Close, 14)
    vol = df.Close.rolling(p["label_vol_window"]).std()
    expanding_min = vol.expanding(min_periods=p["label_vol_norm_window"]).min()
    expanding_max = vol.expanding(min_periods=p["label_vol_norm_window"]).max()
    vol_norm = (vol - expanding_min) / (expanding_max - expanding_min)
    vol_norm = vol_norm.fillna(0.5)
    dynamic_sl_mult = p["label_sl_atr_multiplier_base"] * (1 + vol_norm)
    upper_barrier, lower_barrier = df.Close + (
        atr * dynamic_sl_mult * p["label_risk_reward_ratio"]
    ), df.Close - (atr * dynamic_sl_mult)
    labels = pd.Series(np.nan, index=df.index)
    interval_minutes = int("".join(filter(str.isdigit, CONFIG.get("interval", "1m"))))
    look_forward_bars = int(p["label_look_forward"] / max(1, interval_minutes))
    for i in range(len(df) - look_forward_bars):
        entry_idx = df.index[i]
        path = df.iloc[i + 1 : i + 1 + look_forward_bars]
        if path.empty:
            continue
        up_b, low_b = upper_barrier.loc[entry_idx], lower_barrier.loc[entry_idx]
        if not (np.isfinite(up_b) and np.isfinite(low_b)):
            continue
        upper_touch, lower_touch = (
            path[path.High >= up_b].index.min(),
            path[path.Low <= low_b].index.min(),
        )
        if pd.notna(upper_touch) and pd.notna(lower_touch):
            labels.loc[entry_idx] = 1 if upper_touch <= lower_touch else 0
        elif pd.notna(upper_touch):
            labels.loc[entry_idx] = 1
        elif pd.notna(lower_touch):
            labels.loc[entry_idx] = 0
    return labels


def safe_load_scaler(path, expected_dim):
    if not os.path.exists(path):
        return RobustScaler()
    try:
        scaler = joblib.load(path)
        if hasattr(scaler, "scale_") and len(scaler.scale_) != expected_dim:
            logger.warning(
                f"Scaler 维度不匹配: {len(scaler.scale_)} != {expected_dim}. 将重建 scaler。"
            )
            return RobustScaler()
        return scaler
    except Exception as e:
        logger.warning(f"加载 scaler 失败 ({e})，将创建新 scaler。")
        return RobustScaler()


def train_and_save_xgb(training_df, symbol):
    logger.info(f"[XGB] 为 {symbol} 训练 XGBoost...")
    split = int(len(training_df) * 0.8)
    train_df, test_df = training_df.iloc[:split].copy(), training_df.iloc[split:].copy()
    labels_train, labels_test = make_asymmetric_labels(
        train_df
    ), make_asymmetric_labels(test_df)
    df_train, df_test = train_df.join(labels_train.rename("target")).dropna(
        subset=["target"]
    ), test_df.join(labels_test.rename("target")).dropna(subset=["target"])
    if df_train.empty or df_test.empty:
        logger.warning(f"[{symbol}] XGB: 标签不足，跳过。")
        return None
    df_train.loc[:, "target"], df_test.loc[:, "target"] = df_train["target"].astype(
        int
    ), df_test["target"].astype(int)
    features = SELECTED_FEATURES
    X_train_df, y_train = df_train[features], df_train["target"].values
    X_test_df, y_test = df_test[features], df_test["target"].values
    scaler_path = os.path.join(CONFIG["model_dir"], f"xgb_scaler_{symbol}.pkl")
    scaler = safe_load_scaler(scaler_path, X_train_df.shape[1])
    scaler.fit(X_train_df)
    X_train_s, X_test_s = scaler.transform(X_train_df), scaler.transform(X_test_df)
    joblib.dump(scaler, scaler_path)
    model = xgb.XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        use_label_encoder=False,
        n_estimators=STRATEGY_PARAMS["xgb_nrounds"],
        learning_rate=0.02,
        max_depth=2,
        subsample=0.5,
        colsample_bytree=0.5,
        gamma=STRATEGY_PARAMS.get("xgb_gamma", 2.0),
        reg_lambda=STRATEGY_PARAMS.get("xgb_lambda", 20.0),
        reg_alpha=STRATEGY_PARAMS.get("xgb_alpha", 5.0),
        min_child_weight=10,
        random_state=42,
        verbosity=0,
    )
    model.fit(X_train_s, y_train)
    acc = accuracy_score(y_test, model.predict(X_test_s))
    logger.info(f"[XGB] {symbol} OOS acc={acc:.4f}")
    joblib.dump(model, os.path.join(CONFIG["model_dir"], f"xgb_model_{symbol}.joblib"))
    return acc


# --- Strategy Class ---
def analyze_trade_distribution(trades_df, filename="trade_dist_v51.0.png"):
    if trades_df.empty:
        logger.info("无交易，跳过交易分布图。")
        return
    plt.style.use("seaborn-v0_8-darkgrid")
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.hist(
        [
            trades_df["PnL"][trades_df["PnL"] < 0],
            trades_df["PnL"][trades_df["PnL"] > 0],
        ],
        bins=50,
        label=["losses", "wins"],
        stacked=True,
        color=["#FF5733", "#33C1FF"],
    )
    ax.set_title("Trade PnL Distribution")
    ax.legend()
    plt.savefig(filename)
    plt.close(fig)
    logger.info(f"保存交易分布: {filename}")


class UltimateStrategy(Strategy):
    symbol = None
    enabled_modules = {}

    def init(self, **kwargs):
        self.symbol = kwargs.get("symbol", None) or getattr(self, "symbol", None)
        for k, v in STRATEGY_PARAMS.items():
            setattr(self, k, v)
        self.vol_weight = getattr(self, "vol_weight", 1.0)
        self.enabled_modules = CONFIG.get("enabled_modules", {})
        c, h, l = (
            pd.Series(self.data.Close),
            pd.Series(self.data.High),
            pd.Series(self.data.Low),
        )
        self.market_regime = self.I(
            lambda: getattr(self.data, "market_regime", pd.Series([0] * len(self.data)))
        )
        self.mtf_signal = self.I(
            lambda: getattr(self.data, "mtf_signal", pd.Series([0] * len(self.data)))
        )
        self.tf_ema_fast = self.I(
            lambda: ta.trend.EMAIndicator(c, self.tf_ema_fast_period).ema_indicator(),
            plot=False,
        )
        self.tf_atr = self.I(lambda: safe_atr(h, l, c, self.tf_atr_period), plot=False)
        bb = ta.volatility.BollingerBands(c, self.mr_bb_period, self.mr_bb_std)
        self.mr_bb_upper, self.mr_bb_lower = self.I(
            lambda: bb.bollinger_hband()
        ), self.I(lambda: bb.bollinger_lband())
        self.mr_rsi = self.I(
            lambda: ta.momentum.RSIIndicator(c, self.mr_rsi_period).rsi(), plot=False
        )
        self.reset_trade_state()
        self.xgb, self.xgb_scaler = None, None
        try:
            self.xgb = joblib.load(
                os.path.join(CONFIG["model_dir"], f"xgb_model_{self.symbol}.joblib")
            )
            logger.info(f"[{self.symbol}] XGB 模型加载成功。")
        except:
            logger.debug(f"[{self.symbol}] 无 XGB 模型。")
        try:
            self.xgb_scaler = joblib.load(
                os.path.join(CONFIG["model_dir"], f"xgb_scaler_{self.symbol}.pkl")
            )
        except:
            self.xgb_scaler = None

    def next(self):
        if len(self.data) < max(self.regime_norm_period, 50):
            return
        if self.position:
            self.manage_open_position(self.data.Close[-1])
        else:
            regime = (
                self.market_regime[-1] if "market_regime" in self.data.df.columns else 1
            )
            if regime == 1 and self.enabled_modules.get("trend_following", False):
                self.run_scoring_system_entry(self.data.Close[-1])
            elif regime == -1 and self.enabled_modules.get("mean_reversion", False):
                self.run_mean_reversion_entry(self.data.Close[-1])

    def run_scoring_system_entry(self, price):
        if not all([self.xgb, self.xgb_scaler]):
            return
        current_features_df = self.data.df[SELECTED_FEATURES].iloc[-1:].copy()
        if current_features_df.isna().any().any():
            return
        scaled_features = self.xgb_scaler.transform(current_features_df)
        prob_xgb = float(self.xgb.predict_proba(scaled_features)[0, 1])
        is_long_safe, is_short_safe = (
            price > self.tf_ema_fast[-1],
            price < self.tf_ema_fast[-1],
        )
        if (
            self.mtf_signal[-1] == 1
            and prob_xgb > self.ml_confidence_threshold
            and is_long_safe
        ):
            self.open_tf_position(price, is_long=True, confidence_factor=1.0)
        elif (
            self.mtf_signal[-1] == -1
            and (1 - prob_xgb) > self.ml_confidence_threshold
            and is_short_safe
        ):
            self.open_tf_position(price, is_long=False, confidence_factor=1.0)

    def run_mean_reversion_entry(self, price):
        m = self
        is_long = (
            crossover(m.data.Close, m.mr_bb_lower) and m.mr_rsi[-1] < m.mr_rsi_oversold
        )
        is_short = (
            crossover(m.mr_bb_upper, m.data.Close)
            and m.mr_rsi[-1] > m.mr_rsi_overbought
        )
        if is_long:
            self.open_mr_position(price, True)
        elif is_short:
            self.open_mr_position(price, False)

    def open_mr_position(self, price, is_long):
        risk_per_share = (
            self.tf_atr[-1] * self.mr_stop_loss_atr_multiplier
            if np.isfinite(self.tf_atr[-1])
            else 0
        )
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price,
            risk_per_share,
            self._calculate_dynamic_risk() * self.mr_risk_multiplier,
        )
        if size <= 0:
            return
        self.reset_trade_state()
        self.active_sub_strategy = "MR"
        if is_long:
            self.buy(size=size)
            self.mr_stop_loss = price - risk_per_share
            self.mr_take_profit = price + risk_per_share * self.mr_take_profit_rr
        else:
            self.sell(size=size)
            self.mr_stop_loss = price + risk_per_share
            self.mr_take_profit = price - risk_per_share * self.mr_take_profit_rr

    def manage_mean_reversion_exit(self, price):
        if (
            self.position.is_long
            and (price >= self.mr_take_profit or price <= self.mr_stop_loss)
        ) or (
            self.position.is_short
            and (price <= self.mr_take_profit or price >= self.mr_stop_loss)
        ):
            self.close_position("MR_Exit_TP_SL")

    def reset_trade_state(self):
        (
            self.active_sub_strategy,
            self.chandelier_exit_level,
            self.highest_high_in_trade,
            self.lowest_low_in_trade,
            self.mr_stop_loss,
            self.mr_take_profit,
            self.tf_initial_stop_loss,
        ) = (None, 0.0, 0.0, float("inf"), 0.0, 0.0, 0.0)

    def manage_open_position(self, price):
        if self.active_sub_strategy == "TF":
            self.manage_trend_following_exit(price)
        elif self.active_sub_strategy == "MR":
            self.manage_mean_reversion_exit(price)

    def open_tf_position(self, price, is_long, confidence_factor):
        atr = self.tf_atr[-1]
        risk_per_share = (
            atr * self.tf_stop_loss_atr_multiplier if atr and np.isfinite(atr) else 0
        )
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price, risk_per_share, self._calculate_dynamic_risk() * confidence_factor
        )
        if size <= 0:
            return
        self.reset_trade_state()
        self.active_sub_strategy = "TF"
        if is_long:
            self.buy(size=size)
            self.tf_initial_stop_loss = price - risk_per_share
            self.highest_high_in_trade = self.data.High[-1]
        else:
            self.sell(size=size)
            self.tf_initial_stop_loss = price + risk_per_share
            self.lowest_low_in_trade = self.data.Low[-1]

    def manage_trend_following_exit(self, price):
        atr = self.tf_atr[-1]
        if self.position.is_long:
            if price < self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.highest_high_in_trade = max(
                self.highest_high_in_trade, self.data.High[-1]
            )
            self.chandelier_exit_level = (
                self.highest_high_in_trade - atr * self.tf_chandelier_atr_multiplier
            )
            if price < self.chandelier_exit_level:
                self.close_position("TF_Chandelier")
        else:
            if price > self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.lowest_low_in_trade = min(self.lowest_low_in_trade, self.data.Low[-1])
            self.chandelier_exit_level = (
                self.lowest_low_in_trade + atr * self.tf_chandelier_atr_multiplier
            )
            if price > self.chandelier_exit_level:
                self.close_position("TF_Chandelier")

    def close_position(self, reason: str):
        try:
            self.position.close()
        except:
            pass
        self.reset_trade_state()

    def _calculate_position_size(self, price, risk_per_unit, risk_pct):
        if risk_per_unit <= 0 or price <= 0:
            return 0
        cash_at_risk = risk_pct * self.equity
        pos_size_quote = cash_at_risk / (risk_per_unit / price)
        return min(pos_size_quote / self.equity, 0.99)

    def _calculate_dynamic_risk(self):
        trades = self.closed_trades
        if len(trades) < self.kelly_trade_history:
            return self.default_risk_pct * self.vol_weight
        recent, returns = trades[-self.kelly_trade_history :], [
            t.pl_pct for t in trades[-self.kelly_trade_history :]
        ]
        wins, losses = [r for r in returns if r > 0], [r for r in returns if r < 0]
        if not wins or not losses:
            return self.default_risk_pct * self.vol_weight
        win_rate, avg_win, avg_loss = (
            len(wins) / len(recent),
            sum(wins) / len(wins),
            abs(sum(losses) / len(losses)),
        )
        if avg_loss == 0:
            return self.max_risk_pct
        reward_ratio = avg_win / avg_loss
        if reward_ratio == 0:
            return self.default_risk_pct * self.vol_weight
        kelly = win_rate - (1 - win_rate) / reward_ratio
        return min(max(0.005, kelly * 0.5) * self.vol_weight, self.max_risk_pct)


# --- Main Execution Logic ---
def main():
    set_chinese_font()
    ensure_dirs()
    backtest_start_dt = pd.to_datetime(CONFIG["backtest_start_date"], utc=True)
    backtest_end_dt = pd.to_datetime(CONFIG["backtest_end_date"], utc=True)
    if "training_window_days" not in CONFIG:
        logger.error("CONFIG 中缺少 'training_window_days'")
        return
    training_window = timedelta(days=CONFIG["training_window_days"])
    first_training_start = (
        backtest_start_dt
        - timedelta(days=CONFIG["ml_training_gap_days"])
        - training_window
    )
    overall_start_date = first_training_start
    mtf_warmup_days = 60
    data_fetch_start_date = overall_start_date - timedelta(days=mtf_warmup_days)
    logger.info(
        f"数据获取总时间段: {data_fetch_start_date.date()} -> {backtest_end_dt.date()} (包含 {mtf_warmup_days} 天 MTF 预热)"
    )
    logger.info(f"有效训练/回测开始于: {overall_start_date.date()}")

    symbol = CONFIG["symbols_to_test"][0]
    btc_data_raw = fetch_binance_klines(
        CONFIG["btc_symbol"],
        CONFIG["interval"],
        data_fetch_start_date,
        backtest_end_dt,
        cache_dir=CONFIG["data_cache"],
    )
    symbol_data_raw = fetch_binance_klines(
        symbol,
        CONFIG["interval"],
        data_fetch_start_date,
        backtest_end_dt,
        cache_dir=CONFIG["data_cache"],
    )
    if symbol_data_raw.empty:
        logger.error(f"{symbol} 数据为空，退出。")
        return

    mtf_series = calculate_mtf_signal(btc_data_raw)
    symbol_data_raw["mtf_signal"] = mtf_series
    symbol_data_effective = symbol_data_raw.loc[overall_start_date:].copy()

    logger.info(f"为有效数据 (从 {overall_start_date.date()} 开始) 添加特征...")
    featured_data = add_all_features(symbol_data_effective)

    logger.info(
        "\n"
        + "#" * 80
        + "\n                 模式: 单次训练与回测 (XGBoost Only)\n"
        + "#" * 80
    )
    training_end_dt = backtest_start_dt - timedelta(days=CONFIG["ml_training_gap_days"])
    logger.info(
        f"训练期: {featured_data.index.min().date()} -> {training_end_dt.date()}"
    )
    training_slice = featured_data.loc[:training_end_dt]

    if (
        STRATEGY_PARAMS["ml_filter_enabled"]
        and CONFIG["enabled_modules"].get("ml_filter", False)
        and ML_LIBS
    ):
        if len(training_slice) > 1000:
            train_and_save_xgb(training_slice, symbol)
        else:
            logger.warning(f"[{symbol}] 训练数据不足，跳过本次训练。")

    logger.info(f"回测期: {backtest_start_dt.date()} -> {backtest_end_dt.date()}")
    backtest_slice = (
        featured_data.loc[backtest_start_dt:backtest_end_dt].copy().dropna()
    )
    if backtest_slice.empty:
        logger.error("回测周期内数据为空，退出。")
        return

    bt = Backtest(
        backtest_slice,
        UltimateStrategy,
        cash=CONFIG["initial_cash"],
        commission=CONFIG["commission"],
        finalize_trades=True,
    )
    try:
        stats = bt.run(symbol=symbol)
        logger.info("回测完成，生成最终报告...")
        print(stats)
        if "_trades" in stats and not stats["_trades"].empty:
            logger.info(
                "\n" + "#" * 80 + "\n                 回测表现总览\n" + "#" * 80
            )
            logger.info(f"初始资金: ${CONFIG['initial_cash']:,.2f}")
            logger.info(f"最终权益: ${stats['Equity Final [$]']:,.2f}")
            logger.info(f"总回报率: {stats['Return [%]']:.2f}%")
            logger.info(f"总交易次数: {stats['# Trades']}")
            logger.info(f"胜率: {stats['Win Rate [%]']:.2f}%")
            logger.info(f"盈亏因子: {stats['Profit Factor']:.2f}")
            if CONFIG["show_plots"]:
                bt.plot(filename="backtest_v51.0.html", open_browser=False)
                logger.info("保存详细回测图: backtest_v51.0.html")
                analyze_trade_distribution(
                    stats["_trades"], filename="trade_dist_v51.0.png"
                )
        else:
            logger.info("整个回测期间没有产生任何交易。")
    except Exception as e:
        logger.error(f"回测期间出现严重错误: {e}", exc_info=True)

    logger.info("🚀 V51.0 运行结束。")


if __name__ == "__main__":
    main()


(kronos)  ~/work/conda/Kronos/ [main*] python gpt1.py 
2025-10-21 12:40:24 [INFO] 设置中文字体: Heiti TC
2025-10-21 12:40:24 [INFO] 数据获取总时间段: 2024-08-05 -> 2025-10-01 (包含 60 天 MTF 预热)
2025-10-21 12:40:24 [INFO] 有效训练/回测开始于: 2024-10-04
2025-10-21 12:40:24 [INFO] ✅ 从有效缓存加载 BTCUSDT 数据: data_cache/BTCUSDT_5m.csv
2025-10-21 12:40:24 [INFO] ✅ 从有效缓存加载 ETHUSDT 数据: data_cache/ETHUSDT_5m.csv
2025-10-21 12:40:24 [INFO] 独立计算 MTF 信号...
2025-10-21 12:40:24 [INFO] 为有效数据 (从 2024-10-04 开始) 添加特征...
2025-10-21 12:43:01 [INFO] 
################################################################################
                 模式: 单次训练与回测 (XGBoost Only)
################################################################################
2025-10-21 12:43:01 [INFO] 训练期: 2024-10-04 -> 2025-04-02
2025-10-21 12:43:01 [INFO] [XGB] 为 ETHUSDT 训练 XGBoost...
2025-10-21 12:43:13 [INFO] [XGB] ETHUSDT OOS acc=0.6644
2025-10-21 12:43:13 [INFO] 回测期: 2025-07-01 -> 2025-10-01
2025-10-21 12:43:13 [INFO] [ETHUSDT] XGB 模型加载成功。
2025-10-21 12:43:20 [INFO] 回测完成，生成最终报告...                       
Start                     2025-07-01 00:00...
End                       2025-10-01 00:00...
Duration                     92 days 00:00:00
Exposure Time [%]                     2.50594
Equity Final [$]                 485011.58747
Equity Peak [$]                      500000.0
Commissions [$]                    4834.98253
Return [%]                           -2.99768
Buy & Hold Return [%]                 66.2659
Return (Ann.) [%]                    -11.2592
Volatility (Ann.) [%]                 4.39029
CAGR [%]                            -11.37434
Sharpe Ratio                         -2.56457
Sortino Ratio                        -2.50392
Calmar Ratio                         -2.22808
Alpha [%]                            -3.66669
Beta                                   0.0101
Max. Drawdown [%]                    -5.05332
Avg. Drawdown [%]                    -5.05332
Max. Drawdown Duration       83 days 05:45:00
Avg. Drawdown Duration       83 days 05:45:00
# Trades                                    5
Win Rate [%]                             20.0
Best Trade [%]                        1.42437
Worst Trade [%]                      -1.48333
Avg. Trade [%]                       -0.61461
Max. Trade Duration           1 days 03:00:00
Avg. Trade Duration           0 days 10:59:00
Profit Factor                         0.31864
Expectancy [%]                       -0.60915
SQN                                  -1.20231
Kelly Criterion                      -0.44824
_strategy                 UltimateStrategy...
_equity_curve                             ...
_trades                      Size  EntryBa...
dtype: object
2025-10-21 12:43:20 [INFO] 
################################################################################
                 回测表现总览
################################################################################
2025-10-21 12:43:20 [INFO] 初始资金: $500,000.00
2025-10-21 12:43:20 [INFO] 最终权益: $485,011.59
2025-10-21 12:43:20 [INFO] 总回报率: -3.00%
2025-10-21 12:43:20 [INFO] 总交易次数: 5
2025-10-21 12:43:20 [INFO] 胜率: 20.00%
2025-10-21 12:43:20 [INFO] 盈亏因子: 0.32
2025-10-21 12:43:22 [INFO] 保存详细回测图: backtest_v51.0.html
2025-10-21 12:43:22 [INFO] 保存交易分布: trade_dist_v51.0.png
2025-10-21 12:43:22 [INFO] 🚀 V51.0 运行结束。
(kronos)  ~/work/conda/Kronos/ [main*] 