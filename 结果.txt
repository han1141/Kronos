# -*- coding: utf-8 -*-
"""
Kronos V51.0 â€” XGBoost æ ¸å¿ƒç‰ˆ (The Final Cut)
åŠŸèƒ½æ‘˜è¦ï¼š
- ç»ˆæç®€åŒ–: å®Œå…¨ç§»é™¤ LSTM æ¨¡å‹å’Œæ‰€æœ‰ç›¸å…³çš„ TensorFlow/Keras ä¾èµ–ï¼Œä½¿ä»£ç æ›´è½»é‡ã€æ›´ä¸“æ³¨ã€‚
- æ ¸å¿ƒèšç„¦: ç­–ç•¥ç°åœ¨å®Œå…¨ç”±è¡¨ç°æ›´ä¼˜çš„ XGBoost æ¨¡å‹é©±åŠ¨ï¼Œæ¶ˆé™¤äº†æ¨¡å‹èåˆçš„å¤æ‚æ€§ã€‚
- ä»£ç æ¸…ç†: åˆ é™¤äº†æ‰€æœ‰ä¸å†ä½¿ç”¨çš„å‡½æ•°ã€å‚æ•°å’Œé€»è¾‘ï¼Œæé«˜äº†ä»£ç çš„å¯è¯»æ€§å’Œç»´æŠ¤æ€§ã€‚
- è¿™æ˜¯æˆ‘ä»¬å…±åŒè°ƒè¯•å’Œä¼˜åŒ–ä¹‹æ—…çš„æœ€ç»ˆã€æœ€ç²¾ç‚¼çš„ç‰ˆæœ¬ã€‚
"""
import os
import sys
import time
import logging
import warnings
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import joblib
import requests
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

# ML libs - V51.0: Removed TensorFlow/Keras
try:
    import xgboost as xgb
    from sklearn.preprocessing import RobustScaler
    from sklearn.metrics import accuracy_score

    ML_LIBS = True
except Exception as e:
    ML_LIBS = False
    print("è­¦å‘Š: æ ¸å¿ƒ ML åº“ xgboost/scikit-learn ä¸å¯ç”¨ã€‚MLæ¨¡å—å°†è¢«è·³è¿‡ã€‚", e)

# Backtest libs
try:
    from backtesting import Backtest, Strategy
    from backtesting.lib import crossover
    import ta
except Exception as e:
    print("é”™è¯¯: éœ€è¦å®‰è£… backtesting å’Œ ta åº“: pip install backtesting ta", e)
    raise

# Logging
warnings.filterwarnings("ignore")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# --- CONFIG ---
CONFIG = {
    "symbols_to_test": ["ETHUSDT"],
    "btc_symbol": "BTCUSDT",
    "interval": "5m",
    "backtest_start_date": "2025-07-01",
    "backtest_end_date": "2025-10-01",
    "initial_cash": 500_000,
    "commission": 0.001,
    "spread": 0.0005,
    "show_plots": True,
    "training_window_days": 180,
    "ml_training_gap_days": 90,
    "model_dir": "models",
    "data_cache": "data_cache",
    "enabled_modules": {
        "trend_following": True,
        "mean_reversion": True,
        "ml_filter": True,
    },
}

# --- STRATEGY_PARAMS ---
STRATEGY_PARAMS = {
    "regime_adx_period": 14,
    "regime_atr_period": 14,
    "regime_atr_slope_period": 5,
    "regime_rsi_period": 14,
    "regime_rsi_vol_period": 14,
    "regime_norm_period": 50,
    "regime_hurst_period": 20,
    "regime_score_weight_adx": 0.7,
    "regime_score_weight_atr": 0.2,
    "regime_score_weight_rsi": 0.05,
    "regime_score_weight_hurst": 0.05,
    "regime_score_threshold": 0.55,
    "tf_ema_fast_period": 12,
    "tf_atr_period": 14,
    "tf_chandelier_atr_multiplier": 3.0,
    "tf_stop_loss_atr_multiplier": 1.6,
    "mr_bb_period": 20,
    "mr_bb_std": 2.5,
    "mr_rsi_period": 14,
    "mr_rsi_oversold": 25,
    "mr_rsi_overbought": 75,
    "mr_stop_loss_atr_multiplier": 2.0,
    "mr_risk_multiplier": 0.8,
    "mr_take_profit_rr": 1.5,
    "ml_filter_enabled": True,
    "xgb_nrounds": 80,
    "xgb_gamma": 2.5,
    "xgb_lambda": 25.0,
    "xgb_alpha": 8.0,
    "ml_confidence_threshold": 0.75,
    "label_look_forward": 180,
    "label_risk_reward_ratio": 1.8,
    "label_sl_atr_multiplier_base": 1.5,
    "label_vol_window": 30,
    "label_vol_norm_window": 288,
    "kelly_trade_history": 20,
    "default_risk_pct": 0.015,
    "max_risk_pct": 0.04,
}
SELECTED_FEATURES = [
    "feature_taker_imbalance_10",
    "feature_rsi_14",
    "feature_atr_14_pct",
    "feature_bb_width",
    "feature_close_ma_200_ratio",
]


# --- (Utilities and Feature Engineering functions are unchanged) ---
def set_chinese_font():
    try:
        import matplotlib.font_manager as fm

        font_names = [
            "PingFang SC",
            "Microsoft YaHei",
            "SimHei",
            "Heiti TC",
            "Arial Unicode MS",
            "sans-serif",
        ]
        available = [f.name for f in fm.fontManager.ttflist]
        for font in font_names:
            if font in available:
                plt.rcParams["font.sans-serif"] = [font]
                plt.rcParams["axes.unicode_minus"] = False
                logger.info(f"è®¾ç½®ä¸­æ–‡å­—ä½“: {font}")
                return
        logger.warning("æœªæ‰¾åˆ°å¸¸è§ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾å¯èƒ½ä¹±ç ã€‚")
    except Exception:
        pass


def ensure_dirs():
    os.makedirs(CONFIG["data_cache"], exist_ok=True)
    os.makedirs(CONFIG["model_dir"], exist_ok=True)


def fetch_binance_klines(
    symbol, interval, start_str, end_str=None, limit=1000, cache_dir=None
):
    cache_dir = cache_dir or CONFIG["data_cache"]
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"{symbol}_{interval}.csv")
    start_dt, end_dt = pd.to_datetime(start_str, utc=True), (
        pd.to_datetime(end_str, utc=True)
        if end_str
        else datetime.utcnow().astimezone(pd.Timestamp.utcnow().tz)
    )
    if os.path.exists(cache_file):
        try:
            df = pd.read_csv(cache_file, index_col="timestamp", parse_dates=True)
            if (
                not df.empty
                and df.index[0] <= start_dt
                and df.index[-1] >= end_dt
                and "taker_buy_base_asset_volume" in df.columns
            ):
                logger.info(f"âœ… ä»æœ‰æ•ˆç¼“å­˜åŠ è½½ {symbol} æ•°æ®: {cache_file}")
                return df.loc[start_dt:end_dt]
        except Exception as e:
            logger.warning(f"è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}, å°†é‡æ–°è·å–æ•°æ®ã€‚")
    url = "https://api.binance.com/api/v3/klines"
    all_data, current_start_ts, end_ts = (
        [],
        int(start_dt.timestamp() * 1000),
        int(end_dt.timestamp() * 1000),
    )
    while current_start_ts < end_ts:
        params = {
            "symbol": symbol.upper(),
            "interval": interval,
            "startTime": current_start_ts,
            "endTime": end_ts,
            "limit": limit,
        }
        try:
            resp = requests.get(url, params=params, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            if not data:
                break
            all_data.extend(data)
            current_start_ts = data[-1][0] + 1
        except Exception as e:
            logger.warning(f"è·å– {symbol} æ•°æ®å¤±è´¥: {e}. ç­‰å¾… 3s é‡è¯•...")
            time.sleep(3)
    if not all_data:
        logger.error(f"æœªèƒ½è·å– {symbol} çš„ä»»ä½•æ•°æ®ã€‚")
        return pd.DataFrame()
    df = pd.DataFrame(
        all_data,
        columns=[
            "timestamp",
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "close_time",
            "quote_asset_volume",
            "number_of_trades",
            "taker_buy_base_asset_volume",
            "taker_buy_quote_asset_volume",
            "ignore",
        ],
    )
    df = df[
        [
            "timestamp",
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "taker_buy_base_asset_volume",
        ]
    ]
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
    for col in [
        "Open",
        "High",
        "Low",
        "Close",
        "Volume",
        "taker_buy_base_asset_volume",
    ]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df.drop_duplicates(subset=["timestamp"], inplace=True)
    df = df.set_index("timestamp").sort_index()
    df.to_csv(cache_file)
    logger.info(f"âœ… {symbol} æ•°æ®å·²è·å–å¹¶ç¼“å­˜åˆ°: {cache_file}")
    return df.loc[start_dt:end_dt]


def safe_atr(high, low, close, window):
    try:
        if len(close) < int(window):
            return pd.Series([np.nan] * len(close), index=close.index)
        return ta.volatility.AverageTrueRange(
            high, low, close, window
        ).average_true_range()
    except Exception:
        return pd.Series([np.nan] * len(close), index=close.index)


def compute_hurst(ts, max_lag=100):
    if len(ts) < 10:
        return 0.5
    lags, tau = range(2, min(max_lag, len(ts) // 2 + 1)), []
    for lag in lags:
        std = np.std(np.subtract(ts[lag:], ts[:-lag]))
        if std > 0:
            tau.append(std)
    if len(tau) < 2:
        return 0.5
    try:
        return max(
            0.0, min(1.0, np.polyfit(np.log(lags[: len(tau)]), np.log(tau), 1)[0])
        )
    except Exception:
        return 0.5


def calculate_mtf_signal(raw_data: pd.DataFrame) -> pd.Series:
    logger.info("ç‹¬ç«‹è®¡ç®— MTF ä¿¡å·...")
    df_1d = raw_data.resample("1D").agg({"Close": "last"}).dropna()
    if df_1d.empty:
        return pd.Series(0, index=raw_data.index)
    sma_daily = ta.trend.SMAIndicator(df_1d["Close"], window=50).sma_indicator()
    daily_signal = pd.Series(
        np.where(df_1d["Close"] > sma_daily, 1, -1), index=df_1d.index
    )
    return daily_signal.reindex(raw_data.index, method="ffill").fillna(0)


def add_all_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    p = STRATEGY_PARAMS
    adx = ta.trend.ADXIndicator(df.High, df.Low, df.Close, p["regime_adx_period"]).adx()
    atr = safe_atr(df.High, df.Low, df.Close, p["regime_atr_period"])
    rsi = ta.momentum.RSIIndicator(df.Close, p["regime_rsi_period"]).rsi()
    norm = lambda s: (
        (s - s.rolling(p["regime_norm_period"]).min())
        / (
            s.rolling(p["regime_norm_period"]).max()
            - s.rolling(p["regime_norm_period"]).min()
        )
    ).fillna(0.5)
    df["regime_adx_norm"] = norm(adx)
    df["regime_atr_slope_norm"] = norm(
        (atr - atr.shift(p["regime_atr_slope_period"]))
        / (atr.shift(p["regime_atr_slope_period"]) + 1e-9)
    )
    df["regime_rsi_vol_norm"] = 1 - norm(rsi.rolling(p["regime_rsi_vol_period"]).std())
    df["regime_hurst"] = (
        df.Close.rolling(p["regime_hurst_period"])
        .apply(lambda x: compute_hurst(np.log(x + 1e-9)), raw=False)
        .fillna(0.5)
    )
    df["regime_score"] = (
        df["regime_adx_norm"] * p["regime_score_weight_adx"]
        + df["regime_atr_slope_norm"] * p["regime_score_weight_atr"]
        + df["regime_rsi_vol_norm"] * p["regime_score_weight_rsi"]
        + np.clip((df["regime_hurst"] - 0.3) / 0.7, 0, 1)
        * p["regime_score_weight_hurst"]
    )
    df["market_regime"] = np.where(
        df["regime_score"] > p["regime_score_threshold"], 1, -1
    )
    if "mtf_signal" not in df.columns:
        raise ValueError("è‡´å‘½é”™è¯¯: 'mtf_signal' æœªåœ¨ä¼ å…¥çš„ DataFrame ä¸­æ‰¾åˆ°ã€‚")
    df["feature_rsi_14"] = ta.momentum.RSIIndicator(df.Close, 14).rsi()
    df["feature_atr_14_pct"] = safe_atr(df.High, df.Low, df.Close, 14) / (
        df.Close + 1e-9
    )
    bb = ta.volatility.BollingerBands(df.Close, 20)
    df["feature_bb_width"] = (bb.bollinger_hband() - bb.bollinger_lband()) / (
        df.Close + 1e-9
    )
    df["feature_close_ma_200_ratio"] = df.Close / (
        ta.trend.EMAIndicator(df.Close, 200).ema_indicator() + 1e-9
    )
    if "taker_buy_base_asset_volume" not in df.columns:
        raise ValueError(
            "è‡´å‘½é”™è¯¯: æ•°æ®ä¸­ç¼ºå°‘ 'taker_buy_base_asset_volume' åˆ—ã€‚è¯·åˆ é™¤ 'data_cache' æ–‡ä»¶å¤¹å¹¶é‡æ–°è¿è¡Œã€‚"
        )
    taker_sell_volume = df["Volume"] - df["taker_buy_base_asset_volume"]
    imbalance = (
        df["taker_buy_base_asset_volume"].rolling(10).sum()
        - taker_sell_volume.rolling(10).sum()
    )
    total_volume = df["Volume"].rolling(10).sum()
    df["feature_taker_imbalance_10"] = (imbalance / (total_volume + 1e-9)).fillna(0)
    df.dropna(inplace=True)
    return df


def make_asymmetric_labels(df: pd.DataFrame) -> pd.Series:
    p = STRATEGY_PARAMS
    if df.empty:
        return pd.Series(dtype=float)
    atr = safe_atr(df.High, df.Low, df.Close, 14)
    vol = df.Close.rolling(p["label_vol_window"]).std()
    expanding_min = vol.expanding(min_periods=p["label_vol_norm_window"]).min()
    expanding_max = vol.expanding(min_periods=p["label_vol_norm_window"]).max()
    vol_norm = (vol - expanding_min) / (expanding_max - expanding_min)
    vol_norm = vol_norm.fillna(0.5)
    dynamic_sl_mult = p["label_sl_atr_multiplier_base"] * (1 + vol_norm)
    upper_barrier, lower_barrier = df.Close + (
        atr * dynamic_sl_mult * p["label_risk_reward_ratio"]
    ), df.Close - (atr * dynamic_sl_mult)
    labels = pd.Series(np.nan, index=df.index)
    interval_minutes = int("".join(filter(str.isdigit, CONFIG.get("interval", "1m"))))
    look_forward_bars = int(p["label_look_forward"] / max(1, interval_minutes))
    for i in range(len(df) - look_forward_bars):
        entry_idx = df.index[i]
        path = df.iloc[i + 1 : i + 1 + look_forward_bars]
        if path.empty:
            continue
        up_b, low_b = upper_barrier.loc[entry_idx], lower_barrier.loc[entry_idx]
        if not (np.isfinite(up_b) and np.isfinite(low_b)):
            continue
        upper_touch, lower_touch = (
            path[path.High >= up_b].index.min(),
            path[path.Low <= low_b].index.min(),
        )
        if pd.notna(upper_touch) and pd.notna(lower_touch):
            labels.loc[entry_idx] = 1 if upper_touch <= lower_touch else 0
        elif pd.notna(upper_touch):
            labels.loc[entry_idx] = 1
        elif pd.notna(lower_touch):
            labels.loc[entry_idx] = 0
    return labels


def safe_load_scaler(path, expected_dim):
    if not os.path.exists(path):
        return RobustScaler()
    try:
        scaler = joblib.load(path)
        if hasattr(scaler, "scale_") and len(scaler.scale_) != expected_dim:
            logger.warning(
                f"Scaler ç»´åº¦ä¸åŒ¹é…: {len(scaler.scale_)} != {expected_dim}. å°†é‡å»º scalerã€‚"
            )
            return RobustScaler()
        return scaler
    except Exception as e:
        logger.warning(f"åŠ è½½ scaler å¤±è´¥ ({e})ï¼Œå°†åˆ›å»ºæ–° scalerã€‚")
        return RobustScaler()


def train_and_save_xgb(training_df, symbol):
    logger.info(f"[XGB] ä¸º {symbol} è®­ç»ƒ XGBoost...")
    split = int(len(training_df) * 0.8)
    train_df, test_df = training_df.iloc[:split].copy(), training_df.iloc[split:].copy()
    labels_train, labels_test = make_asymmetric_labels(
        train_df
    ), make_asymmetric_labels(test_df)
    df_train, df_test = train_df.join(labels_train.rename("target")).dropna(
        subset=["target"]
    ), test_df.join(labels_test.rename("target")).dropna(subset=["target"])
    if df_train.empty or df_test.empty:
        logger.warning(f"[{symbol}] XGB: æ ‡ç­¾ä¸è¶³ï¼Œè·³è¿‡ã€‚")
        return None
    df_train.loc[:, "target"], df_test.loc[:, "target"] = df_train["target"].astype(
        int
    ), df_test["target"].astype(int)
    features = SELECTED_FEATURES
    X_train_df, y_train = df_train[features], df_train["target"].values
    X_test_df, y_test = df_test[features], df_test["target"].values
    scaler_path = os.path.join(CONFIG["model_dir"], f"xgb_scaler_{symbol}.pkl")
    scaler = safe_load_scaler(scaler_path, X_train_df.shape[1])
    scaler.fit(X_train_df)
    X_train_s, X_test_s = scaler.transform(X_train_df), scaler.transform(X_test_df)
    joblib.dump(scaler, scaler_path)
    model = xgb.XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        use_label_encoder=False,
        n_estimators=STRATEGY_PARAMS["xgb_nrounds"],
        learning_rate=0.02,
        max_depth=2,
        subsample=0.5,
        colsample_bytree=0.5,
        gamma=STRATEGY_PARAMS.get("xgb_gamma", 2.0),
        reg_lambda=STRATEGY_PARAMS.get("xgb_lambda", 20.0),
        reg_alpha=STRATEGY_PARAMS.get("xgb_alpha", 5.0),
        min_child_weight=10,
        random_state=42,
        verbosity=0,
    )
    model.fit(X_train_s, y_train)
    acc = accuracy_score(y_test, model.predict(X_test_s))
    logger.info(f"[XGB] {symbol} OOS acc={acc:.4f}")
    joblib.dump(model, os.path.join(CONFIG["model_dir"], f"xgb_model_{symbol}.joblib"))
    return acc


# --- Strategy Class ---
def analyze_trade_distribution(trades_df, filename="trade_dist_v51.0.png"):
    if trades_df.empty:
        logger.info("æ— äº¤æ˜“ï¼Œè·³è¿‡äº¤æ˜“åˆ†å¸ƒå›¾ã€‚")
        return
    plt.style.use("seaborn-v0_8-darkgrid")
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.hist(
        [
            trades_df["PnL"][trades_df["PnL"] < 0],
            trades_df["PnL"][trades_df["PnL"] > 0],
        ],
        bins=50,
        label=["losses", "wins"],
        stacked=True,
        color=["#FF5733", "#33C1FF"],
    )
    ax.set_title("Trade PnL Distribution")
    ax.legend()
    plt.savefig(filename)
    plt.close(fig)
    logger.info(f"ä¿å­˜äº¤æ˜“åˆ†å¸ƒ: {filename}")


class UltimateStrategy(Strategy):
    symbol = None
    enabled_modules = {}

    def init(self, **kwargs):
        self.symbol = kwargs.get("symbol", None) or getattr(self, "symbol", None)
        for k, v in STRATEGY_PARAMS.items():
            setattr(self, k, v)
        self.vol_weight = getattr(self, "vol_weight", 1.0)
        self.enabled_modules = CONFIG.get("enabled_modules", {})
        c, h, l = (
            pd.Series(self.data.Close),
            pd.Series(self.data.High),
            pd.Series(self.data.Low),
        )
        self.market_regime = self.I(
            lambda: getattr(self.data, "market_regime", pd.Series([0] * len(self.data)))
        )
        self.mtf_signal = self.I(
            lambda: getattr(self.data, "mtf_signal", pd.Series([0] * len(self.data)))
        )
        self.tf_ema_fast = self.I(
            lambda: ta.trend.EMAIndicator(c, self.tf_ema_fast_period).ema_indicator(),
            plot=False,
        )
        self.tf_atr = self.I(lambda: safe_atr(h, l, c, self.tf_atr_period), plot=False)
        bb = ta.volatility.BollingerBands(c, self.mr_bb_period, self.mr_bb_std)
        self.mr_bb_upper, self.mr_bb_lower = self.I(
            lambda: bb.bollinger_hband()
        ), self.I(lambda: bb.bollinger_lband())
        self.mr_rsi = self.I(
            lambda: ta.momentum.RSIIndicator(c, self.mr_rsi_period).rsi(), plot=False
        )
        self.reset_trade_state()
        self.xgb, self.xgb_scaler = None, None
        try:
            self.xgb = joblib.load(
                os.path.join(CONFIG["model_dir"], f"xgb_model_{self.symbol}.joblib")
            )
            logger.info(f"[{self.symbol}] XGB æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
        except:
            logger.debug(f"[{self.symbol}] æ—  XGB æ¨¡å‹ã€‚")
        try:
            self.xgb_scaler = joblib.load(
                os.path.join(CONFIG["model_dir"], f"xgb_scaler_{self.symbol}.pkl")
            )
        except:
            self.xgb_scaler = None

    def next(self):
        if len(self.data) < max(self.regime_norm_period, 50):
            return
        if self.position:
            self.manage_open_position(self.data.Close[-1])
        else:
            regime = (
                self.market_regime[-1] if "market_regime" in self.data.df.columns else 1
            )
            if regime == 1 and self.enabled_modules.get("trend_following", False):
                self.run_scoring_system_entry(self.data.Close[-1])
            elif regime == -1 and self.enabled_modules.get("mean_reversion", False):
                self.run_mean_reversion_entry(self.data.Close[-1])

    def run_scoring_system_entry(self, price):
        if not all([self.xgb, self.xgb_scaler]):
            return
        current_features_df = self.data.df[SELECTED_FEATURES].iloc[-1:].copy()
        if current_features_df.isna().any().any():
            return
        scaled_features = self.xgb_scaler.transform(current_features_df)
        prob_xgb = float(self.xgb.predict_proba(scaled_features)[0, 1])
        is_long_safe, is_short_safe = (
            price > self.tf_ema_fast[-1],
            price < self.tf_ema_fast[-1],
        )
        if (
            self.mtf_signal[-1] == 1
            and prob_xgb > self.ml_confidence_threshold
            and is_long_safe
        ):
            self.open_tf_position(price, is_long=True, confidence_factor=1.0)
        elif (
            self.mtf_signal[-1] == -1
            and (1 - prob_xgb) > self.ml_confidence_threshold
            and is_short_safe
        ):
            self.open_tf_position(price, is_long=False, confidence_factor=1.0)

    def run_mean_reversion_entry(self, price):
        m = self
        is_long = (
            crossover(m.data.Close, m.mr_bb_lower) and m.mr_rsi[-1] < m.mr_rsi_oversold
        )
        is_short = (
            crossover(m.mr_bb_upper, m.data.Close)
            and m.mr_rsi[-1] > m.mr_rsi_overbought
        )
        if is_long:
            self.open_mr_position(price, True)
        elif is_short:
            self.open_mr_position(price, False)

    def open_mr_position(self, price, is_long):
        risk_per_share = (
            self.tf_atr[-1] * self.mr_stop_loss_atr_multiplier
            if np.isfinite(self.tf_atr[-1])
            else 0
        )
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price,
            risk_per_share,
            self._calculate_dynamic_risk() * self.mr_risk_multiplier,
        )
        if size <= 0:
            return
        self.reset_trade_state()
        self.active_sub_strategy = "MR"
        if is_long:
            self.buy(size=size)
            self.mr_stop_loss = price - risk_per_share
            self.mr_take_profit = price + risk_per_share * self.mr_take_profit_rr
        else:
            self.sell(size=size)
            self.mr_stop_loss = price + risk_per_share
            self.mr_take_profit = price - risk_per_share * self.mr_take_profit_rr

    def manage_mean_reversion_exit(self, price):
        if (
            self.position.is_long
            and (price >= self.mr_take_profit or price <= self.mr_stop_loss)
        ) or (
            self.position.is_short
            and (price <= self.mr_take_profit or price >= self.mr_stop_loss)
        ):
            self.close_position("MR_Exit_TP_SL")

    def reset_trade_state(self):
        (
            self.active_sub_strategy,
            self.chandelier_exit_level,
            self.highest_high_in_trade,
            self.lowest_low_in_trade,
            self.mr_stop_loss,
            self.mr_take_profit,
            self.tf_initial_stop_loss,
        ) = (None, 0.0, 0.0, float("inf"), 0.0, 0.0, 0.0)

    def manage_open_position(self, price):
        if self.active_sub_strategy == "TF":
            self.manage_trend_following_exit(price)
        elif self.active_sub_strategy == "MR":
            self.manage_mean_reversion_exit(price)

    def open_tf_position(self, price, is_long, confidence_factor):
        atr = self.tf_atr[-1]
        risk_per_share = (
            atr * self.tf_stop_loss_atr_multiplier if atr and np.isfinite(atr) else 0
        )
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price, risk_per_share, self._calculate_dynamic_risk() * confidence_factor
        )
        if size <= 0:
            return
        self.reset_trade_state()
        self.active_sub_strategy = "TF"
        if is_long:
            self.buy(size=size)
            self.tf_initial_stop_loss = price - risk_per_share
            self.highest_high_in_trade = self.data.High[-1]
        else:
            self.sell(size=size)
            self.tf_initial_stop_loss = price + risk_per_share
            self.lowest_low_in_trade = self.data.Low[-1]

    def manage_trend_following_exit(self, price):
        atr = self.tf_atr[-1]
        if self.position.is_long:
            if price < self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.highest_high_in_trade = max(
                self.highest_high_in_trade, self.data.High[-1]
            )
            self.chandelier_exit_level = (
                self.highest_high_in_trade - atr * self.tf_chandelier_atr_multiplier
            )
            if price < self.chandelier_exit_level:
                self.close_position("TF_Chandelier")
        else:
            if price > self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.lowest_low_in_trade = min(self.lowest_low_in_trade, self.data.Low[-1])
            self.chandelier_exit_level = (
                self.lowest_low_in_trade + atr * self.tf_chandelier_atr_multiplier
            )
            if price > self.chandelier_exit_level:
                self.close_position("TF_Chandelier")

    def close_position(self, reason: str):
        try:
            self.position.close()
        except:
            pass
        self.reset_trade_state()

    def _calculate_position_size(self, price, risk_per_unit, risk_pct):
        if risk_per_unit <= 0 or price <= 0:
            return 0
        cash_at_risk = risk_pct * self.equity
        pos_size_quote = cash_at_risk / (risk_per_unit / price)
        return min(pos_size_quote / self.equity, 0.99)

    def _calculate_dynamic_risk(self):
        trades = self.closed_trades
        if len(trades) < self.kelly_trade_history:
            return self.default_risk_pct * self.vol_weight
        recent, returns = trades[-self.kelly_trade_history :], [
            t.pl_pct for t in trades[-self.kelly_trade_history :]
        ]
        wins, losses = [r for r in returns if r > 0], [r for r in returns if r < 0]
        if not wins or not losses:
            return self.default_risk_pct * self.vol_weight
        win_rate, avg_win, avg_loss = (
            len(wins) / len(recent),
            sum(wins) / len(wins),
            abs(sum(losses) / len(losses)),
        )
        if avg_loss == 0:
            return self.max_risk_pct
        reward_ratio = avg_win / avg_loss
        if reward_ratio == 0:
            return self.default_risk_pct * self.vol_weight
        kelly = win_rate - (1 - win_rate) / reward_ratio
        return min(max(0.005, kelly * 0.5) * self.vol_weight, self.max_risk_pct)


# --- Main Execution Logic ---
def main():
    set_chinese_font()
    ensure_dirs()
    backtest_start_dt = pd.to_datetime(CONFIG["backtest_start_date"], utc=True)
    backtest_end_dt = pd.to_datetime(CONFIG["backtest_end_date"], utc=True)
    if "training_window_days" not in CONFIG:
        logger.error("CONFIG ä¸­ç¼ºå°‘ 'training_window_days'")
        return
    training_window = timedelta(days=CONFIG["training_window_days"])
    first_training_start = (
        backtest_start_dt
        - timedelta(days=CONFIG["ml_training_gap_days"])
        - training_window
    )
    overall_start_date = first_training_start
    mtf_warmup_days = 60
    data_fetch_start_date = overall_start_date - timedelta(days=mtf_warmup_days)
    logger.info(
        f"æ•°æ®è·å–æ€»æ—¶é—´æ®µ: {data_fetch_start_date.date()} -> {backtest_end_dt.date()} (åŒ…å« {mtf_warmup_days} å¤© MTF é¢„çƒ­)"
    )
    logger.info(f"æœ‰æ•ˆè®­ç»ƒ/å›æµ‹å¼€å§‹äº: {overall_start_date.date()}")

    symbol = CONFIG["symbols_to_test"][0]
    btc_data_raw = fetch_binance_klines(
        CONFIG["btc_symbol"],
        CONFIG["interval"],
        data_fetch_start_date,
        backtest_end_dt,
        cache_dir=CONFIG["data_cache"],
    )
    symbol_data_raw = fetch_binance_klines(
        symbol,
        CONFIG["interval"],
        data_fetch_start_date,
        backtest_end_dt,
        cache_dir=CONFIG["data_cache"],
    )
    if symbol_data_raw.empty:
        logger.error(f"{symbol} æ•°æ®ä¸ºç©ºï¼Œé€€å‡ºã€‚")
        return

    mtf_series = calculate_mtf_signal(btc_data_raw)
    symbol_data_raw["mtf_signal"] = mtf_series
    symbol_data_effective = symbol_data_raw.loc[overall_start_date:].copy()

    logger.info(f"ä¸ºæœ‰æ•ˆæ•°æ® (ä» {overall_start_date.date()} å¼€å§‹) æ·»åŠ ç‰¹å¾...")
    featured_data = add_all_features(symbol_data_effective)

    logger.info(
        "\n"
        + "#" * 80
        + "\n                 æ¨¡å¼: å•æ¬¡è®­ç»ƒä¸å›æµ‹ (XGBoost Only)\n"
        + "#" * 80
    )
    training_end_dt = backtest_start_dt - timedelta(days=CONFIG["ml_training_gap_days"])
    logger.info(
        f"è®­ç»ƒæœŸ: {featured_data.index.min().date()} -> {training_end_dt.date()}"
    )
    training_slice = featured_data.loc[:training_end_dt]

    if (
        STRATEGY_PARAMS["ml_filter_enabled"]
        and CONFIG["enabled_modules"].get("ml_filter", False)
        and ML_LIBS
    ):
        if len(training_slice) > 1000:
            train_and_save_xgb(training_slice, symbol)
        else:
            logger.warning(f"[{symbol}] è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡æœ¬æ¬¡è®­ç»ƒã€‚")

    logger.info(f"å›æµ‹æœŸ: {backtest_start_dt.date()} -> {backtest_end_dt.date()}")
    backtest_slice = (
        featured_data.loc[backtest_start_dt:backtest_end_dt].copy().dropna()
    )
    if backtest_slice.empty:
        logger.error("å›æµ‹å‘¨æœŸå†…æ•°æ®ä¸ºç©ºï¼Œé€€å‡ºã€‚")
        return

    bt = Backtest(
        backtest_slice,
        UltimateStrategy,
        cash=CONFIG["initial_cash"],
        commission=CONFIG["commission"],
        finalize_trades=True,
    )
    try:
        stats = bt.run(symbol=symbol)
        logger.info("å›æµ‹å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        print(stats)
        if "_trades" in stats and not stats["_trades"].empty:
            logger.info(
                "\n" + "#" * 80 + "\n                 å›æµ‹è¡¨ç°æ€»è§ˆ\n" + "#" * 80
            )
            logger.info(f"åˆå§‹èµ„é‡‘: ${CONFIG['initial_cash']:,.2f}")
            logger.info(f"æœ€ç»ˆæƒç›Š: ${stats['Equity Final [$]']:,.2f}")
            logger.info(f"æ€»å›æŠ¥ç‡: {stats['Return [%]']:.2f}%")
            logger.info(f"æ€»äº¤æ˜“æ¬¡æ•°: {stats['# Trades']}")
            logger.info(f"èƒœç‡: {stats['Win Rate [%]']:.2f}%")
            logger.info(f"ç›ˆäºå› å­: {stats['Profit Factor']:.2f}")
            if CONFIG["show_plots"]:
                bt.plot(filename="backtest_v51.0.html", open_browser=False)
                logger.info("ä¿å­˜è¯¦ç»†å›æµ‹å›¾: backtest_v51.0.html")
                analyze_trade_distribution(
                    stats["_trades"], filename="trade_dist_v51.0.png"
                )
        else:
            logger.info("æ•´ä¸ªå›æµ‹æœŸé—´æ²¡æœ‰äº§ç”Ÿä»»ä½•äº¤æ˜“ã€‚")
    except Exception as e:
        logger.error(f"å›æµ‹æœŸé—´å‡ºç°ä¸¥é‡é”™è¯¯: {e}", exc_info=True)

    logger.info("ğŸš€ V51.0 è¿è¡Œç»“æŸã€‚")


if __name__ == "__main__":
    main()


(kronos) ï£¿ ~/work/conda/Kronos/ [main*] python gpt1.py 
2025-10-21 12:40:24 [INFO] è®¾ç½®ä¸­æ–‡å­—ä½“: Heiti TC
2025-10-21 12:40:24 [INFO] æ•°æ®è·å–æ€»æ—¶é—´æ®µ: 2024-08-05 -> 2025-10-01 (åŒ…å« 60 å¤© MTF é¢„çƒ­)
2025-10-21 12:40:24 [INFO] æœ‰æ•ˆè®­ç»ƒ/å›æµ‹å¼€å§‹äº: 2024-10-04
2025-10-21 12:40:24 [INFO] âœ… ä»æœ‰æ•ˆç¼“å­˜åŠ è½½ BTCUSDT æ•°æ®: data_cache/BTCUSDT_5m.csv
2025-10-21 12:40:24 [INFO] âœ… ä»æœ‰æ•ˆç¼“å­˜åŠ è½½ ETHUSDT æ•°æ®: data_cache/ETHUSDT_5m.csv
2025-10-21 12:40:24 [INFO] ç‹¬ç«‹è®¡ç®— MTF ä¿¡å·...
2025-10-21 12:40:24 [INFO] ä¸ºæœ‰æ•ˆæ•°æ® (ä» 2024-10-04 å¼€å§‹) æ·»åŠ ç‰¹å¾...
2025-10-21 12:43:01 [INFO] 
################################################################################
                 æ¨¡å¼: å•æ¬¡è®­ç»ƒä¸å›æµ‹ (XGBoost Only)
################################################################################
2025-10-21 12:43:01 [INFO] è®­ç»ƒæœŸ: 2024-10-04 -> 2025-04-02
2025-10-21 12:43:01 [INFO] [XGB] ä¸º ETHUSDT è®­ç»ƒ XGBoost...
2025-10-21 12:43:13 [INFO] [XGB] ETHUSDT OOS acc=0.6644
2025-10-21 12:43:13 [INFO] å›æµ‹æœŸ: 2025-07-01 -> 2025-10-01
2025-10-21 12:43:13 [INFO] [ETHUSDT] XGB æ¨¡å‹åŠ è½½æˆåŠŸã€‚
2025-10-21 12:43:20 [INFO] å›æµ‹å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...                       
Start                     2025-07-01 00:00...
End                       2025-10-01 00:00...
Duration                     92 days 00:00:00
Exposure Time [%]                     2.50594
Equity Final [$]                 485011.58747
Equity Peak [$]                      500000.0
Commissions [$]                    4834.98253
Return [%]                           -2.99768
Buy & Hold Return [%]                 66.2659
Return (Ann.) [%]                    -11.2592
Volatility (Ann.) [%]                 4.39029
CAGR [%]                            -11.37434
Sharpe Ratio                         -2.56457
Sortino Ratio                        -2.50392
Calmar Ratio                         -2.22808
Alpha [%]                            -3.66669
Beta                                   0.0101
Max. Drawdown [%]                    -5.05332
Avg. Drawdown [%]                    -5.05332
Max. Drawdown Duration       83 days 05:45:00
Avg. Drawdown Duration       83 days 05:45:00
# Trades                                    5
Win Rate [%]                             20.0
Best Trade [%]                        1.42437
Worst Trade [%]                      -1.48333
Avg. Trade [%]                       -0.61461
Max. Trade Duration           1 days 03:00:00
Avg. Trade Duration           0 days 10:59:00
Profit Factor                         0.31864
Expectancy [%]                       -0.60915
SQN                                  -1.20231
Kelly Criterion                      -0.44824
_strategy                 UltimateStrategy...
_equity_curve                             ...
_trades                      Size  EntryBa...
dtype: object
2025-10-21 12:43:20 [INFO] 
################################################################################
                 å›æµ‹è¡¨ç°æ€»è§ˆ
################################################################################
2025-10-21 12:43:20 [INFO] åˆå§‹èµ„é‡‘: $500,000.00
2025-10-21 12:43:20 [INFO] æœ€ç»ˆæƒç›Š: $485,011.59
2025-10-21 12:43:20 [INFO] æ€»å›æŠ¥ç‡: -3.00%
2025-10-21 12:43:20 [INFO] æ€»äº¤æ˜“æ¬¡æ•°: 5
2025-10-21 12:43:20 [INFO] èƒœç‡: 20.00%
2025-10-21 12:43:20 [INFO] ç›ˆäºå› å­: 0.32
2025-10-21 12:43:22 [INFO] ä¿å­˜è¯¦ç»†å›æµ‹å›¾: backtest_v51.0.html
2025-10-21 12:43:22 [INFO] ä¿å­˜äº¤æ˜“åˆ†å¸ƒ: trade_dist_v51.0.png
2025-10-21 12:43:22 [INFO] ğŸš€ V51.0 è¿è¡Œç»“æŸã€‚
(kronos) ï£¿ ~/work/conda/Kronos/ [main*] 