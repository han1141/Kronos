# -*- coding: utf-8 -*-
"""
ğŸš€ ç»ˆæä¼˜åŒ–ç‰ˆåŠ å¯†è´§å¸è¶‹åŠ¿äº¤æ˜“ç³»ç»Ÿ (V41.01-No-News)

ç‰ˆæœ¬æ›´æ–°ï¼š
- (V41.01-No-News) æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œå®Œå…¨ç§»é™¤äº†æ–°é—»æƒ…ç»ªè·å–å’Œåˆ†æåŠŸèƒ½ï¼Œä»¥ç®€åŒ–æµç¨‹å¹¶æ¶ˆé™¤APIä¾èµ–ã€‚
- (V41.00-Walk-Forward) å®æ–½äº†å‰å‘å±•å¼€(Walk-Forward)è®­ç»ƒå’ŒéªŒè¯æ¡†æ¶ä»¥è§£å†³æ—¶é—´åºåˆ—è¿‡æ‹Ÿåˆé—®é¢˜ã€‚
    - åºŸå¼ƒäº† `train_test_split`ï¼Œé‡‡ç”¨ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºçš„è®­ç»ƒå’ŒéªŒè¯æ–¹å¼ã€‚
    - æ¨¡å‹ç°åœ¨ä¼šåœ¨å›æµ‹æœŸé—´ï¼ŒåŸºäºä¸€ä¸ªæ»šåŠ¨çš„å†å²æ•°æ®çª—å£è¢«å®šæœŸé‡æ–°è®­ç»ƒã€‚
    - ç­–ç•¥å®ç°äº†åŠ¨æ€æ¨¡å‹åŠ è½½æœºåˆ¶ï¼Œä»¥åœ¨å›æµ‹ä¸­è‡ªåŠ¨ä½¿ç”¨æœ€æ–°çš„ã€åˆé€‚çš„æ¨¡å‹ã€‚
    - æ–°å¢äº†ç”¨äºæ§åˆ¶å‰å‘å±•å¼€è®­ç»ƒæµç¨‹çš„é…ç½®é€‰é¡¹ã€‚
"""

# --- 1. å¯¼å…¥åº“ä¸é…ç½® ---
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import logging
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
import matplotlib.font_manager
import joblib
import os
import glob

# æ£€æŸ¥æœºå™¨å­¦ä¹ åº“æ˜¯å¦å®‰è£…
try:
    import lightgbm as lgb
    from sklearn.metrics import classification_report

    ML_LIBS_INSTALLED = True
except ImportError:
    ML_LIBS_INSTALLED = False

# æ£€æŸ¥é«˜çº§æœºå™¨å­¦ä¹ åº“æ˜¯å¦å®‰è£…
try:
    import tensorflow as tf

    ADVANCED_ML_LIBS_INSTALLED = True
except ImportError:
    ADVANCED_ML_LIBS_INSTALLED = False

from backtesting import Backtest, Strategy
from backtesting.lib import crossover
import ta

# --- æ—¥å¿—å’Œå­—ä½“é…ç½® ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
log_filename = f"trading_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
file_handler = logging.FileHandler(log_filename, encoding="utf-8")
file_handler.setLevel(logging.DEBUG)
stream_handler = logging.StreamHandler()
stream_handler.setLevel(logging.INFO)
formatter = logging.Formatter(
    "%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
)
file_handler.setFormatter(formatter)
stream_handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(file_handler)
    logger.addHandler(stream_handler)


def set_chinese_font():
    try:
        font_names = [
            "PingFang SC",
            "Microsoft YaHei",
            "SimHei",
            "Heiti TC",
            "sans-serif",
        ]
        for font in font_names:
            if font in [f.name for f in matplotlib.font_manager.fontManager.ttflist]:
                plt.rcParams["font.sans-serif"] = [font]
                plt.rcParams["axes.unicode_minus"] = False
                logger.info(f"æˆåŠŸè®¾ç½®ä¸­æ–‡å­—ä½“: {font}")
                return
        logger.warning("æœªæ‰¾åˆ°æŒ‡å®šçš„ä¸­æ–‡å­—ä½“")
    except Exception as e:
        logger.error(f"è®¾ç½®ä¸­æ–‡å­—ä½“æ—¶å‡ºé”™: {e}")


set_chinese_font()

# --- æ ¸å¿ƒé…ç½® ---
CONFIG = {
    "symbols_to_test": ["BTCUSDT", "ETHUSDT"],
    "interval": "1h",
    "backtest_start_date": "2025-01-01",  # å›æµ‹å¼€å§‹æ—¥æœŸ
    "backtest_end_date": "2025-10-13",  # å›æµ‹ç»“æŸæ—¥æœŸ
    "initial_cash": 500_000,
    "commission": 0.0002,
    "spread": 0.0005,
    "run_monte_carlo": False,
    "show_plots": False,
    # --- å‰å‘å±•å¼€è®­ç»ƒ (Walk-Forward Training) é…ç½® ---
    "enable_walk_forward_training": True,  # è®¾ä¸º True ä»¥å¯ç”¨å‘¨æœŸæ€§æ¨¡å‹é‡è®­ç»ƒ
    "training_window_days": 365 * 2,  # ç”¨äºè®­ç»ƒæ¯ä¸ªæ¨¡å‹çš„å†å²æ•°æ®å¤©æ•° (ä¾‹å¦‚ 2 å¹´)
    "retrain_every_days": 90,  # æ¯éš”å¤šå°‘å¤©é‡è®­ç»ƒä¸€æ¬¡æ¨¡å‹ (ä¾‹å¦‚æ¯å­£åº¦)
}
ML_HORIZONS = [4, 8, 12]

# --- å‚æ•°ä¸ç±»å®šä¹‰ (æ— å˜åŠ¨) ---
STRATEGY_PARAMS = {
    "kelly_trade_history": 20,
    "default_risk_pct": 0.015,
    "max_risk_pct": 0.04,
    "dd_grace_period_bars": 240,
    "dd_initial_pct": 0.35,
    "dd_final_pct": 0.25,
    "dd_decay_bars": 4320,
    "regime_adx_period": 14,
    "regime_atr_period": 14,
    "regime_atr_slope_period": 5,
    "regime_rsi_period": 14,
    "regime_rsi_vol_period": 14,
    "regime_norm_period": 252,
    "regime_hurst_period": 100,
    "regime_score_weight_adx": 0.6,
    "regime_score_weight_atr": 0.3,
    "regime_score_weight_rsi": 0.05,
    "regime_score_weight_hurst": 0.05,
    "regime_score_threshold": 0.45,
    "tf_donchian_period": 30,
    "tf_ema_fast_period": 20,
    "tf_ema_slow_period": 75,
    "tf_adx_confirm_period": 14,
    "tf_adx_confirm_threshold": 18,
    "tf_chandelier_period": 22,
    "tf_chandelier_atr_multiplier": 3.0,
    "tf_atr_period": 14,
    "tf_stop_loss_atr_multiplier": 2.5,
    "mr_bb_period": 20,
    "mr_bb_std": 2.0,
    "mr_rsi_period": 14,
    "mr_rsi_oversold": 30,
    "mr_rsi_overbought": 70,
    "mr_stop_loss_atr_multiplier": 1.5,
    "mr_risk_multiplier": 0.5,
    "mtf_period": 50,
    "score_entry_threshold": 0.4,
    "score_weights_tf": {
        "breakout": 0.20,
        "momentum": 0.15,
        "mtf": 0.10,
        "ml": 0.30,
        "advanced_ml": 0.25,
    },
}
ASSET_SPECIFIC_OVERRIDES = {
    "BTCUSDT": {
        "strategy_class": "BTCStrategy",
        "ml_weights": {"4h": 0.2, "8h": 0.3, "12h": 0.5},
        "ml_weighted_threshold": 0.45,
        "score_entry_threshold": 0.5,
        "score_weights_tf": {
            "breakout": 0.15,
            "momentum": 0.20,
            "mtf": 0.15,
            "ml": 0.25,
            "advanced_ml": 0.25,
        },
    },
    "ETHUSDT": {
        "strategy_class": "ETHStrategy",
        "ml_weights": {"4h": 0.25, "8h": 0.35, "12h": 0.4},
        "ml_weighted_threshold": 0.2,
        "score_entry_threshold": 0.35,
    },
    "SOLUSDT": {
        "strategy_class": "SOLStrategy",
        "ml_weights": {"4h": 0.3, "8h": 0.4, "12h": 0.3},
        "ml_weighted_threshold": 0.25,
        "score_entry_threshold": 0.4,
        "score_weights_tf": {
            "breakout": 0.3,
            "momentum": 0.1,
            "mtf": 0.1,
            "ml": 0.25,
            "advanced_ml": 0.25,
        },
    },
}


class StrategyMemory:  # æ— å˜åŠ¨
    def __init__(self, filepath="strategy_memory.csv"):
        self.filepath = filepath
        self.columns = [
            "timestamp",
            "symbol",
            "regime",
            "param_key",
            "param_value",
            "performance",
        ]
        self.memory_df = self._load_memory()

    def _load_memory(self):
        if os.path.exists(self.filepath):
            return pd.read_csv(self.filepath, parse_dates=["timestamp"])
        return pd.DataFrame(columns=self.columns)

    def record_optimization(self, timestamp, symbol, regime, best_params, performance):
        new_records = [
            {
                "timestamp": timestamp,
                "symbol": symbol,
                "regime": regime,
                "param_key": key,
                "param_value": value,
                "performance": performance,
            }
            for key, value in best_params.items()
        ]
        new_df = pd.DataFrame(new_records)
        self.memory_df = pd.concat([self.memory_df, new_df], ignore_index=True)
        self.memory_df.sort_values(by="timestamp", inplace=True)
        self.memory_df.drop_duplicates(
            subset=["timestamp", "symbol", "regime", "param_key"],
            keep="last",
            inplace=True,
        )
        self.memory_df.to_csv(self.filepath, index=False)
        logger.info(f"ğŸ§  è®°å¿†åº“å·²æ›´æ–°: {symbol} åœ¨ {regime} çŠ¶æ€ä¸‹çš„æœ€ä¼˜å‚æ•°å·²è®°å½•ã€‚")

    def get_best_params(self, timestamp, symbol, regime):
        relevant_memory = self.memory_df[
            (self.memory_df["symbol"] == symbol)
            & (self.memory_df["regime"] == regime)
            & (self.memory_df["timestamp"] <= timestamp)
        ]
        if relevant_memory.empty:
            return None
        latest_timestamp = relevant_memory["timestamp"].max()
        latest_params_df = relevant_memory[
            relevant_memory["timestamp"] == latest_timestamp
        ]
        return pd.Series(
            latest_params_df.param_value.values, index=latest_params_df.param_key
        ).to_dict()


def fetch_binance_klines(  # æ— å˜åŠ¨
    symbol: str, interval: str, start_str: str, end_str: str = None, limit: int = 1000
) -> pd.DataFrame:
    url, columns = "https://api.binance.com/api/v3/klines", [
        "timestamp",
        "Open",
        "High",
        "Low",
        "Close",
        "Volume",
        "close_time",
        "quote_asset_volume",
        "number_of_trades",
        "taker_buy_base_volume",
        "taker_buy_quote_volume",
        "ignore",
    ]
    start_ts, end_ts = int(pd.to_datetime(start_str).timestamp() * 1000), (
        int(pd.to_datetime(end_str).timestamp() * 1000)
        if end_str
        else int(time.time() * 1000)
    )
    all_data, retries, last_exception = [], 5, None
    while start_ts < end_ts:
        params = {
            "symbol": symbol.upper(),
            "interval": interval,
            "startTime": start_ts,
            "endTime": end_ts,
            "limit": limit,
        }
        for attempt in range(retries):
            try:
                response = requests.get(url, params=params, timeout=15)
                response.raise_for_status()
                data = response.json()
                if not data:
                    start_ts = end_ts
                    break
                all_data.extend(data)
                start_ts = data[-1][0] + 1
                break
            except requests.exceptions.RequestException as e:
                last_exception = e
                time.sleep(2**attempt)
        else:
            logger.error(
                f"è·å– {symbol} æ•°æ®åœ¨ {retries} æ¬¡å°è¯•åå½»åº•å¤±è´¥. æœ€åé”™è¯¯: {last_exception}"
            )
            return pd.DataFrame()
    if not all_data:
        return pd.DataFrame()
    df = pd.DataFrame(all_data, columns=columns)[
        ["timestamp", "Open", "High", "Low", "Close", "Volume"]
    ].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
    for col in ["Open", "High", "Low", "Close", "Volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df.set_index("timestamp", inplace=True)
    df.sort_index(inplace=True)
    logger.info(f"âœ… è·å– {symbol} æ•°æ®æˆåŠŸï¼š{len(df)} æ¡")
    return df


def compute_hurst(ts, max_lag=100):  # æ— å˜åŠ¨
    if len(ts) < 10:
        return 0.5
    lags, tau, valid_lags = range(2, min(max_lag, len(ts) // 2 + 1)), [], []
    for lag in lags:
        diff = ts[lag:] - ts[:-lag]
        std_diff = np.std(diff)
        if std_diff > 0:
            tau.append(std_diff)
            valid_lags.append(lag)
    if len(tau) < 2:
        return 0.5
    try:
        return max(0.0, min(1.0, np.polyfit(np.log(valid_lags), np.log(tau), 1)[0]))
    except:
        return 0.5


def run_advanced_model_inference(df: pd.DataFrame) -> pd.DataFrame:  # æ— å˜åŠ¨
    logger.info("æ­£åœ¨è¿è¡Œé«˜çº§æ¨¡å‹æ¨ç† (æ¨¡æ‹Ÿ)...")
    if not ADVANCED_ML_LIBS_INSTALLED:
        logger.warning("TensorFlow/PyTorch æœªå®‰è£…ã€‚é«˜çº§æ¨¡å‹ä¿¡å·å°†ä¸ºä¸­æ€§(0)ã€‚")
        df["advanced_ml_signal"] = 0.0
        return df
    if "ai_filter_signal" in df.columns:
        df["advanced_ml_signal"] = (
            df["ai_filter_signal"].rolling(window=24, min_periods=12).mean().fillna(0)
        )
    else:
        df["advanced_ml_signal"] = 0.0
    logger.info("é«˜çº§æ¨¡å‹æ¨ç† (æ¨¡æ‹Ÿ) å®Œæˆã€‚")
    return df


def add_ml_features(df: pd.DataFrame) -> pd.DataFrame:
    p = STRATEGY_PARAMS
    adx = ta.trend.ADXIndicator(df.High, df.Low, df.Close, p["regime_adx_period"]).adx()
    atr = ta.volatility.AverageTrueRange(
        df.High, df.Low, df.Close, p["regime_atr_period"]
    ).average_true_range()
    rsi = ta.momentum.RSIIndicator(df.Close, p["regime_rsi_period"]).rsi()
    norm = lambda s: (
        (s - s.rolling(p["regime_norm_period"]).min())
        / (
            s.rolling(p["regime_norm_period"]).max()
            - s.rolling(p["regime_norm_period"]).min()
        )
    ).fillna(0.5)
    df["feature_adx_norm"] = norm(adx)
    df["feature_atr_slope_norm"] = norm(
        (atr - atr.shift(p["regime_atr_slope_period"]))
        / atr.shift(p["regime_atr_slope_period"])
    )
    df["feature_rsi_vol_norm"] = 1 - norm(rsi.rolling(p["regime_rsi_vol_period"]).std())
    df["feature_hurst"] = (
        df.Close.rolling(p["regime_hurst_period"])
        .apply(lambda x: compute_hurst(np.log(x + 1e-9)), raw=False)
        .fillna(0.5)
    )
    # **æ³¨æ„**: æ­¤å¤„å·²ç§»é™¤ feature_news_sentiment çš„åˆ›å»º
    df["feature_regime_score"] = (
        df["feature_adx_norm"] * p["regime_score_weight_adx"]
        + df["feature_atr_slope_norm"] * p["regime_score_weight_atr"]
        + df["feature_rsi_vol_norm"] * p["regime_score_weight_rsi"]
        + np.clip((df["feature_hurst"] - 0.3) / 0.7, 0, 1)
        * p["regime_score_weight_hurst"]
    )
    return df


def add_market_regime_features(df: pd.DataFrame) -> pd.DataFrame:  # æ— å˜åŠ¨
    df["regime_score"] = df["feature_regime_score"]
    df["trend_regime"] = np.where(
        df["regime_score"] > STRATEGY_PARAMS["regime_score_threshold"],
        "Trending",
        "Mean-Reverting",
    )
    df["volatility"] = df["Close"].pct_change().rolling(24 * 7).std() * np.sqrt(
        24 * 365
    )
    low_vol, high_vol = df["volatility"].quantile(0.33), df["volatility"].quantile(0.67)
    df["volatility_regime"] = pd.cut(
        df["volatility"],
        bins=[0, low_vol, high_vol, np.inf],
        labels=["Low", "Medium", "High"],
        include_lowest=True,
    )
    df["market_regime_final"] = (
        df["trend_regime"].astype(str) + "_" + df["volatility_regime"].astype(str)
    )
    df["market_regime"] = np.where(df["trend_regime"] == "Trending", 1, -1)
    return df


def preprocess_data_for_strategy(data_in: pd.DataFrame, symbol: str) -> pd.DataFrame:
    df = data_in.copy()
    logger.info(
        f"[{symbol}] å¼€å§‹æ•°æ®é¢„å¤„ç† (æ•°æ®èŒƒå›´: {df.index.min()} to {df.index.max()})..."
    )

    # **æ³¨æ„**: æ­¤å¤„å·²ç§»é™¤å¯¹ get_news_sentiment çš„è°ƒç”¨

    rsi_filter = ta.momentum.RSIIndicator(df.Close, 14).rsi()
    df["ai_filter_signal"] = (
        (((rsi_filter.rolling(3).mean() - rsi_filter.rolling(10).mean()) / 50))
        .clip(-1, 1)
        .fillna(0)
    )
    df = run_advanced_model_inference(df)
    df = add_ml_features(df)
    df = add_market_regime_features(df)

    # è·å–ä¸å½“å‰å°æ—¶æ•°æ®åŒ¹é…çš„æ—¥çº¿æ•°æ®
    daily_start = df.index.min().normalize() - pd.Timedelta(
        days=STRATEGY_PARAMS["mtf_period"] + 1
    )
    daily_end = df.index.max().normalize()
    data_1d = fetch_binance_klines(
        symbol,
        "1d",
        daily_start.strftime("%Y-%m-%d"),
        daily_end.strftime("%Y-%m-%d"),
    )
    if data_1d is not None and not data_1d.empty:
        sma = ta.trend.SMAIndicator(
            data_1d["Close"], window=STRATEGY_PARAMS["mtf_period"]
        ).sma_indicator()
        mtf_signal_1d = pd.Series(
            np.where(data_1d["Close"] > sma, 1, -1), index=data_1d.index
        )
        df["mtf_signal"] = mtf_signal_1d.reindex(df.index, method="ffill").fillna(0)
    else:
        logger.warning(f"[{symbol}] æœªèƒ½è·å–æ—¥çº¿æ•°æ®ç”¨äºMTFä¿¡å·è®¡ç®—ã€‚")
        df["mtf_signal"] = 0

    df.dropna(inplace=True)
    logger.info(f"[{symbol}] æ•°æ®é¢„å¤„ç†å®Œæˆã€‚æ•°æ®è¡Œæ•°: {len(df)}")
    return df


# --- æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ (Walk-Forward ç‰ˆ) ---
def train_and_save_model(
    training_data: pd.DataFrame, symbol: str, training_end_date: pd.Timestamp
):
    """
    ä½¿ç”¨ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºçš„æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œä¿å­˜ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚
    """
    if not ML_LIBS_INSTALLED:
        logger.warning("ç¼ºå°‘ LightGBM æˆ– scikit-learn åº“ï¼Œè·³è¿‡æ¨¡å‹è®­ç»ƒã€‚")
        return
    logger.info(
        f"--- ğŸ¤– [Walk-Forward] å¼€å§‹ä¸º {symbol} è®­ç»ƒæ¨¡å‹ (æ•°æ®æˆªæ­¢äº: {training_end_date.date()}) ---"
    )

    features = [col for col in training_data.columns if "feature_" in col]
    if not features:
        logger.error(f"[{symbol}] æ‰¾ä¸åˆ°ä»»ä½•ç‰¹å¾åˆ— (feature_) ç”¨äºè®­ç»ƒã€‚")
        return
    logger.info(f"[{symbol}] ä½¿ç”¨ä»¥ä¸‹ç‰¹å¾è¿›è¡Œè®­ç»ƒ: {features}")

    for h in ML_HORIZONS:
        logger.info(f"æ­£åœ¨ä¸º {h}h é¢„æµ‹çª—å£å‡†å¤‡æ•°æ®...")
        data = training_data.copy()
        data[f"target_{h}h"] = (data["Close"].shift(-h) > data["Close"]).astype(int)
        df_train = data.dropna(subset=[f"target_{h}h"] + features)

        X = df_train[features]
        y = df_train[f"target_{h}h"]

        if len(X) < 200 or len(y.unique()) < 2:
            logger.warning(
                f"[{symbol}-{h}h] æ•°æ®ä¸è¶³æˆ–ç›®æ ‡ç±»åˆ«å•ä¸€ï¼Œè·³è¿‡æ­¤é¢„æµ‹çª—å£çš„è®­ç»ƒã€‚"
            )
            continue

        # --- å…³é”®æ”¹åŠ¨ï¼šä¸å†ä½¿ç”¨ train_test_split ---
        # ä½¿ç”¨è®­ç»ƒæ•°æ®çš„æœ€å10%ä½œä¸ºéªŒè¯é›†ï¼Œä»¥ç›‘æ§è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶ä¿æŒæ—¶é—´é¡ºåº
        eval_size = int(len(X) * 0.1)
        X_train, X_eval = X[:-eval_size], X[-eval_size:]
        y_train, y_eval = y[:-eval_size], y[-eval_size:]

        logger.info(f"å¼€å§‹è®­ç»ƒ {symbol} çš„ {h}h æ¨¡å‹...")
        model = lgb.LGBMClassifier(
            objective="binary", n_estimators=100, random_state=42
        )
        model.fit(
            X_train,
            y_train,
            eval_set=[(X_eval, y_eval)],
            callbacks=[lgb.early_stopping(10, verbose=False)],
        )

        y_pred = model.predict(X_eval)
        logger.info(
            f"[{symbol}-{h}h] æ¨¡å‹åœ¨æ—¶é—´é¡ºåºéªŒè¯é›†ä¸Šçš„è¯„ä¼°æŠ¥å‘Š:\n{classification_report(y_eval, y_pred)}"
        )

        # ä½¿ç”¨è®­ç»ƒç»“æŸæ—¥æœŸæ¥å‘½åæ¨¡å‹æ–‡ä»¶
        date_str = training_end_date.strftime("%Y%m%d")
        model_filename = f"directional_model_{symbol}_{h}h_{date_str}.joblib"
        joblib.dump(model, model_filename)
        logger.info(f"âœ… [{symbol}-{h}h] æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜è‡³: {model_filename}")


class BaseAssetStrategy:  # æ— å˜åŠ¨
    def __init__(self, main_strategy: Strategy):
        self.main = main_strategy

    def _calculate_entry_score(self) -> float:
        main = self.main
        weights = main.score_weights_tf
        breakout_score = (
            1
            if main.data.High[-1] > main.tf_donchian_h[-1]
            else -1 if main.data.Low[-1] < main.tf_donchian_l[-1] else 0
        )
        momentum_score = 1 if main.tf_ema_fast[-1] > main.tf_ema_slow[-1] else -1
        mtf_score = main.mtf_signal[-1]
        ml_score = main.get_ml_confidence_score()
        advanced_ml_score = main.advanced_ml_signal[-1]
        return (
            breakout_score * weights.get("breakout", 0)
            + momentum_score * weights.get("momentum", 0)
            + mtf_score * weights.get("mtf", 0)
            + ml_score * weights.get("ml", 0)
            + advanced_ml_score * weights.get("advanced_ml", 0)
        )

    def _define_mr_entry_signal(self) -> int:
        main = self.main
        return (
            1
            if crossover(main.data.Close, main.mr_bb_lower)
            and main.mr_rsi[-1] < main.mr_rsi_oversold
            else (
                -1
                if crossover(main.mr_bb_upper, main.data.Close)
                and main.mr_rsi[-1] > main.mr_rsi_overbought
                else 0
            )
        )


class BTCStrategy(BaseAssetStrategy):  # æ— å˜åŠ¨
    def _calculate_entry_score(self) -> float:
        if self.main.tf_adx[-1] > 20:
            return super()._calculate_entry_score()
        return 0


class ETHStrategy(BaseAssetStrategy):  # æ— å˜åŠ¨
    pass


class SOLStrategy(BaseAssetStrategy):  # æ— å˜åŠ¨
    def _calculate_entry_score(self) -> float:
        base_score = super()._calculate_entry_score()
        try:
            volume_series = pd.Series(self.main.data.Volume)
            if len(volume_series) < 20:
                return base_score
            current_volume = volume_series.iloc[-1]
            mean_volume = volume_series.rolling(20).mean().iloc[-2]
            volume_spike = current_volume > mean_volume * 1.5
            if volume_spike and abs(base_score) > 0:
                return base_score * 1.1
        except Exception:
            return base_score
        return base_score


STRATEGY_MAPPING = {
    "BaseAssetStrategy": BaseAssetStrategy,
    "BTCStrategy": BTCStrategy,
    "ETHStrategy": ETHStrategy,
    "SOLStrategy": SOLStrategy,
}


class UltimateStrategy(Strategy):
    strategy_class_override, memory_instance = None, None
    score_entry_threshold_override, score_weights_tf_override = None, None
    ml_weights_override, ml_weighted_threshold_override = None, None
    for key, value in STRATEGY_PARAMS.items():
        exec(f"{key} = {value}")
    vol_weight, symbol = 1.0, None

    def init(self):
        # --- å‚æ•°å’Œèµ„äº§ç‰¹å®šç­–ç•¥çš„åˆå§‹åŒ– (åŸºæœ¬æ— å˜åŠ¨) ---
        self.ml_weighted_threshold = getattr(
            self,
            "ml_weighted_threshold_override",
            ASSET_SPECIFIC_OVERRIDES.get(self.symbol, {}).get(
                "ml_weighted_threshold", 0.3
            ),
        )
        self.regime_score_threshold = getattr(
            self,
            "regime_score_threshold_override",
            STRATEGY_PARAMS["regime_score_threshold"],
        )
        self.score_entry_threshold = getattr(
            self,
            "score_entry_threshold_override",
            ASSET_SPECIFIC_OVERRIDES.get(self.symbol, {}).get(
                "score_entry_threshold", 0.4
            ),
        )
        score_weights_override = getattr(self, "score_weights_tf_override", None)
        if score_weights_override is not None:
            self.score_weights_tf = score_weights_override
        else:
            self.score_weights_tf = ASSET_SPECIFIC_OVERRIDES.get(self.symbol, {}).get(
                "score_weights_tf", STRATEGY_PARAMS["score_weights_tf"]
            )
        self.ml_weights_dict = ASSET_SPECIFIC_OVERRIDES.get(self.symbol, {}).get(
            "ml_weights"
        )
        strategy_class_name = getattr(
            self, "strategy_class_override", "BaseAssetStrategy"
        )
        self.asset_strategy = STRATEGY_MAPPING.get(
            strategy_class_name, BaseAssetStrategy
        )(self)

        close, high, low = (
            pd.Series(self.data.Close, index=self.data.index),
            pd.Series(self.data.High, index=self.data.index),
            pd.Series(self.data.Low, index=self.data.index),
        )
        (
            self.recent_trade_returns,
            self.equity_peak,
            self.global_stop_triggered,
        ) = (
            deque(maxlen=self.kelly_trade_history),
            self.equity,
            False,
        )
        self.reset_trade_state()
        self.market_regime = self.I(lambda: self.data.market_regime)
        self.mtf_signal = self.I(lambda: self.data.mtf_signal)
        self.advanced_ml_signal = self.I(lambda: self.data.advanced_ml_signal)
        self.tf_atr = self.I(
            lambda: ta.volatility.AverageTrueRange(
                high, low, close, self.tf_atr_period
            ).average_true_range()
        )
        self.tf_donchian_h = self.I(
            lambda: high.rolling(self.tf_donchian_period).max().shift(1)
        )
        self.tf_donchian_l = self.I(
            lambda: low.rolling(self.tf_donchian_period).min().shift(1)
        )
        self.tf_ema_fast = self.I(
            lambda: ta.trend.EMAIndicator(
                close, self.tf_ema_fast_period
            ).ema_indicator()
        )
        self.tf_ema_slow = self.I(
            lambda: ta.trend.EMAIndicator(
                close, self.tf_ema_slow_period
            ).ema_indicator()
        )
        self.tf_adx = self.I(
            lambda: ta.trend.ADXIndicator(
                high, low, close, self.tf_adx_confirm_period
            ).adx()
        )
        bb = ta.volatility.BollingerBands(close, self.mr_bb_period, self.mr_bb_std)
        self.mr_bb_upper, self.mr_bb_lower, self.mr_bb_mid = (
            self.I(bb.bollinger_hband),
            self.I(bb.bollinger_lband),
            self.I(bb.bollinger_mavg),
        )
        self.mr_rsi = self.I(
            lambda: ta.momentum.RSIIndicator(close, self.mr_rsi_period).rsi()
        )

        # --- æ–°å¢ï¼šåŠ¨æ€æ¨¡å‹åŠ è½½æœºåˆ¶ ---
        self.ml_models = {}
        self.model_files_map = []
        self.next_model_load_idx = 0
        self._discover_and_prepare_models()
        self._check_and_load_model()  # åˆå§‹åŠ è½½

        self.last_checked_day = -1
        self.current_params = {"score_entry_threshold": self.score_entry_threshold}

    def _discover_and_prepare_models(self):
        """åœ¨å›æµ‹å¼€å§‹æ—¶ï¼Œå‘ç°æ‰€æœ‰å¯ç”¨çš„ã€å·²è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼Œå¹¶æŒ‰æ—¥æœŸæ’åºã€‚"""
        if self.symbol and ML_LIBS_INSTALLED:
            model_pattern = f"directional_model_{self.symbol}_*_*.joblib"
            model_files = glob.glob(model_pattern)

            parsed_files = []
            for f in model_files:
                try:
                    # ä»æ–‡ä»¶åè§£ææ—¥æœŸï¼Œä¾‹å¦‚ '..._BTCUSDT_4h_20240101.joblib'
                    date_str = f.split("_")[-1].split(".")[0]
                    model_date = pd.to_datetime(date_str, format="%Y%m%d")
                    horizon_str = f.split("_")[-2]  # '4h', '8h', '12h'
                    parsed_files.append(
                        {"date": model_date, "horizon": horizon_str, "path": f}
                    )
                except (IndexError, ValueError):
                    logger.warning(f"æ— æ³•è§£ææ¨¡å‹æ–‡ä»¶åæ ¼å¼: {f}")

            if parsed_files:
                # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œç„¶åæŒ‰æ—¥æœŸæ’åº
                df = pd.DataFrame(parsed_files)
                grouped = df.groupby("date")
                for date, group in sorted(grouped, key=lambda x: x[0]):
                    self.model_files_map.append(
                        {"date": date, "models": group.to_dict("records")}
                    )

            if self.model_files_map:
                logger.info(
                    f"[{self.symbol}] å‘ç°äº† {len(self.model_files_map)} ä¸ªè®­ç»ƒå‘¨æœŸçš„æ¨¡å‹ã€‚"
                )

    def _check_and_load_model(self):
        """æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦éœ€è¦åŠ è½½æ–°çš„æ¨¡å‹ã€‚"""
        current_timestamp = self.data.index[-1]

        # å¦‚æœè¿˜æœ‰å¾…åŠ è½½çš„æ¨¡å‹ï¼Œå¹¶ä¸”å½“å‰æ—¶é—´å·²ç»è¶…è¿‡äº†ä¸‹ä¸€ä¸ªæ¨¡å‹çš„ç”Ÿæ•ˆæ—¥æœŸ
        if (
            self.next_model_load_idx < len(self.model_files_map)
            and current_timestamp
            >= self.model_files_map[self.next_model_load_idx]["date"]
        ):

            model_set = self.model_files_map[self.next_model_load_idx]
            effective_date = model_set["date"].date()
            logger.info(f"[{self.symbol}] åŠ¨æ€åŠ è½½äº {effective_date} è®­ç»ƒçš„æ–°æ¨¡å‹...")

            loaded_count = 0
            for model_info in model_set["models"]:
                try:
                    h = int(model_info["horizon"][:-1])  # '4h' -> 4
                    self.ml_models[h] = joblib.load(model_info["path"])
                    loaded_count += 1
                except Exception as e:
                    logger.error(f"åŠ è½½æ¨¡å‹æ–‡ä»¶ {model_info['path']} å¤±è´¥: {e}")

            if loaded_count > 0:
                logger.info(f"âœ… æˆåŠŸåŠ è½½ {loaded_count} ä¸ªæ–°æ¨¡å‹ã€‚")
            self.next_model_load_idx += 1

    def next(self):
        # åœ¨æ¯ä¸ªbarï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ¨¡å‹
        self._check_and_load_model()

        # --- æ ¸å¿ƒäº¤æ˜“é€»è¾‘ (æ— å˜åŠ¨) ---
        if self.position:
            self.manage_open_position(self.data.Close[-1])
        else:
            if self.data.market_regime[-1] == 1:
                self.run_scoring_system_entry(self.data.Close[-1])
            else:
                self.run_mean_reversion_entry(self.data.Close[-1])

    # --- å…¶ä½™æ‰€æœ‰ç­–ç•¥æ–¹æ³• (`run_scoring_system_entry`, `get_ml_confidence_score` ç­‰) å‡æ— å˜åŠ¨ ---

    def run_scoring_system_entry(self, price):
        final_score = self.asset_strategy._calculate_entry_score()
        is_long = final_score > self.score_entry_threshold
        is_short = final_score < -self.score_entry_threshold
        if not (is_long or is_short):
            return
        self.open_tf_position(
            price, is_long=is_long, score=1.0, confidence_factor=abs(final_score)
        )

    def run_mean_reversion_entry(self, price):
        base_signal = self.asset_strategy._define_mr_entry_signal()
        if base_signal != 0:
            self.open_mr_position(price, is_long=(base_signal == 1))

    def get_ml_confidence_score(self) -> float:
        if not self.ml_weights_dict or not self.ml_models:
            return 0.0
        features = [col for col in self.data.df.columns if "feature_" in col]
        if self.data.df[features].iloc[-1].isnull().any():
            return 0.0
        current_features = self.data.df[features].iloc[-1:]
        confidence_score = 0.0
        for h, model in self.ml_models.items():
            try:
                pred = 1 if model.predict(current_features)[0] == 1 else -1
                confidence_score += pred * self.ml_weights_dict.get(f"{h}h", 0)
            except Exception:  # å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼Œåˆ™è·³è¿‡
                pass
        return confidence_score

    def reset_trade_state(self):
        self.active_sub_strategy = None
        self.chandelier_exit_level = 0.0
        self.highest_high_in_trade = 0
        self.lowest_low_in_trade = float("inf")
        self.mr_stop_loss = 0.0
        self.tf_initial_stop_loss = 0.0

    def manage_open_position(self, price):
        if self.active_sub_strategy == "TF":
            self.manage_trend_following_exit(price)
        elif self.active_sub_strategy == "MR":
            self.manage_mean_reversion_exit(price)

    def open_tf_position(self, price, is_long, score, confidence_factor):
        risk_per_share = self.tf_atr[-1] * self.tf_stop_loss_atr_multiplier
        if risk_per_share <= 0:
            return
        final_risk = self._calculate_dynamic_risk() * score * confidence_factor
        size = self._calculate_position_size(price, risk_per_share, final_risk)
        if not (0 < size < 0.98):
            return
        self.reset_trade_state()
        self.active_sub_strategy = "TF"
        if is_long:
            self.buy(size=size)
            self.tf_initial_stop_loss = price - risk_per_share
            self.highest_high_in_trade = self.data.High[-1]
            self.chandelier_exit_level = (
                self.highest_high_in_trade
                - self.tf_atr[-1] * self.tf_chandelier_atr_multiplier
            )
        else:
            self.sell(size=size)
            self.tf_initial_stop_loss = price + risk_per_share
            self.lowest_low_in_trade = self.data.Low[-1]
            self.chandelier_exit_level = (
                self.lowest_low_in_trade
                + self.tf_atr[-1] * self.tf_chandelier_atr_multiplier
            )

    def manage_trend_following_exit(self, price):
        atr = self.tf_atr[-1]
        if self.position.is_long:
            if price < self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.highest_high_in_trade = max(
                self.highest_high_in_trade, self.data.High[-1]
            )
            self.chandelier_exit_level = (
                self.highest_high_in_trade - atr * self.tf_chandelier_atr_multiplier
            )
            if price < self.chandelier_exit_level:
                self.close_position("TF_Chandelier")
        elif self.position.is_short:
            if price > self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            self.lowest_low_in_trade = min(self.lowest_low_in_trade, self.data.Low[-1])
            self.chandelier_exit_level = (
                self.lowest_low_in_trade + atr * self.tf_chandelier_atr_multiplier
            )
            if price > self.chandelier_exit_level:
                self.close_position("TF_Chandelier")

    def open_mr_position(self, price, is_long):
        risk_per_share = self.tf_atr[-1] * self.mr_stop_loss_atr_multiplier
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price,
            risk_per_share,
            self._calculate_dynamic_risk() * self.mr_risk_multiplier,
        )
        if not (0 < size < 0.98):
            return
        self.reset_trade_state()
        self.active_sub_strategy = "MR"
        if is_long:
            self.buy(size=size)
            self.mr_stop_loss = price - risk_per_share
        else:
            self.sell(size=size)
            self.mr_stop_loss = price + risk_per_share

    def manage_mean_reversion_exit(self, price):
        if (
            self.position.is_long
            and (price >= self.mr_bb_mid[-1] or price <= self.mr_stop_loss)
        ) or (
            self.position.is_short
            and (price <= self.mr_bb_mid[-1] or price >= self.mr_stop_loss)
        ):
            self.close_position("MR")

    def close_position(self, reason: str):
        equity_before_close = self.equity
        self.position.close()
        self.recent_trade_returns.append((self.equity / equity_before_close) - 1)
        self.reset_trade_state()

    def _calculate_position_size(self, price, risk_per_share, target_risk_pct):
        if risk_per_share <= 0 or price <= 0:
            return 0
        return (target_risk_pct * self.equity) / (risk_per_share / price) / self.equity

    def _calculate_dynamic_risk(self):
        if len(self.recent_trade_returns) < self.kelly_trade_history:
            return self.default_risk_pct * self.vol_weight
        wins, losses = [r for r in self.recent_trade_returns if r > 0], [
            r for r in self.recent_trade_returns if r < 0
        ]
        if not wins or not losses:
            return self.default_risk_pct * self.vol_weight
        win_rate = len(wins) / len(self.recent_trade_returns)
        reward_ratio = (sum(wins) / len(wins)) / (abs(sum(losses) / len(losses)))
        if reward_ratio == 0:
            return self.default_risk_pct * self.vol_weight
        kelly = win_rate - (1 - win_rate) / reward_ratio
        return min(max(0.005, kelly * 0.5) * self.vol_weight, self.max_risk_pct)


if __name__ == "__main__":
    logger.info(f"ğŸš€ (V41.01-No-News) å¼€å§‹è¿è¡Œ...")

    # --- 1. è®¡ç®—æ‰€éœ€çš„æœ€æ—©æ•°æ®æ—¥æœŸ ---
    backtest_start_dt = pd.to_datetime(CONFIG["backtest_start_date"])
    training_window = timedelta(days=CONFIG["training_window_days"])
    data_fetch_start_date = (backtest_start_dt - training_window).strftime("%Y-%m-%d")

    logger.info(
        f"å›æµ‹æ—¶é—´æ®µ: {CONFIG['backtest_start_date']} to {CONFIG['backtest_end_date']}"
    )
    logger.info(f"æ•°æ®è·å–èµ·å§‹æ—¥æœŸ (åŒ…å«è®­ç»ƒçª—å£): {data_fetch_start_date}")

    # --- 2. ä¸€æ¬¡æ€§è·å–æ‰€æœ‰éœ€è¦çš„å†å²æ•°æ® ---
    raw_data = {
        symbol: fetch_binance_klines(
            symbol,
            CONFIG["interval"],
            data_fetch_start_date,
            CONFIG["backtest_end_date"],
        )
        for symbol in CONFIG["symbols_to_test"]
    }
    raw_data = {s: d for s, d in raw_data.items() if not d.empty}
    if not raw_data:
        logger.error("æ‰€æœ‰å“ç§æ•°æ®è·å–å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        exit()

    # --- 3. æ‰§è¡Œå‰å‘å±•å¼€è®­ç»ƒ (å¦‚æœå¯ç”¨) ---
    if CONFIG["enable_walk_forward_training"]:
        logger.info("### æ¨¡å¼: å‰å‘å±•å¼€(Walk-Forward)æ¨¡å‹è®­ç»ƒ ###")

        retrain_interval = timedelta(days=CONFIG["retrain_every_days"])
        current_training_date = backtest_start_dt

        while current_training_date <= pd.to_datetime(CONFIG["backtest_end_date"]):
            training_data_start = current_training_date - training_window

            logger.info("=" * 50)
            logger.info(f"å‡†å¤‡è®­ç»ƒå‘¨æœŸï¼Œè®­ç»ƒæ•°æ®æˆªæ­¢äº: {current_training_date.date()}")
            logger.info(
                f"è®­ç»ƒæ•°æ®çª—å£: {training_data_start.date()} -> {current_training_date.date()}"
            )
            logger.info("=" * 50)

            for symbol, data in raw_data.items():
                training_slice = data.loc[
                    training_data_start:current_training_date
                ].copy()
                if training_slice.empty:
                    logger.warning(f"[{symbol}] åœ¨æ­¤è®­ç»ƒå‘¨æœŸå†…æ— æ•°æ®ï¼Œè·³è¿‡ã€‚")
                    continue

                processed_training_data = preprocess_data_for_strategy(
                    training_slice, symbol
                )
                if not processed_training_data.empty:
                    train_and_save_model(
                        processed_training_data, symbol, current_training_date
                    )

            current_training_date += retrain_interval
    else:
        logger.info("### æ¨¡å¼: è·³è¿‡æ¨¡å‹è®­ç»ƒ ###")

    # --- 4. å‡†å¤‡å®Œæ•´çš„å›æµ‹æ•°æ® ---
    logger.info(f"### å‡†å¤‡å®Œæ•´å›æµ‹æ•°æ® (å¼€å§‹æ—¥æœŸ: {CONFIG['backtest_start_date']}) ###")
    processed_backtest_data = {}
    for symbol, data in raw_data.items():
        backtest_period_slice = data.loc[CONFIG["backtest_start_date"] :].copy()
        if not backtest_period_slice.empty:
            logger.info(f"ä¸º {symbol} é¢„å¤„ç†å›æµ‹æ•°æ®...")
            processed_backtest_data[symbol] = preprocess_data_for_strategy(
                backtest_period_slice, symbol
            )

    processed_backtest_data = {
        s: d for s, d in processed_backtest_data.items() if not d.empty
    }
    if not processed_backtest_data:
        logger.error("å›æµ‹æ—¶é—´æ®µå†…æ²¡æœ‰å¯ç”¨çš„é¢„å¤„ç†æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        exit()

    # --- 5. æ‰§è¡Œå›æµ‹ ---
    logger.info(f"### è¿›å…¥å›æµ‹æ¨¡å¼ ###")
    all_stats, total_equity = {}, 0
    vols = {
        s: d.Close.resample("D").last().pct_change().std() * np.sqrt(365)
        for s, d in processed_backtest_data.items()
    }
    inv_vols = {s: 1 / v for s, v in vols.items() if v > 0}
    vol_weights = {
        s: (iv / sum(inv_vols.values())) * len(inv_vols) for s, iv in inv_vols.items()
    }

    for symbol, data in processed_backtest_data.items():
        print("\n" + "=" * 80 + f"\næ­£åœ¨å›æµ‹å“ç§: {symbol}\n" + "=" * 80)
        final_params = {
            f"{k}_override": v
            for k, v in ASSET_SPECIFIC_OVERRIDES.get(symbol, {}).items()
        }

        bt = Backtest(
            data,
            UltimateStrategy,
            cash=CONFIG["initial_cash"],
            commission=CONFIG["commission"],
            finalize_trades=True,
        )
        stats = bt.run(
            symbol=symbol, vol_weight=vol_weights.get(symbol, 1.0), **final_params
        )
        all_stats[symbol], total_equity = (
            stats,
            total_equity + stats["Equity Final [$]"],
        )
        print(
            "\n" + "-" * 40 + f"\n          {symbol} å›æµ‹ç»“æœæ‘˜è¦\n" + "-" * 40,
            stats,
        )
        if CONFIG["show_plots"]:
            bt.plot()

    if all_stats:
        initial_total = CONFIG["initial_cash"] * len(all_stats)
        ret = ((total_equity - initial_total) / initial_total) * 100
        print("\n" + "#" * 80 + "\n                 ç»„åˆç­–ç•¥è¡¨ç°æ€»è§ˆ\n" + "#" * 80)
        for symbol, stats in all_stats.items():
            print(
                f"  - {symbol}:\n    - æœ€ç»ˆæƒç›Š: ${stats['Equity Final [$]']:,.2f} (å›æŠ¥ç‡: {stats['Return [%]']:.2f}%)\n    - æœ€å¤§å›æ’¤: {stats['Max. Drawdown [%]']:.2f}%\n    - å¤æ™®æ¯”ç‡: {stats.get('Sharpe Ratio', 'N/A')}"
            )
        print(
            f"\n--- æŠ•èµ„ç»„åˆæ•´ä½“è¡¨ç° ---\næ€»åˆå§‹èµ„é‡‘: ${initial_total:,.2f}\næ€»æœ€ç»ˆæƒç›Š: ${total_equity:,.2f}\nç»„åˆæ€»å›æŠ¥ç‡: {ret:.2f}%"
        )
