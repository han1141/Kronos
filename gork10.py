# -*- coding: utf-8 -*-
import os
import time
import logging
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import joblib
import requests
import matplotlib.font_manager
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

# å°è¯•å¯¼å…¥æœºå™¨å­¦ä¹ ç›¸å…³çš„åº“
try:
    import xgboost as xgb
    from sklearn.preprocessing import RobustScaler
    from sklearn.metrics import accuracy_score
    import tensorflow as tf
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import (
        Conv1D,
        LSTM,
        Dense,
        Dropout,
        Input,
        BatchNormalization,
    )
    from tensorflow.keras.callbacks import EarlyStopping
    from tensorflow.keras.regularizers import l2

    ML_LIBS = True
except ImportError:
    ML_LIBS = False
    print(
        "è­¦å‘Š: æœªæ‰¾åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªæœºå™¨å­¦ä¹ åº“ (xgboost, scikit-learn, tensorflow)ã€‚MLåŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚"
    )


# å°è¯•å¯¼å…¥å›æµ‹ç›¸å…³çš„åº“
try:
    from backtesting import Backtest, Strategy
    from backtesting.lib import crossover
    import ta
except ImportError:
    print(
        "é”™è¯¯: æœªæ‰¾åˆ°å›æµ‹åº“ (backtesting, ta)ã€‚è¯·è¿è¡Œ 'pip install backtesting ta' è¿›è¡Œå®‰è£…ã€‚"
    )
    exit()


import warnings
from pandas.errors import SettingWithCopyWarning

# --- å…¨å±€è®¾ç½® ---
# å¿½ç•¥ç‰¹å®šçš„è­¦å‘Šä¿¡æ¯ï¼Œä¿æŒè¾“å‡ºæ•´æ´
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning, module="xgboost")
warnings.filterwarnings("ignore", category=SettingWithCopyWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# é…ç½®æ—¥å¿—è®°å½•å™¨
logging.getLogger("matplotlib").setLevel(logging.WARNING)
logging.getLogger("tensorflow").setLevel(logging.ERROR)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
formatter = logging.Formatter(
    "%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
)
if not logger.handlers:
    ch.setFormatter(formatter)
    logger.addHandler(ch)


def set_chinese_font():
    """
    è‡ªåŠ¨æŸ¥æ‰¾å¹¶è®¾ç½®å¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œç”¨äºmatplotlibç»˜å›¾ã€‚
    """
    try:
        font_names = [
            "PingFang SC",
            "Microsoft YaHei",
            "SimHei",
            "Heiti TC",
            "sans-serif",
        ]
        for font in font_names:
            if font in [f.name for f in matplotlib.font_manager.fontManager.ttflist]:
                plt.rcParams["font.sans-serif"] = [font]
                plt.rcParams["axes.unicode_minus"] = False
                logger.info(f"æˆåŠŸè®¾ç½®ä¸­æ–‡å­—ä½“: {font}")
                return
        logger.warning("æœªæ‰¾åˆ°æŒ‡å®šçš„ä¸­æ–‡å­—ä½“ï¼Œç»˜å›¾å¯èƒ½å‡ºç°ä¹±ç ã€‚")
    except Exception as e:
        logger.error(f"è®¾ç½®ä¸­æ–‡å­—ä½“æ—¶å‡ºé”™: {e}")


# --- CONFIGURATION ---
# æ ¸å¿ƒé…ç½®æ–‡ä»¶ï¼Œç”¨äºè°ƒæ•´ç­–ç•¥è¡Œä¸ºå’Œå›æµ‹è®¾ç½®
CONFIG = {
    "symbols_to_test": ["ETHUSDT"],  # æµ‹è¯•çš„äº¤æ˜“å¯¹åˆ—è¡¨
    "btc_symbol": "BTCUSDT",  # ç”¨äºè®¡ç®—ç›¸å…³æ€§çš„åŸºå‡†èµ„äº§
    "interval": "1h",  # Kçº¿æ—¶é—´å‘¨æœŸ
    "backtest_start_date": "2025-05-01",  # å›æµ‹å¼€å§‹æ—¥æœŸ
    "backtest_end_date": "2025-10-18",  # å›æµ‹ç»“æŸæ—¥æœŸ
    "initial_cash": 500_000,  # åˆå§‹èµ„é‡‘
    "commission": 0.001,  # äº¤æ˜“æ‰‹ç»­è´¹
    "spread": 0.0005,  # æ¨¡æ‹Ÿä¹°å–ä»·å·®
    "show_plots": False,  # æ˜¯å¦æ˜¾ç¤ºå¹¶ä¿å­˜ç»“æœå›¾è¡¨
    "training_window_days": 365 * 3,  # æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ•°æ®çš„æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰
    "ml_training_gap_days": 30,  # è®­ç»ƒæ•°æ®å’Œå›æµ‹æ•°æ®ä¹‹é—´çš„æ—¶é—´éš”ç¦»æœŸï¼Œé˜²æ­¢å‰è§†åå·®
    # [V49.1 æ–°å¢] å¼€å…³ï¼šæ˜¯å¦ä½¿ç”¨å·²å­˜åœ¨çš„MLæ¨¡å‹è¿›è¡Œå›æµ‹ã€‚
    # è‹¥ä¸ºTrueï¼Œåˆ™è·³è¿‡è®­ç»ƒè¿‡ç¨‹ï¼Œç›´æ¥åŠ è½½æœ¬åœ°æ¨¡å‹æ–‡ä»¶ã€‚è¿™åœ¨è°ƒè¯•éMLå‚æ•°æ—¶éå¸¸æœ‰ç”¨ã€‚
    "use_pretrained_models": True,
    # ç­–ç•¥æ¨¡å—å¼€å…³ï¼Œç”¨äºè¿›è¡Œæ¶ˆèç ”ç©¶(Ablation Study)æˆ–å…³é—­ç‰¹å®šé€»è¾‘
    "enabled_modules": {
        "trend_following": True,  # è¶‹åŠ¿è·Ÿè¸ªæ¨¡å—
        "mean_reversion": True,  # å‡å€¼å›å½’æ¨¡å—
        "ml_filter": True,  # æœºå™¨å­¦ä¹ è¿‡æ»¤å™¨æ¨¡å—
        "lpr_mode": True,  # åˆ©æ¶¦å¥”è·‘æ¨¡å¼ (LPR)
    },
}

# --- STRATEGY PARAMETERS ---
# ç­–ç•¥å†…éƒ¨ä½¿ç”¨çš„è¯¦ç»†å‚æ•°ï¼Œç”¨äºæŠ€æœ¯æŒ‡æ ‡å’Œäº¤æ˜“é€»è¾‘
STRATEGY_PARAMS = {
    # é£é™©ç®¡ç†
    "kelly_trade_history": 20,  # è®¡ç®—å‡¯åˆ©å…¬å¼æ‰€ç”¨çš„å†å²äº¤æ˜“æ¬¡æ•°
    "default_risk_pct": 0.015,  # é»˜è®¤å•ç¬”é£é™©ç™¾åˆ†æ¯”
    "max_risk_pct": 0.04,  # æœ€å¤§å•ç¬”é£é™©ç™¾åˆ†æ¯”
    # å¸‚åœºçŠ¶æ€åˆ¤æ–­ (Regime Filter)
    "regime_adx_period": 14,
    "regime_atr_period": 14,
    "regime_atr_slope_period": 5,
    "regime_rsi_period": 14,
    "regime_rsi_vol_period": 14,
    "regime_norm_period": 252,  # å½’ä¸€åŒ–å‘¨æœŸ
    "regime_hurst_period": 100,  # HurstæŒ‡æ•°è®¡ç®—å‘¨æœŸ
    "regime_score_weight_adx": 0.6,
    "regime_score_weight_atr": 0.3,
    "regime_score_weight_rsi": 0.05,
    "regime_score_weight_hurst": 0.05,
    "regime_score_threshold": 0.55,  # åŒºåˆ†è¶‹åŠ¿/éœ‡è¡å¸‚åœºçš„é˜ˆå€¼
    # è¶‹åŠ¿è·Ÿè¸ªæ¨¡å— (Trend Following)
    "tf_donchian_period": 30,
    "tf_ema_fast_period": 20,
    "tf_ema_slow_period": 75,
    "tf_adx_confirm_period": 14,
    "tf_adx_confirm_threshold": 18,
    "tf_chandelier_period": 22,
    "tf_chandelier_atr_multiplier": 3.0,
    "tf_atr_period": 14,
    "tf_stop_loss_atr_multiplier": 2.5,
    # å‡å€¼å›å½’æ¨¡å— (Mean Reversion)
    "mr_bb_period": 20,
    "mr_bb_std": 2.0,
    "mr_rsi_period": 14,
    "mr_rsi_oversold": 30,
    "mr_rsi_overbought": 70,
    "mr_stop_loss_atr_multiplier": 1.5,
    "mr_risk_multiplier": 0.5,  # å‡å€¼å›å½’ç›¸å¯¹è¶‹åŠ¿è·Ÿè¸ªçš„é£é™©ç³»æ•°
    # å¤šæ—¶é—´æ¡†æ¶ä¿¡å·
    "mtf_period": 50,  # æ—¥çº¿çº§åˆ«SMAå‘¨æœŸ
    # è¿›åœºè¯„åˆ†ç³»ç»Ÿ
    "score_entry_threshold": 0.65,
    "score_weights_tf": {"breakout": 0.5, "momentum": 0.3, "mtf": 0.2},
    # åˆ©æ¶¦å¥”è·‘æ¨¡å¼ (Let Profits Run)
    "lpr_enabled": True,
    "lpr_trigger_pct": 0.05,  # æ¿€æ´»LPRæ¨¡å¼çš„ç›ˆåˆ©ç™¾åˆ†æ¯”
    "lpr_trail_atr_multiplier": 2.0,  # LPRæ¨¡å¼ä¸‹çš„ç§»åŠ¨æ­¢æŸATRå€æ•°
    # æœºå™¨å­¦ä¹ è¿‡æ»¤å™¨
    "ml_filter_enabled": True,
    "lstm_sequence_length": 48,  # LSTMæ¨¡å‹è¾“å…¥åºåˆ—é•¿åº¦
    "lstm_epochs": 60,
    "lstm_batch_size": 128,
    "lstm_l2_reg": 0.001,  # LSTM L2æ­£åˆ™åŒ–ç³»æ•°
    "xgb_nrounds": 250,
    "xgb_gamma": 0.3,  # XGBoost Gammaæ­£åˆ™åŒ–
    "xgb_lambda": 1.5,  # XGBoost Lambda(L2)æ­£åˆ™åŒ–
    "ensemble_w_lstm": 0.4,  # é›†æˆæ¨¡å‹ä¸­LSTMçš„æƒé‡
    "ensemble_w_xgb": 0.6,  # é›†æˆæ¨¡å‹ä¸­XGBoostçš„æƒé‡
    "ml_confidence_threshold": 0.65,  # MLæ¨¡å‹é¢„æµ‹æ¦‚ç‡çš„ç½®ä¿¡åº¦é˜ˆå€¼
    "ml_score_weight": 0.2,  # MLé¢„æµ‹ç»“æœå¯¹æœ€ç»ˆå¾—åˆ†çš„è´¡çŒ®æƒé‡
}


def fetch_binance_klines(
    symbol, interval, start_str, end_str=None, limit=1000, cache_dir="data_cache"
):
    """
    ä»å¸å®‰APIè·å–Kçº¿æ•°æ®ï¼Œå¹¶å®ç°æœ¬åœ°ç¼“å­˜æœºåˆ¶ã€‚
    """
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"{symbol}_{interval}.csv")

    start_dt = pd.to_datetime(start_str, utc=True)
    end_dt = pd.to_datetime(end_str, utc=True) if end_str else datetime.utcnow()

    # å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®
    if os.path.exists(cache_file):
        try:
            df = pd.read_csv(cache_file, index_col="timestamp", parse_dates=True)
            if not df.empty and df.index[0] <= start_dt and df.index[-1] >= end_dt:
                logger.info(f"âœ… ä»ç¼“å­˜åŠ è½½ {symbol} æ•°æ®: {cache_file}")
                return df.loc[start_dt:end_dt]
        except Exception as e:
            logger.warning(f"è¯»å–ç¼“å­˜æ–‡ä»¶ {cache_file} å¤±è´¥: {e}")

    logger.info(f"å¼€å§‹ä»å¸å®‰APIä¸‹è½½ {symbol} æ•°æ®...")
    url = "https://api.binance.com/api/v3/klines"
    all_data = []
    current_start_ts = int(start_dt.timestamp() * 1000)
    end_ts = int(end_dt.timestamp() * 1000)

    while current_start_ts < end_ts:
        params = {
            "symbol": symbol.upper(),
            "interval": interval,
            "startTime": current_start_ts,
            "endTime": end_ts,
            "limit": limit,
        }
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            if not data:
                break
            all_data.extend(data)
            current_start_ts = data[-1][0] + 1
        except requests.exceptions.RequestException as e:
            logger.warning(f"è·å– {symbol} æ—¶é‡åˆ°è¿æ¥é—®é¢˜: {e}ã€‚5ç§’åé‡è¯•...")
            time.sleep(5)

    if not all_data:
        logger.error(f"æœªèƒ½è·å–åˆ° {symbol} çš„ä»»ä½•æ•°æ®ã€‚")
        return pd.DataFrame()

    df = pd.DataFrame(
        all_data,
        columns=[
            "timestamp",
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "close_time",
            "quote_asset_volume",
            "number_of_trades",
            "taker_buy_base_asset_volume",
            "taker_buy_quote_asset_volume",
            "ignore",
        ],
    )
    df = df[["timestamp", "Open", "High", "Low", "Close", "Volume"]].copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
    for col in df.columns[1:]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df.drop_duplicates(subset=["timestamp"], inplace=True)
    df = df.set_index("timestamp").sort_index()

    # ä¿å­˜åˆ°ç¼“å­˜
    df.to_csv(cache_file)
    logger.info(f"âœ… {symbol} æ•°æ®å·²ç¼“å­˜è‡³: {cache_file}")
    return df.loc[start_dt:end_dt]


def compute_hurst(ts, max_lag=100):
    """è®¡ç®—æ—¶é—´åºåˆ—çš„HurstæŒ‡æ•°ã€‚"""
    if len(ts) < 10:
        return 0.5
    lags = range(2, min(max_lag, len(ts) // 2 + 1))
    tau = []
    for lag in lags:
        diff = np.subtract(ts[lag:], ts[:-lag])
        std = np.std(diff)
        if std > 0:
            tau.append(std)
    if len(tau) < 2:
        return 0.5
    try:
        # ä½¿ç”¨å¯¹æ•°-å¯¹æ•°å›å½’ä¼°è®¡HurstæŒ‡æ•°
        return max(
            0.0, min(1.0, np.polyfit(np.log(lags[: len(tau)]), np.log(tau), 1)[0])
        )
    except np.linalg.LinAlgError:
        return 0.5


def add_all_features(df: pd.DataFrame, btc_df: pd.DataFrame = None) -> pd.DataFrame:
    """ä¸ºç»™å®šçš„DataFrameè®¡ç®—å¹¶æ·»åŠ æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œç‰¹å¾ã€‚"""
    df = df.copy()
    p = STRATEGY_PARAMS

    # --- å¸‚åœºçŠ¶æ€åˆ¤æ–­ç‰¹å¾ ---
    norm = lambda s: (
        (s - s.rolling(p["regime_norm_period"]).min())
        / (
            s.rolling(p["regime_norm_period"]).max()
            - s.rolling(p["regime_norm_period"]).min()
        )
    ).fillna(0.5)

    adx = ta.trend.ADXIndicator(df.High, df.Low, df.Close, p["regime_adx_period"]).adx()
    atr = ta.volatility.AverageTrueRange(
        df.High, df.Low, df.Close, p["regime_atr_period"]
    ).average_true_range()
    rsi = ta.momentum.RSIIndicator(df.Close, p["regime_rsi_period"]).rsi()

    df["regime_adx_norm"] = norm(adx)
    df["regime_atr_slope_norm"] = norm(
        (atr - atr.shift(p["regime_atr_slope_period"]))
        / atr.shift(p["regime_atr_slope_period"])
    )
    df["regime_rsi_vol_norm"] = 1 - norm(rsi.rolling(p["regime_rsi_vol_period"]).std())
    df["regime_hurst"] = (
        df.Close.rolling(p["regime_hurst_period"])
        .apply(lambda x: compute_hurst(np.log(x + 1e-9)), raw=False)
        .fillna(0.5)
    )

    df["regime_score"] = (
        df["regime_adx_norm"] * p["regime_score_weight_adx"]
        + df["regime_atr_slope_norm"] * p["regime_score_weight_atr"]
        + df["regime_rsi_vol_norm"] * p["regime_score_weight_rsi"]
        + np.clip((df["regime_hurst"] - 0.3) / 0.7, 0, 1)
        * p["regime_score_weight_hurst"]
    )
    df["market_regime"] = np.where(
        df["regime_score"] > p["regime_score_threshold"], 1, -1
    )  # 1 for Trend, -1 for Mean Reversion

    # --- å¤šæ—¶é—´æ¡†æ¶ (MTF) ç‰¹å¾ ---
    df_1d = (
        df.resample("1D")
        .agg(
            {
                "Open": "first",
                "High": "max",
                "Low": "min",
                "Close": "last",
                "Volume": "sum",
            }
        )
        .dropna()
    )
    if not df_1d.empty:
        sma_daily = ta.trend.SMAIndicator(
            df_1d["Close"], window=p["mtf_period"]
        ).sma_indicator()
        df["mtf_signal"] = (
            pd.Series(np.where(df_1d["Close"] > sma_daily, 1, -1), index=df_1d.index)
            .reindex(df.index, method="ffill")
            .fillna(0)
        )
    else:
        df["mtf_signal"] = 0

    # --- æœºå™¨å­¦ä¹  (ML) ç‰¹å¾ ---
    df["feature_log_return_1"] = np.log(df.Close / df.Close.shift(1))
    df["feature_rsi_14"] = ta.momentum.RSIIndicator(df.Close, 14).rsi()
    df["feature_atr_14_pct"] = (
        ta.volatility.AverageTrueRange(
            df.High, df.Low, df.Close, 14
        ).average_true_range()
        / df.Close
    )
    df["feature_bb_width"] = (
        ta.volatility.BollingerBands(df.Close, 20).bollinger_hband()
        - ta.volatility.BollingerBands(df.Close, 20).bollinger_lband()
    ) / df.Close
    df["feature_close_ma_200_ratio"] = (
        df.Close / ta.trend.EMAIndicator(df.Close, 200).ema_indicator()
    )
    df["feature_atr_std_ratio"] = (
        df["feature_atr_14_pct"].rolling(20).std() / df["feature_atr_14_pct"]
    )

    if btc_df is not None and not btc_df.empty:
        btc_log_ret = np.log(btc_df.Close / btc_df.Close.shift(1))
        df["feature_btc_log_return"] = btc_log_ret.reindex(df.index, method="ffill")
        df["feature_btc_corr_120"] = (
            df["feature_log_return_1"].rolling(120).corr(df["feature_btc_log_return"])
        )

    df["feature_hour"] = df.index.hour
    df["feature_dayofweek"] = df.index.dayofweek

    # æ¸…ç†æ•°æ®
    df.ffill(inplace=True)
    df.bfill(inplace=True)
    df.dropna(inplace=True)
    return df


def make_asymmetric_labels(
    df, look_forward=30, risk_reward_ratio=2.0, sl_atr_multiplier=1.5
):
    """
    åˆ›å»ºéå¯¹ç§°æ ‡ç­¾ï¼ˆä¸‰åˆ†ç±»ï¼šç›ˆåˆ©ã€äºæŸã€æœªè§¦åŠï¼‰ï¼Œç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒã€‚
    1: ä»·æ ¼å…ˆè§¦åŠç›ˆåˆ©ç›®æ ‡ (TP)
    0: ä»·æ ¼å…ˆè§¦åŠæ­¢æŸç›®æ ‡ (SL)
    """
    atr = ta.volatility.AverageTrueRange(
        df.High, df.Low, df.Close, 14
    ).average_true_range()
    upper_barrier = df.Close + (atr * sl_atr_multiplier * risk_reward_ratio)
    lower_barrier = df.Close - (atr * sl_atr_multiplier)
    labels = pd.Series(np.nan, index=df.index)

    for i in range(len(df) - look_forward):
        entry_idx = df.index[i]
        path = df.iloc[i + 1 : i + 1 + look_forward]
        upper_touch_time = path[path.High >= upper_barrier.loc[entry_idx]].index.min()
        lower_touch_time = path[path.Low <= lower_barrier.loc[entry_idx]].index.min()

        if pd.notna(upper_touch_time) and pd.notna(lower_touch_time):
            labels.loc[entry_idx] = 1 if upper_touch_time <= lower_touch_time else 0
        elif pd.notna(upper_touch_time):
            labels.loc[entry_idx] = 1
        elif pd.notna(lower_touch_time):
            labels.loc[entry_idx] = 0
    return labels


def create_sequences(X, y, seq_len):
    """å°†æ•°æ®è½¬æ¢ä¸ºé€‚ç”¨äºLSTMçš„åºåˆ—æ ¼å¼ã€‚"""
    Xs, ys = [], []
    for i in range(len(X) - seq_len):
        Xs.append(X[i : i + seq_len])
        ys.append(y[i + seq_len])
    return np.array(Xs), np.array(ys)


# --- MACHINE LEARNING MODELS ---


def train_and_save_lstm(training_df, symbol, seq_len, epochs, batch_size):
    """è®­ç»ƒå¹¶ä¿å­˜LSTMæ¨¡å‹ã€‚"""
    logger.info(f"ä¸º {symbol} è®­ç»ƒ LSTM æ¨¡å‹...")
    labels = make_asymmetric_labels(training_df)
    df = training_df.join(labels.rename("target")).dropna(subset=["target"])
    df.loc[:, "target"] = df["target"].astype(int)
    features = [c for c in df.columns if c.startswith("feature_")]
    X, y = df[features].values, df["target"].values

    if len(np.unique(y)) < 2:
        logger.warning(f"[{symbol}] è®­ç»ƒæ•°æ®ä¸­åªå­˜åœ¨ä¸€ä¸ªç±»åˆ«ï¼Œè·³è¿‡ LSTM è®­ç»ƒã€‚")
        return None

    split = int(len(X) * 0.8)
    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]

    scaler = RobustScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    joblib.dump(scaler, f"lstm_scaler_{symbol}.pkl")

    X_train_seq, y_train_seq = create_sequences(X_train_s, y_train, seq_len)
    X_test_seq, y_test_seq = create_sequences(X_test_s, y_test, seq_len)

    if len(X_train_seq) == 0:
        logger.error(f"[{symbol}] è½¬æ¢åçš„åºåˆ—æ ·æœ¬æ•°é‡ä¸º0ï¼Œæ— æ³•è®­ç»ƒ LSTMã€‚")
        return None
    if np.unique(y_train_seq).size < 2 or np.unique(y_test_seq).size < 2:
        logger.warning(
            f"[{symbol}] è®­ç»ƒé›†æˆ–æµ‹è¯•é›†åºåˆ—ä¸­åªå­˜åœ¨ä¸€ä¸ªç±»åˆ«ï¼Œè·³è¿‡ LSTM è®­ç»ƒã€‚"
        )
        return None

    l2_reg = STRATEGY_PARAMS.get("lstm_l2_reg", 0.001)
    model = Sequential(
        [
            Input(shape=(seq_len, X_train_seq.shape[2])),
            Conv1D(64, kernel_size=5, activation="relu", kernel_regularizer=l2(l2_reg)),
            BatchNormalization(),
            Dropout(0.2),
            LSTM(128, return_sequences=True, kernel_regularizer=l2(l2_reg)),
            Dropout(0.3),
            LSTM(64, kernel_regularizer=l2(l2_reg)),
            Dropout(0.3),
            Dense(64, activation="relu", kernel_regularizer=l2(l2_reg)),
            Dense(1, activation="sigmoid"),
        ]
    )
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
        loss="binary_crossentropy",
        metrics=["accuracy"],
    )
    es = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
    model.fit(
        X_train_seq,
        y_train_seq,
        validation_data=(X_test_seq, y_test_seq),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[es],
        verbose=0,
    )

    loss, acc = model.evaluate(X_test_seq, y_test_seq, verbose=0)
    logger.info(f"LSTM for {symbol} - æ—¶é—´å¤–æ ·æœ¬å‡†ç¡®ç‡: {acc:.4f}")
    model.save(f"lstm_model_{symbol}.keras")
    return acc


def train_and_save_xgb(training_df, symbol):
    """è®­ç»ƒå¹¶ä¿å­˜XGBoostæ¨¡å‹ã€‚"""
    logger.info(f"ä¸º {symbol} è®­ç»ƒ XGBoost æ¨¡å‹...")
    labels = make_asymmetric_labels(training_df)
    df = training_df.join(labels.rename("target")).dropna(subset=["target"])
    df.loc[:, "target"] = df["target"].astype(int)
    features = [c for c in df.columns if c.startswith("feature_")]
    X, y = df[features].values, df["target"].values

    if len(np.unique(y)) < 2:
        logger.warning(f"[{symbol}] è®­ç»ƒæ•°æ®ä¸­åªå­˜åœ¨ä¸€ä¸ªç±»åˆ«ï¼Œè·³è¿‡ XGBoost è®­ç»ƒã€‚")
        return None

    split = int(len(X) * 0.8)
    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]

    scaler = RobustScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    joblib.dump(scaler, f"xgb_scaler_{symbol}.pkl")

    model = xgb.XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        use_label_encoder=False,
        n_estimators=STRATEGY_PARAMS["xgb_nrounds"],
        learning_rate=0.02,
        max_depth=3,
        subsample=0.7,
        colsample_bytree=0.7,
        gamma=STRATEGY_PARAMS.get("xgb_gamma", 0.3),
        reg_lambda=STRATEGY_PARAMS.get("xgb_lambda", 1.5),
        early_stopping_rounds=25,
    )
    model.fit(X_train_s, y_train, eval_set=[(X_test_s, y_test)], verbose=False)
    acc = accuracy_score(y_test, model.predict(X_test_s))
    logger.info(f"XGBoost for {symbol} - æ—¶é—´å¤–æ ·æœ¬å‡†ç¡®ç‡: {acc:.4f}")
    joblib.dump(model, f"xgb_model_{symbol}.joblib")
    return acc


# --- PLOTTING & ANALYSIS ---


def plot_walk_forward_equity(
    equity_curves, combined_trades, initial_cash, title="æ»šåŠ¨å›æµ‹æƒç›Šæ›²çº¿"
):
    """ç»˜åˆ¶å¹¶å°†æ»šåŠ¨å›æµ‹çš„æƒç›Šæ›²çº¿æ‹¼æ¥æˆä¸€å¼ æ€»å›¾ã€‚"""
    plt.style.use("seaborn-v0_8-darkgrid")
    fig, ax = plt.subplots(figsize=(15, 8))

    # æ‹¼æ¥æ‰€æœ‰å‘¨æœŸçš„æƒç›Šæ›²çº¿
    full_equity_curve = pd.Series([initial_cash])
    for i, curve in enumerate(equity_curves):
        period_equity = curve["Equity"]
        if i > 0:
            start_val = full_equity_curve.iloc[-1]
            period_equity = period_equity / period_equity.iloc[0] * start_val
        full_equity_curve = pd.concat([full_equity_curve.iloc[:-1], period_equity])

    full_equity_curve.plot(
        ax=ax, label="æ€»æƒç›Šæ›²çº¿ (Total Equity)", color="blue", linewidth=2.5
    )

    # ç»˜åˆ¶å‘¨æœŸåˆ†å‰²çº¿
    for curve in equity_curves:
        start_date = curve.index[0]
        ax.axvline(
            x=start_date,
            color="grey",
            linestyle="--",
            linewidth=0.8,
            label="å‘¨æœŸåˆ†å‰²çº¿" if start_date == equity_curves[0].index[0] else "",
        )

    formatter = mticker.FuncFormatter(lambda x, p: f"${x:,.0f}")
    ax.yaxis.set_major_formatter(formatter)
    plt.title(title, fontsize=16)
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("è´¦æˆ·æƒç›Š ($)")
    plt.legend()
    plt.grid(True)
    filename = "equity_curve.png"
    plt.savefig(filename)
    logger.info(f"âœ… æƒç›Šæ›²çº¿å›¾å·²ä¿å­˜è‡³: {filename}")
    plt.close(fig)


def analyze_trade_distribution(combined_trades, title="äº¤æ˜“ç›ˆäº (PnL) åˆ†å¸ƒ"):
    """åˆ†æå¹¶ç»˜åˆ¶æ‰€æœ‰äº¤æ˜“çš„ç›ˆäºåˆ†å¸ƒç›´æ–¹å›¾ã€‚"""
    if combined_trades.empty:
        logger.warning("æ²¡æœ‰äº¤æ˜“è®°å½•ï¼Œæ— æ³•ç”Ÿæˆæ”¶ç›Šåˆ†å¸ƒå›¾ã€‚")
        return
    pnl = combined_trades["PnL"]
    wins = pnl[pnl > 0]
    losses = pnl[pnl < 0]

    plt.style.use("seaborn-v0_8-darkgrid")
    fig, ax = plt.subplots(figsize=(15, 8))
    ax.hist(
        losses, bins=50, color="salmon", alpha=0.7, label=f"äºæŸäº¤æ˜“ (n={len(losses)})"
    )
    ax.hist(
        wins, bins=50, color="skyblue", alpha=0.7, label=f"ç›ˆåˆ©äº¤æ˜“ (n={len(wins)})"
    )

    stats_text = (
        f"ç›ˆåˆ©äº¤æ˜“:\n  - æ•°é‡: {len(wins)}\n  - å¹³å‡ç›ˆåˆ©: ${wins.mean():,.2f}\n  - ç›ˆåˆ©æ ‡å‡†å·®: ${wins.std():,.2f}\n\n"
        f"äºæŸäº¤æ˜“:\n  - æ•°é‡: {len(losses)}\n  - å¹³å‡äºæŸ: ${losses.mean():,.2f}\n  - äºæŸæ ‡å‡†å·®: ${losses.std():,.2f}"
    )
    ax.text(
        0.02,
        0.98,
        stats_text,
        transform=ax.transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=dict(boxstyle="round,pad=0.5", fc="wheat", alpha=0.5),
    )

    plt.title(title, fontsize=16)
    plt.xlabel("å•ç¬”äº¤æ˜“ç›ˆäº ($)")
    plt.ylabel("äº¤æ˜“æ¬¡æ•°")
    plt.legend()
    plt.grid(True)
    filename = "trade_distribution.png"
    plt.savefig(filename)
    logger.info(f"âœ… äº¤æ˜“åˆ†å¸ƒå›¾å·²ä¿å­˜è‡³: {filename}")
    plt.close(fig)


def generate_optimization_suggestions(stats, model_accuracies, config):
    """æ ¹æ®å›æµ‹ç»“æœï¼Œç”Ÿæˆæ™ºèƒ½ä¼˜åŒ–å»ºè®®ã€‚"""
    logger.info("\n" + "#" * 80 + "\n                 ğŸ§  AI ä¼˜åŒ–å»ºè®®å™¨\n" + "#" * 80)
    suggestions = []

    # å…³äºç›ˆäºå› å­çš„å»ºè®®
    if stats["Profit Factor"] < 1.1:
        suggestions.append(
            "ğŸš¨ æ ¸å¿ƒé—®é¢˜: ç›ˆäºå› å­ä½äº1.1ï¼Œç­–ç•¥ç›ˆåˆ©èƒ½åŠ›éå¸¸è„†å¼±ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: ä¼˜å…ˆæé«˜ä¿¡å·è´¨é‡ï¼Œè€Œä¸æ˜¯å¢åŠ äº¤æ˜“é¢‘ç‡ã€‚è€ƒè™‘æé«˜ `score_entry_threshold` ä»¥è¿‡æ»¤æ‰æ›´å¤šå¼±ä¿¡å·ã€‚"
        )
    elif stats["Profit Factor"] < 1.3:
        suggestions.append(
            "âš ï¸ æ³¨æ„: ç›ˆäºå› å­ (1.1-1.3) å°šå¯ï¼Œä½†æœ‰æå‡ç©ºé—´ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: å®¡è§†äºæŸäº¤æ˜“ï¼Œæ£€æŸ¥æ˜¯å¦èƒ½é€šè¿‡è°ƒæ•´æ­¢æŸ (`tf_stop_loss_atr_multiplier`) æˆ–è¶‹åŠ¿è¯†åˆ«å‚æ•°æ¥è§„é¿éƒ¨åˆ†äºæŸã€‚"
        )
    else:
        suggestions.append(
            "âœ… ä¼˜åŠ¿: ç›ˆäºå› å­ (>=1.3) è¡¨ç°è‰¯å¥½ï¼Œç­–ç•¥å…·å¤‡ä¸é”™çš„ç›ˆåˆ©èƒ½åŠ›ã€‚"
        )

    # å…³äºèƒœç‡çš„å»ºè®®
    if stats["Win Rate [%]"] < 40:
        suggestions.append(
            f"âš ï¸ æ³¨æ„: èƒœç‡ ({stats['Win Rate [%]']:.2f}%) åä½ï¼Œå¯èƒ½å¯¼è‡´å›æ’¤è¾ƒå¤§ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: 1. æé«˜ `score_entry_threshold`ã€‚ 2. æé«˜æœºå™¨å­¦ä¹ çš„ç½®ä¿¡åº¦é—¨æ§› `ml_confidence_threshold`ã€‚"
        )
    else:
        suggestions.append(
            f"âœ… ä¼˜åŠ¿: èƒœç‡ ({stats['Win Rate [%]']:.2f}%) å¤„äºå¯æ¥å—èŒƒå›´ã€‚"
        )

    # å…³äºæœºå™¨å­¦ä¹ æ¨¡å‹è¡¨ç°çš„å»ºè®®
    if model_accuracies:
        avg_lstm_acc = np.mean([acc.get("lstm", 0.5) for acc in model_accuracies])
        avg_xgb_acc = np.mean([acc.get("xgb", 0.5) for acc in model_accuracies])
        if avg_lstm_acc < 0.52:
            suggestions.append(
                f"ğŸ“‰ æ¨¡å‹é—®é¢˜: LSTM å¹³å‡å‡†ç¡®ç‡ ({avg_lstm_acc:.2%}) è¿‡ä½ï¼Œå‡ ä¹æ²¡æœ‰é¢„æµ‹èƒ½åŠ›ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: 1. å¤§å¹…é™ä½å…¶åœ¨é›†æˆæ¨¡å‹ä¸­çš„æƒé‡ (`ensemble_w_lstm`)ã€‚ 2. è€ƒè™‘ä»é›†æˆä¸­ç§»é™¤LSTM (é€šè¿‡ enabled_modules è®¾ç½®)ã€‚"
            )
        if avg_xgb_acc < 0.53:
            suggestions.append(
                f"ğŸ“‰ æ¨¡å‹é—®é¢˜: XGBoost å¹³å‡å‡†ç¡®ç‡ ({avg_xgb_acc:.2%}) åä½ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: 1. è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œç§»é™¤é‡è¦æ€§ä½çš„ç‰¹å¾ã€‚ 2. è°ƒæ•´`make_asymmetric_labels`ä¸­çš„å‚æ•°ã€‚"
            )
        if avg_xgb_acc > avg_lstm_acc + 0.02:
            suggestions.append(
                f"ğŸ’¡ æ¨¡å‹æ´å¯Ÿ: XGBoost (acc: {avg_xgb_acc:.2%}) è¡¨ç°æ˜¾è‘—ä¼˜äº LSTM (acc: {avg_lstm_acc:.2%})ã€‚\n   >> ä¼˜åŒ–æ–¹å‘: è°ƒæ•´é›†æˆæƒé‡ï¼Œç»™äºˆXGBoostæ›´å¤§çš„è¯è¯­æƒï¼Œä¾‹å¦‚ `ensemble_w_xgb` è°ƒæ•´è‡³ 0.7 æˆ–æ›´é«˜ã€‚"
            )

    for i, suggestion in enumerate(suggestions):
        logger.info(f"\n--- å»ºè®® {i+1} ---\n{suggestion}")
    logger.info("\n" + "#" * 80)


# --- STRATEGY IMPLEMENTATION ---


class BaseAssetStrategy:
    """
    ä¸€ä¸ªè¾…åŠ©ç±»ï¼Œç”¨äºå°è£…ç‰¹å®šèµ„äº§æˆ–é€šç”¨çš„äº¤æ˜“é€»è¾‘è®¡ç®—ï¼Œä½¿ä¸»ç­–ç•¥ç±»æ›´æ¸…æ™°ã€‚
    """

    def __init__(self, main_strategy: Strategy):
        self.main = main_strategy

    def _calculate_entry_score(self) -> float:
        """è®¡ç®—è¶‹åŠ¿è·Ÿè¸ªéƒ¨åˆ†çš„TAåŸºç¡€å¾—åˆ†ã€‚"""
        m, w = self.main, self.main.score_weights_tf
        # çªç ´ä¿¡å·
        breakout_signal = (
            1
            if m.data.High[-1] > m.tf_donchian_h[-2]
            else -1 if m.data.Low[-1] < m.tf_donchian_l[-2] else 0
        )
        # åŠ¨é‡ä¿¡å·
        momentum_signal = 1 if m.tf_ema_fast[-1] > m.tf_ema_slow[-1] else -1
        # ç»„åˆå¾—åˆ†
        return (
            breakout_signal * w.get("breakout", 0)
            + momentum_signal * w.get("momentum", 0)
            + m.mtf_signal[-1] * w.get("mtf", 0)
        )

    def _define_mr_entry_signal(self) -> int:
        """å®šä¹‰å‡å€¼å›å½’çš„è¿›åœºä¿¡å·ã€‚"""
        m = self.main
        is_long_signal = (
            crossover(m.data.Close, m.mr_bb_lower) and m.mr_rsi[-1] < m.mr_rsi_oversold
        )
        is_short_signal = (
            crossover(m.mr_bb_upper, m.data.Close)
            and m.mr_rsi[-1] > m.mr_rsi_overbought
        )
        return 1 if is_long_signal else -1 if is_short_signal else 0


class UltimateStrategy(Strategy):
    """
    ç»ˆææ··åˆç­–ç•¥ï¼Œç»“åˆäº†å¸‚åœºçŠ¶æ€åˆ¤æ–­ã€è¶‹åŠ¿è·Ÿè¸ªã€å‡å€¼å›å½’ä»¥åŠæœºå™¨å­¦ä¹ è¿‡æ»¤å™¨ã€‚
    """

    symbol = None  # å°†ç”±runæ–¹æ³•ä¼ å…¥
    vol_weight = 1.0  # æ³¢åŠ¨ç‡æƒé‡ï¼Œæœªæ¥å¯æ‰©å±•
    enabled_modules = None  # æ¨¡å—å¼€å…³ï¼Œå°†ç”±runæ–¹æ³•ä¼ å…¥

    def init(self):
        """ç­–ç•¥åˆå§‹åŒ–ï¼ŒåŠ è½½å‚æ•°å’ŒæŒ‡æ ‡ã€‚"""
        # åŠ è½½åŸºç¡€å‚æ•°
        for k, v in STRATEGY_PARAMS.items():
            setattr(self, k, v)

        # ä»CONFIGåŠ è½½æ¨¡å—å¼€å…³
        if self.enabled_modules is None:
            self.enabled_modules = CONFIG.get("enabled_modules", {})

        self.asset_strategy = BaseAssetStrategy(self)

        # å‡†å¤‡æ•°æ®åºåˆ—ï¼Œç”¨äºæŒ‡æ ‡è®¡ç®—
        c = pd.Series(self.data.Close)
        h = pd.Series(self.data.High)
        l = pd.Series(self.data.Low)

        self.reset_trade_state()

        # --- åˆå§‹åŒ–æŒ‡æ ‡ ---
        self.market_regime = self.I(lambda: self.data.market_regime)
        self.mtf_signal = self.I(lambda: self.data.mtf_signal)

        # è¶‹åŠ¿è·Ÿè¸ªæŒ‡æ ‡
        self.tf_atr = self.I(
            lambda: ta.volatility.AverageTrueRange(
                h, l, c, self.tf_atr_period
            ).average_true_range(),
            plot=False,
        )
        self.tf_donchian_h = self.I(
            lambda: h.rolling(self.tf_donchian_period).max().shift(1)
        )
        self.tf_donchian_l = self.I(
            lambda: l.rolling(self.tf_donchian_period).min().shift(1)
        )
        self.tf_ema_fast = self.I(
            lambda: ta.trend.EMAIndicator(c, self.tf_ema_fast_period).ema_indicator(),
            plot=False,
        )
        self.tf_ema_slow = self.I(
            lambda: ta.trend.EMAIndicator(c, self.tf_ema_slow_period).ema_indicator(),
            plot=False,
        )

        # å‡å€¼å›å½’æŒ‡æ ‡
        bb = ta.volatility.BollingerBands(c, self.mr_bb_period, self.mr_bb_std)
        self.mr_bb_upper = self.I(lambda: bb.bollinger_hband())
        self.mr_bb_lower = self.I(lambda: bb.bollinger_lband())
        self.mr_bb_mid = self.I(lambda: bb.bollinger_mavg())
        self.mr_rsi = self.I(
            lambda: ta.momentum.RSIIndicator(c, self.mr_rsi_period).rsi(),
            plot=False,
        )

        # --- å°è¯•åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹ ---
        self.lstm, self.lstm_scaler, self.xgb, self.xgb_scaler = None, None, None, None
        if self.ml_filter_enabled and self.enabled_modules.get("ml_filter", False):
            try:
                self.lstm = load_model(f"lstm_model_{self.symbol}.keras")
                self.lstm_scaler = joblib.load(f"lstm_scaler_{self.symbol}.pkl")
                logger.info(f"âœ… [{self.symbol}] LSTM æ¨¡å‹åŠscaleråŠ è½½æˆåŠŸã€‚")
            except Exception:
                logger.warning(f"[{self.symbol}] æœªèƒ½åŠ è½½LSTMæ¨¡å‹æˆ–scalerã€‚")
                self.lstm = None
            try:
                self.xgb = joblib.load(f"xgb_model_{self.symbol}.joblib")
                self.xgb_scaler = joblib.load(f"xgb_scaler_{self.symbol}.pkl")
                logger.info(f"âœ… [{self.symbol}] XGBoost æ¨¡å‹åŠscaleråŠ è½½æˆåŠŸã€‚")
            except Exception:
                logger.warning(f"[{self.symbol}] æœªèƒ½åŠ è½½XGBoostæ¨¡å‹æˆ–scalerã€‚")
                self.xgb = None

    def next(self):
        """ç­–ç•¥çš„æ ¸å¿ƒé€»è¾‘ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥è¢«è°ƒç”¨ã€‚"""
        # æ•°æ®é¢„çƒ­æœŸ
        if len(self.data) < max(
            self.tf_donchian_period, self.tf_ema_slow_period, self.regime_norm_period
        ):
            return

        # å¦‚æœæœ‰æŒä»“ï¼Œåˆ™ç®¡ç†æŒä»“
        if self.position:
            self.manage_open_position(self.data.Close[-1])
        # å¦‚æœæ— æŒä»“ï¼Œåˆ™å¯»æ‰¾å¼€ä»“æœºä¼š
        else:
            # è¶‹åŠ¿å¸‚åœº
            if self.market_regime[-1] == 1:
                if self.enabled_modules.get("trend_following", False):
                    self.run_scoring_system_entry(self.data.Close[-1])
            # éœ‡è¡å¸‚åœº
            else:
                if self.enabled_modules.get("mean_reversion", False):
                    self.run_mean_reversion_entry(self.data.Close[-1])

    def run_scoring_system_entry(self, price):
        """æ‰§è¡ŒåŸºäºè¯„åˆ†ç³»ç»Ÿçš„è¶‹åŠ¿è·Ÿè¸ªè¿›åœºé€»è¾‘ã€‚"""
        ta_score = self.asset_strategy._calculate_entry_score()
        ml_boost = 0.0

        # å¦‚æœå¯ç”¨äº†MLè¿‡æ»¤å™¨
        if self.ml_filter_enabled and self.enabled_modules.get("ml_filter", False):
            prob_lstm, prob_xgb = 0.5, 0.5
            features = [c for c in self.data.df.columns if c.startswith("feature_")]

            # LSTMé¢„æµ‹
            if (
                self.lstm
                and self.lstm_scaler
                and len(self.data.df) >= self.lstm_sequence_length
            ):
                seq = self.data.df[features].iloc[-self.lstm_sequence_length :].values
                if not np.isnan(seq).any():
                    scaled_seq = self.lstm_scaler.transform(seq)
                    prob_lstm = float(
                        self.lstm.predict(np.expand_dims(scaled_seq, 0), verbose=0)[0][
                            0
                        ]
                    )

            # XGBoosté¢„æµ‹
            if self.xgb and self.xgb_scaler:
                current_features = self.data.df[features].iloc[-1:].values
                if not np.isnan(current_features).any():
                    scaled_features = self.xgb_scaler.transform(current_features)
                    prob_xgb = float(self.xgb.predict_proba(scaled_features)[0, 1])

            # é›†æˆé¢„æµ‹
            ensemble_prob = (
                self.ensemble_w_lstm * prob_lstm + self.ensemble_w_xgb * prob_xgb
            )

            # æ ¹æ®é¢„æµ‹ç»“æœè°ƒæ•´å¾—åˆ†
            is_long_ta = ta_score > 0
            if is_long_ta and ensemble_prob > self.ml_confidence_threshold:
                ml_boost = (ensemble_prob - 0.5) * 2 * self.ml_score_weight
            elif not is_long_ta and (1 - ensemble_prob) > self.ml_confidence_threshold:
                ml_boost = ((1 - ensemble_prob) - 0.5) * 2 * self.ml_score_weight * -1

        final_score = ta_score + ml_boost

        if abs(final_score) > self.score_entry_threshold:
            self.open_tf_position(
                price, is_long=(final_score > 0), confidence_factor=abs(final_score)
            )

    def run_mean_reversion_entry(self, price):
        """æ‰§è¡Œå‡å€¼å›å½’è¿›åœºé€»è¾‘ã€‚"""
        signal = self.asset_strategy._define_mr_entry_signal()
        if signal != 0:
            self.open_mr_position(price, is_long=(signal > 0))

    def reset_trade_state(self):
        """é‡ç½®ä¸å•ç¬”äº¤æ˜“ç›¸å…³çš„çŠ¶æ€å˜é‡ã€‚"""
        self.active_sub_strategy = None
        self.chandelier_exit_level = 0.0
        self.highest_high_in_trade = 0
        self.lowest_low_in_trade = float("inf")
        self.mr_stop_loss = 0.0
        self.tf_initial_stop_loss = 0.0
        self.lpr_is_active = False
        self.lpr_trailing_stop = 0.0

    def manage_open_position(self, price):
        """ç®¡ç†å½“å‰æŒä»“çš„é€€å‡ºé€»è¾‘ã€‚"""
        # ä¼˜å…ˆå¤„ç†LPRæ¨¡å¼
        if self.lpr_is_active:
            self.manage_lpr_exit(price)
            return

        # æ£€æŸ¥æ˜¯å¦æ¿€æ´»LPRæ¨¡å¼
        if (
            self.lpr_enabled
            and self.enabled_modules.get("lpr_mode", False)
            and self.position
        ):
            trade = self.trades[-1]
            profit_pct = (
                (price / trade.entry_price - 1)
                if self.position.is_long
                else (trade.entry_price / price - 1)
            )
            if profit_pct >= self.lpr_trigger_pct:
                self.lpr_is_active = True
                self.lpr_trailing_stop = 0.0  # Reset trailing stop on activation
                logger.info(
                    f"ğŸš€ åˆ©æ¶¦å¥”è·‘æ¨¡å¼æ¿€æ´»! ä»·æ ¼: {price:.2f}, ç›ˆåˆ©: {profit_pct:.2%}"
                )
                self.manage_lpr_exit(price)
                return

        # æ ¹æ®å­ç­–ç•¥ç®¡ç†é€€å‡º
        if self.active_sub_strategy == "TF":
            self.manage_trend_following_exit(price)
        elif self.active_sub_strategy == "MR":
            self.manage_mean_reversion_exit(price)

    def open_tf_position(self, price, is_long, confidence_factor):
        """å¼€ç«‹è¶‹åŠ¿è·Ÿè¸ªä»“ä½ã€‚"""
        risk_per_share = self.tf_atr[-1] * self.tf_stop_loss_atr_multiplier
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price,
            risk_per_share,
            self._calculate_dynamic_risk() * confidence_factor,
        )
        if size <= 0:
            return

        self.reset_trade_state()
        self.active_sub_strategy = "TF"
        if is_long:
            self.buy(size=size)
            self.tf_initial_stop_loss = price - risk_per_share
            self.highest_high_in_trade = self.data.High[-1]
        else:
            self.sell(size=size)
            self.tf_initial_stop_loss = price + risk_per_share
            self.lowest_low_in_trade = self.data.Low[-1]

    def manage_trend_following_exit(self, price):
        """ç®¡ç†è¶‹åŠ¿è·Ÿè¸ªä»“ä½çš„é€€å‡ºã€‚"""
        atr = self.tf_atr[-1]
        if self.position.is_long:
            # ç¡¬æ­¢æŸ
            if price < self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            # åŠ¨æ€åŠç¯æ­¢æŸ
            self.highest_high_in_trade = max(
                self.highest_high_in_trade, self.data.High[-1]
            )
            self.chandelier_exit_level = (
                self.highest_high_in_trade - atr * self.tf_chandelier_atr_multiplier
            )
            if price < self.chandelier_exit_level:
                self.close_position("TF_Chandelier")
        elif self.position.is_short:
            # ç¡¬æ­¢æŸ
            if price > self.tf_initial_stop_loss:
                self.close_position("TF_Initial_SL")
                return
            # åŠ¨æ€åŠç¯æ­¢æŸ
            self.lowest_low_in_trade = min(self.lowest_low_in_trade, self.data.Low[-1])
            self.chandelier_exit_level = (
                self.lowest_low_in_trade + atr * self.tf_chandelier_atr_multiplier
            )
            if price > self.chandelier_exit_level:
                self.close_position("TF_Chandelier")

    def open_mr_position(self, price, is_long):
        """å¼€ç«‹å‡å€¼å›å½’ä»“ä½ã€‚"""
        risk_per_share = self.tf_atr[-1] * self.mr_stop_loss_atr_multiplier
        if risk_per_share <= 0:
            return
        size = self._calculate_position_size(
            price,
            risk_per_share,
            self._calculate_dynamic_risk() * self.mr_risk_multiplier,
        )
        if size <= 0:
            return

        self.reset_trade_state()
        self.active_sub_strategy = "MR"
        if is_long:
            self.buy(size=size)
            self.mr_stop_loss = price - risk_per_share
        else:
            self.sell(size=size)
            self.mr_stop_loss = price + risk_per_share

    def manage_mean_reversion_exit(self, price):
        """ç®¡ç†å‡å€¼å›å½’ä»“ä½çš„é€€å‡ºã€‚"""
        is_long_exit = self.position.is_long and (
            price >= self.mr_bb_mid[-1] or price <= self.mr_stop_loss
        )
        is_short_exit = self.position.is_short and (
            price <= self.mr_bb_mid[-1] or price >= self.mr_stop_loss
        )
        if is_long_exit or is_short_exit:
            self.close_position("MR_Exit")

    def manage_lpr_exit(self, price):
        """ç®¡ç†åˆ©æ¶¦å¥”è·‘æ¨¡å¼ä¸‹çš„ç§»åŠ¨æ­¢æŸã€‚"""
        atr_dist = self.tf_atr[-1] * self.lpr_trail_atr_multiplier
        if self.position.is_long:
            new_stop = self.data.High[-1] - atr_dist
            self.lpr_trailing_stop = max(self.lpr_trailing_stop, new_stop)
            if price <= self.lpr_trailing_stop:
                self.close_position("LPR_Trail_Stop")
        elif self.position.is_short:
            new_stop = self.data.Low[-1] + atr_dist
            # é¦–æ¬¡è®¾ç½®æ—¶éœ€è¦ç‰¹æ®Šå¤„ç†
            self.lpr_trailing_stop = (
                min(self.lpr_trailing_stop, new_stop)
                if self.lpr_trailing_stop > 0
                else new_stop
            )
            if price >= self.lpr_trailing_stop:
                self.close_position("LPR_Trail_Stop")

    def close_position(self, reason: str):
        """å¹³ä»“å¹¶é‡ç½®çŠ¶æ€ã€‚"""
        self.position.close()
        self.reset_trade_state()

    def _calculate_position_size(self, price, risk_per_unit, risk_pct):
        """æ ¹æ®é£é™©è®¡ç®—ä»“ä½å¤§å°ã€‚"""
        if risk_per_unit <= 0 or price <= 0:
            return 0
        cash_at_risk = risk_pct * self.equity
        position_size_in_quote = cash_at_risk / (risk_per_unit / price)
        # è½¬æ¢ä¸ºbacktesting.pyçš„sizeæ ¼å¼ (å æƒç›Šçš„ç™¾åˆ†æ¯”)
        size = position_size_in_quote / self.equity
        return min(size, 0.99)  # é¿å…æ»¡ä»“

    def _calculate_dynamic_risk(self):
        """ä½¿ç”¨ç®€åŒ–çš„å‡¯åˆ©å…¬å¼åŠ¨æ€è°ƒæ•´é£é™©ç™¾åˆ†æ¯”ã€‚"""
        trades = self.closed_trades
        if len(trades) < self.kelly_trade_history:
            return self.default_risk_pct * self.vol_weight

        recent_trades = trades[-self.kelly_trade_history :]
        returns = [t.pl_pct for t in recent_trades]
        wins = [r for r in returns if r > 0]
        losses = [r for r in returns if r < 0]

        if not wins or not losses:
            return self.default_risk_pct * self.vol_weight

        win_rate = len(wins) / len(recent_trades)
        avg_win = sum(wins) / len(wins)
        avg_loss = abs(sum(losses) / len(losses))

        if avg_loss == 0:
            return self.max_risk_pct
        reward_ratio = avg_win / avg_loss
        if reward_ratio == 0:
            return self.default_risk_pct * self.vol_weight

        # ä½¿ç”¨åŠå‡¯åˆ©ä»¥é™ä½é£é™©
        kelly_fraction = win_rate - (1 - win_rate) / reward_ratio
        risk = max(0.005, kelly_fraction * 0.5) * self.vol_weight
        return min(risk, self.max_risk_pct)


# --- MAIN EXECUTION BLOCK ---

if __name__ == "__main__":
    set_chinese_font()
    CACHE_DIR = "data_cache"
    logger.info(f"ğŸš€ (V49.1) å¼€å§‹è¿è¡ŒæŠ—è¿‡æ‹Ÿåˆé‡æ„ç‰ˆ...")

    # --- 1. æ•°æ®å‡†å¤‡ ---
    backtest_start_dt = pd.to_datetime(CONFIG["backtest_start_date"], utc=True)
    backtest_end_dt = pd.to_datetime(CONFIG["backtest_end_date"], utc=True)

    if CONFIG.get("use_pretrained_models", False):
        # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œä»…éœ€è·å–å°‘é‡å†å²æ•°æ®ç”¨äºæŒ‡æ ‡é¢„çƒ­
        warmup_days = 15
        overall_start_date = backtest_start_dt - timedelta(days=warmup_days)
        logger.info(
            f"ğŸ’¡ 'use_pretrained_models' is True. Fetching data from {overall_start_date.date()} for indicator warm-up."
        )
    else:
        # è®­ç»ƒæ¨¡å‹æ—¶ï¼Œéœ€è¦è·å–å®Œæ•´çš„è®­ç»ƒæ•°æ®çª—å£
        training_window = timedelta(days=CONFIG["training_window_days"])
        overall_start_date = backtest_start_dt - training_window

    logger.info(
        f"æ•°æ®è·å–æ€»æ—¶é—´æ®µ: {overall_start_date.date()} to {backtest_end_dt.date()}"
    )

    all_featured_data = {}
    btc_data = fetch_binance_klines(
        CONFIG["btc_symbol"],
        CONFIG["interval"],
        overall_start_date,
        backtest_end_dt,
        cache_dir=CACHE_DIR,
    )

    for s in CONFIG["symbols_to_test"]:
        raw_data = fetch_binance_klines(
            s,
            CONFIG["interval"],
            overall_start_date,
            backtest_end_dt,
            cache_dir=CACHE_DIR,
        )
        if raw_data.empty:
            logger.error(f"{s} æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡ã€‚")
            continue
        logger.info(f"ä¸º {s} æ·»åŠ æ‰€æœ‰ç‰¹å¾...")
        all_featured_data[s] = add_all_features(raw_data, btc_df=btc_data)

    if not all_featured_data:
        logger.error("æ‰€æœ‰å“ç§æ•°æ®å¤„ç†å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        exit()

    # --- 2. å›æµ‹æ‰§è¡Œ ---
    all_equity_curves, all_trades, all_model_accuracies = [], pd.DataFrame(), []
    current_equity = CONFIG["initial_cash"]

    # MODIFICATION: æ ¹æ® use_pretrained_models çš„å€¼é€‰æ‹©å›æµ‹æ¨¡å¼
    if CONFIG.get("use_pretrained_models", False):
        # --- æ¨¡å¼ä¸€: å•æ¬¡è¿ç»­å›æµ‹ (ä¸è®­ç»ƒæ¨¡å‹) ---
        logger.info("ğŸš€ 'use_pretrained_models' is True. è¿è¡Œå•æ¬¡è¿ç»­å›æµ‹æ¨¡å¼ã€‚")
        print(
            "#" * 80
            + f"\nå•æ¬¡è¿ç»­å›æµ‹: {backtest_start_dt.date()} to {backtest_end_dt.date()}\n"
            + "#" * 80
        )

        for symbol in CONFIG["symbols_to_test"]:
            if symbol not in all_featured_data:
                continue

            data = all_featured_data[symbol]
            backtest_slice = data.loc[backtest_start_dt:backtest_end_dt].copy().dropna()

            if backtest_slice.empty:
                logger.warning(f"[{symbol}] åœ¨æŒ‡å®šå›æµ‹æœŸé—´å†…æ— æ•°æ®ï¼Œè·³è¿‡ã€‚")
                continue

            logger.info(f"å¼€å§‹å›æµ‹ {symbol}...")
            logger.info(f"[{symbol}] å°†å°è¯•åŠ è½½å·²å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶ã€‚")

            bt = Backtest(
                backtest_slice,
                UltimateStrategy,
                cash=current_equity,
                commission=CONFIG["commission"],
                finalize_trades=True,
            )
            stats = bt.run(symbol=symbol, enabled_modules=CONFIG["enabled_modules"])

            current_equity = stats["Equity Final [$]"]
            all_equity_curves.append(stats["_equity_curve"])
            if "_trades" in stats and not stats["_trades"].empty:
                trades_df = stats["_trades"]
                trades_df["Symbol"] = symbol
                all_trades = pd.concat([all_trades, trades_df], ignore_index=True)

            print(stats)

    else:
        # --- æ¨¡å¼äºŒ: æ»šåŠ¨çª—å£å›æµ‹ (è®­ç»ƒæ¨¡å‹) ---
        logger.info(
            "ğŸš€ 'use_pretrained_models' is False. è¿è¡Œæ»šåŠ¨çª—å£å›æµ‹ (Walk-Forward) æ¨¡å¼ã€‚"
        )
        walk_forward_periods = pd.date_range(
            start=backtest_start_dt, end=backtest_end_dt, freq="3MS"
        )

        for i, period_start in enumerate(walk_forward_periods):
            period_end = (
                walk_forward_periods[i + 1] - timedelta(seconds=1)
                if i + 1 < len(walk_forward_periods)
                else backtest_end_dt
            )
            training_end_dt = period_start - timedelta(seconds=1)
            gap_days = CONFIG.get("ml_training_gap_days", 30)
            training_end_with_gap = training_end_dt - timedelta(days=gap_days)

            print(
                "\n"
                + "#" * 80
                + f"\næ»šåŠ¨å‘¨æœŸ {i+1}: å›æµ‹ {period_start.date()} to {period_end.date()}\n"
                + "#" * 80
            )

            for symbol, data in all_featured_data.items():
                period_accuracies = {}

                # æ¨¡å‹è®­ç»ƒ
                if (
                    STRATEGY_PARAMS["ml_filter_enabled"]
                    and CONFIG["enabled_modules"].get("ml_filter", False)
                    and ML_LIBS
                ):
                    logger.info(
                        f"[{symbol}] å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œæˆªæ­¢äº: {training_end_with_gap.date()} (å·²åº”ç”¨ {gap_days}-day éš”ç¦»æœŸ)"
                    )
                    training_slice = data.loc[:training_end_with_gap]

                    if len(training_slice) > 1000:
                        acc_lstm = train_and_save_lstm(
                            training_slice,
                            symbol,
                            STRATEGY_PARAMS["lstm_sequence_length"],
                            STRATEGY_PARAMS["lstm_epochs"],
                            STRATEGY_PARAMS["lstm_batch_size"],
                        )
                        acc_xgb = train_and_save_xgb(training_slice, symbol)
                        if acc_lstm is not None:
                            period_accuracies["lstm"] = acc_lstm
                        if acc_xgb is not None:
                            period_accuracies["xgb"] = acc_xgb
                    else:
                        logger.warning(
                            f"[{symbol}] è®­ç»ƒæ•°æ®ä¸è¶³ (<1000)ï¼Œè·³è¿‡æœ¬å‘¨æœŸè®­ç»ƒã€‚"
                        )

                if period_accuracies:
                    all_model_accuracies.append(period_accuracies)

                # æ‰§è¡Œå›æµ‹
                backtest_slice = data.loc[period_start:period_end].copy().dropna()
                if backtest_slice.empty:
                    logger.warning(f"[{symbol}] åœ¨å‘¨æœŸ {i+1} å†…æ²¡æœ‰æ•°æ®ï¼Œè·³è¿‡å›æµ‹ã€‚")
                    continue

                logger.info(f"å¼€å§‹å›æµ‹ {symbol} for period {i+1}...")
                bt = Backtest(
                    backtest_slice,
                    UltimateStrategy,
                    cash=current_equity,
                    commission=CONFIG["commission"],
                    finalize_trades=True,
                )
                stats = bt.run(symbol=symbol, enabled_modules=CONFIG["enabled_modules"])

                current_equity = stats["Equity Final [$]"]
                all_equity_curves.append(stats["_equity_curve"])
                if "_trades" in stats and not stats["_trades"].empty:
                    trades_df = stats["_trades"]
                    trades_df["Symbol"] = symbol
                    trades_df["Rolling Period"] = i + 1
                    all_trades = pd.concat([all_trades, trades_df], ignore_index=True)

                print(stats)

    # --- 3. ç»“æœåˆ†æä¸å¯è§†åŒ– ---
    if not all_trades.empty:
        final_stats = {
            "Profit Factor": (
                all_trades[all_trades["PnL"] > 0]["PnL"].sum()
                / abs(all_trades[all_trades["PnL"] < 0]["PnL"].sum())
                if abs(all_trades[all_trades["PnL"] < 0]["PnL"].sum()) != 0
                else float("inf")
            ),
            "Win Rate [%]": len(all_trades[all_trades["ReturnPct"] > 0])
            / len(all_trades)
            * 100,
            "# Trades": len(all_trades),
        }
        logger.info("\n" + "#" * 80 + "\n                 å›æµ‹è¡¨ç°æ€»è§ˆ\n" + "#" * 80)
        logger.info(f"æ€»åˆå§‹èµ„é‡‘: ${CONFIG['initial_cash']:,.2f}")
        logger.info(f"æ€»æœ€ç»ˆæƒç›Š: ${current_equity:,.2f}")
        logger.info(
            f"æ€»å›æŠ¥ç‡: {(current_equity / CONFIG['initial_cash'] - 1) * 100:.2f}%"
        )
        logger.info(f"æ€»äº¤æ˜“æ¬¡æ•°: {final_stats['# Trades']}")
        logger.info(f"æ•´ä½“èƒœç‡: {final_stats['Win Rate [%]']:.2f}%")
        logger.info(f"æ•´ä½“ç›ˆäºå› å­ (Profit Factor): {final_stats['Profit Factor']:.2f}")

        if CONFIG["show_plots"]:
            plot_title = (
                "ç­–ç•¥æƒç›Šæ›²çº¿"
                if CONFIG.get("use_pretrained_models")
                else "æ»šåŠ¨å›æµ‹æƒç›Šæ›²çº¿"
            )
            plot_walk_forward_equity(
                all_equity_curves, all_trades, CONFIG["initial_cash"], title=plot_title
            )
            analyze_trade_distribution(all_trades)

        generate_optimization_suggestions(final_stats, all_model_accuracies, CONFIG)
    else:
        logger.info("æ•´ä¸ªå›æµ‹æœŸé—´æ²¡æœ‰äº§ç”Ÿä»»ä½•äº¤æ˜“ã€‚")
