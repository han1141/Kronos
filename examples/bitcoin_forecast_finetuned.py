import pandas as pd
import matplotlib.pyplot as plt
import sys
import torch
import os
# é¢„æµ‹btc - ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹
sys.path.append("../")
from model import Kronos, KronosTokenizer, KronosPredictor

if torch.backends.mps.is_available():
    device = "mps"
    print("âœ…  MPS (Apple Silicon GPU).")
else:
    device = "cpu"

csv_name1 = "./csv/btc_usdt_1d_no_time.csv"
df = pd.read_csv(csv_name1)
df["timestamps"] = pd.to_datetime(df["timestamps"])

# =================================================================
# ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹
# =================================================================
print("ğŸ”„ æ­£åœ¨åŠ è½½å¾®è°ƒåçš„æ¨¡å‹...")

# å¾®è°ƒåçš„tokenizerè·¯å¾„
finetuned_tokenizer_path = "../outputs/models/btc_finetune_tokenizer/checkpoints/best_model"
# å¾®è°ƒåçš„predictorè·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
finetuned_predictor_path = "../outputs/models/btc_finetune_predictor/checkpoints/best_model"

# æ£€æŸ¥å¾®è°ƒåçš„predictoræ˜¯å¦å­˜åœ¨
if os.path.exists(finetuned_predictor_path):
    print("âœ… æ‰¾åˆ°å¾®è°ƒåçš„predictoræ¨¡å‹ï¼Œæ­£åœ¨åŠ è½½...")
    tokenizer = KronosTokenizer.from_pretrained(finetuned_tokenizer_path)
    model = Kronos.from_pretrained(finetuned_predictor_path)
    print("âœ… æˆåŠŸåŠ è½½å¾®è°ƒåçš„tokenizerå’Œpredictor")
else:
    print("âš ï¸  æœªæ‰¾åˆ°å¾®è°ƒåçš„predictoræ¨¡å‹ï¼Œä½¿ç”¨å¾®è°ƒåçš„tokenizer + é¢„è®­ç»ƒçš„predictor")
    tokenizer = KronosTokenizer.from_pretrained(finetuned_tokenizer_path)
    model = Kronos.from_pretrained("NeoQuasar/Kronos-small")
    print("âœ… æˆåŠŸåŠ è½½å¾®è°ƒåçš„tokenizerå’Œé¢„è®­ç»ƒçš„predictor")

predictor = KronosPredictor(
    model=model,
    tokenizer=tokenizer,
    device=device,
)

# =================================================================
# é¢„æµ‹å‚æ•°è®¾ç½®
# =================================================================
lookback = 400
pred_len = 120

if len(df) < lookback:
    print(
        f"âŒ æ•°æ®ä¸è¶³ï¼éœ€è¦è‡³å°‘ {lookback} è¡Œå†å²æ•°æ®ï¼Œä½†æ–‡ä»¶åªæœ‰ {len(df)} è¡Œã€‚"
    )
    sys.exit()

# =================================================================
# æ•°æ®å‡†å¤‡å’Œé¢„æµ‹
# =================================================================
x_df_for_forecast = df.iloc[-lookback:].copy()
x_timestamp_for_forecast = x_df_for_forecast["timestamps"]
last_timestamp = x_timestamp_for_forecast.iloc[-1]
freq = pd.infer_freq(x_timestamp_for_forecast)
if freq is None:
    freq = "h"
    print(f"æ— æ³•è‡ªåŠ¨æ¨æ–­æ—¶é—´é¢‘ç‡ï¼Œå·²é»˜è®¤ä½¿ç”¨ '{freq}'ã€‚")

future_timestamps = pd.date_range(
    start=last_timestamp, periods=pred_len + 1, freq=freq
)[1:]
y_timestamp_for_forecast = pd.Series(future_timestamps)

print("ğŸ”® å¼€å§‹è¿›è¡ŒBTCä»·æ ¼é¢„æµ‹...")
forecast_df = predictor.predict(
    df=x_df_for_forecast[["open", "high", "low", "close", "volume"]],
    x_timestamp=x_timestamp_for_forecast,
    y_timestamp=y_timestamp_for_forecast,
    pred_len=pred_len,
    T=0.7,
    top_p=1.0,
    sample_count=3,
    verbose=True,
)
forecast_df["timestamps"] = y_timestamp_for_forecast.values

# =================================================================
# ç»“æœå¯¼å‡º
# =================================================================
x_df_for_forecast_export = x_df_for_forecast.copy()
x_df_for_forecast_export['data_type'] = 'historical'
forecast_df_export = forecast_df.copy()
forecast_df_export['data_type'] = 'prediction'

# å¤„ç†æ—¶åŒºä¿¡æ¯
if hasattr(x_df_for_forecast_export['timestamps'].dtype, 'tz') and x_df_for_forecast_export['timestamps'].dtype.tz is not None:
    x_df_for_forecast_export['timestamps'] = x_df_for_forecast_export['timestamps'].dt.tz_localize(None)

if hasattr(forecast_df_export['timestamps'].dtype, 'tz') and forecast_df_export['timestamps'].dtype.tz is not None:
    forecast_df_export['timestamps'] = forecast_df_export['timestamps'].dt.tz_localize(None)

combined_df = pd.concat([x_df_for_forecast_export, forecast_df_export], ignore_index=True)
combined_df = combined_df.sort_values('timestamps').reset_index(drop=True)
output_filename = "csv/kronos_btc_finetuned.csv"
combined_df.to_csv(output_filename, index=False)

print(f"\nâœ… å·²æˆåŠŸå¯¼å‡ºåˆå¹¶æ•°æ®åˆ°: {output_filename}")
print(f"   - å†å²æ•°æ®: {len(x_df_for_forecast_export)} æ¡")
print(f"   - é¢„æµ‹æ•°æ®: {len(forecast_df_export)} æ¡")
print(f"   - æ€»è®¡: {len(combined_df)} æ¡")

# =================================================================
# æ¨¡å‹ä¿¡æ¯æ€»ç»“
# =================================================================
print("\nğŸ“Š ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯:")
if os.path.exists(finetuned_predictor_path):
    print("   - Tokenizer: å¾®è°ƒåçš„BTCä¸“ç”¨tokenizer")
    print("   - Predictor: å¾®è°ƒåçš„BTCä¸“ç”¨predictor")
    print("   - æ¨¡å‹çŠ¶æ€: å®Œå…¨å¾®è°ƒ")
else:
    print("   - Tokenizer: å¾®è°ƒåçš„BTCä¸“ç”¨tokenizer")
    print("   - Predictor: é¢„è®­ç»ƒçš„é€šç”¨predictor")
    print("   - æ¨¡å‹çŠ¶æ€: éƒ¨åˆ†å¾®è°ƒï¼ˆä»…tokenizerï¼‰")
print(f"   - è®¾å¤‡: {device}")
print(f"   - å†å²çª—å£: {lookback} å¤©")
print(f"   - é¢„æµ‹çª—å£: {pred_len} å¤©")